{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ImageCLEF2021 Multi-label Classification Approach.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IWL-Z1HaCG9K",
        "np7WJ9mqK3Xn"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjpa121197/ImageCLEF2021/blob/main/Multi_label_classification/ImageCLEF2021_Multi_label_Classification_Approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SecnTw3YOFcf",
        "outputId": "e7d5e00d-c2b8-438b-cc09-9c3c19bd852a"
      },
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "os.environ['KAGGLE_USERNAME'] = \"#####\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"#####\" # key from the json file\n",
        "!kaggle datasets download -d fjpa121197/imageclefmed-concept-detection-2021\n",
        "!kaggle datasets download -d fjpa121197/training-images-concepts-by-semantic-type\n",
        "!kaggle datasets download -d fjpa121197/imageclefmed2021 # api copied from kaggle !!!!!!!CHANGE API COMMAND TO THE NEW DATASET"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imageclefmed-concept-detection-2021.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "training-images-concepts-by-semantic-type.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "imageclefmed2021.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkgd35TJO-_6",
        "outputId": "6bf67eda-926e-4d5a-edc9-4a0f1bcf1280"
      },
      "source": [
        "# Unzip 2021 data\n",
        "clef2021 = \"/content/imageclefmed-concept-detection-2021.zip\"\n",
        "with ZipFile(clef2021, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done with 2021 image dataset')\n",
        "\n",
        "clef2021_concepts = \"/content/training-images-concepts-by-semantic-type.zip\"\n",
        "with ZipFile(clef2021_concepts, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done with 2021 concepts dataset')\n",
        "\n",
        "# Unzip 2020 data\n",
        "clef2020 = \"/content/imageclefmed2021.zip\"\n",
        "with ZipFile(clef2020, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done with 2020 image dataset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done with 2021 image dataset\n",
            "done with 2021 concepts dataset\n",
            "done with 2020 image dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxbiRBQIh5r1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import json\n",
        "import pickle\n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkY-h2I8BNqJ"
      },
      "source": [
        "# Multi-label Classification without autoencoders and Densenet-121"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWL-Z1HaCG9K"
      },
      "source": [
        "## Using 2021 data only (all semantic type labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMjuNMKTCS6S"
      },
      "source": [
        "# Utils functions\n",
        "def extract_concepts(root_paths, image_id_concepts_dict = dict()):\n",
        "\n",
        "    for idx, name in enumerate(root_paths):\n",
        "      with open(name, \"r\", encoding= 'utf-8-sig') as f:\n",
        "        reader = csv.reader(f, delimiter = '\\t')\n",
        "        \n",
        "        if name == '/content/Training_Set_Concepts.csv':\n",
        "          image_path = '/content/ImageCLEF2021_ConceptDetection_Training-Set/ImageCLEF2021_ConceptDetection_Training-Set/Training-Images/'\n",
        "        else:\n",
        "          image_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images/'\n",
        "        for i, line in enumerate(reader):\n",
        "          if len(line[1]) < 1:\n",
        "            image_id_concepts_dict[image_path+line[0]+'.jpg'] = []\n",
        "          else:\n",
        "            image_id_concepts_dict[image_path+line[0]+'.jpg'] = list(line[1].split(';'))\n",
        "\n",
        "    return image_id_concepts_dict\n",
        "\n",
        "\n",
        "def transform_images(path_to_image):\n",
        "  #path_to_image = os.path.join(training_images_dir, image)\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_to_image, target_size= (224,224))\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img = tf.keras.applications.densenet.preprocess_input(img)\n",
        "\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzIv2QnUCTAQ"
      },
      "source": [
        "# Path and csv name to concepts file for training and validation images\n",
        "path_to_concepts = ['/content/Training_Set_Concepts.csv','/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation_Set_Concepts.csv']\n",
        "\n",
        "#Extract concepts for the validation and training images and save to dict\n",
        "image_id_concepts_dict = extract_concepts(path_to_concepts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTRAHAR3F0e7"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "images_ids = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoDYi6Z1F0iD"
      },
      "source": [
        "for image in image_id_concepts_dict.keys():\n",
        "  X.append(transform_images(image))\n",
        "  Y.append(image_id_concepts_dict[image])\n",
        "  images_ids.append(image.split(\"/\")[-1].split(\".\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZG8q0GhJHxz",
        "outputId": "7bbb5cb9-2804-4da1-b338-ef19c7e77477"
      },
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVvLHnYdF0lF",
        "outputId": "0dfa6341-4063-47f6-b6e6-925d4779121a"
      },
      "source": [
        "# Use a multilabelbinarizer to transform the concepts into a binary format for training\n",
        "mlb = MultiLabelBinarizer()\n",
        "Y = mlb.fit_transform(Y)\n",
        "print(len(mlb.classes_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez-hTCueF0ow"
      },
      "source": [
        "X, X_test, y, y_test = train_test_split(X, Y, test_size = 0.1, shuffle = True, random_state = 14)\n",
        "ids_images_train, ids_images_test = train_test_split(images_ids, test_size = 0.1, shuffle=True, random_state = 14) \n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 14) \n",
        "ids_images_train_train, ids_images_val = train_test_split(ids_images_train, test_size = 0.2, shuffle=True, random_state = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbnC5uMeJB33",
        "outputId": "f96c796c-18eb-49f2-80ad-124c892d0757"
      },
      "source": [
        "X_train.shape\n",
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2344, 1585)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8efwlgXMF0sB"
      },
      "source": [
        "default_densenet = tf.keras.applications.densenet.DenseNet121(include_top=False, weights= 'imagenet') # Load model (only feature extraction part) with imagenet weights\n",
        "default_densenet.trainable = False # Freeze all layers of the model, so weights remain the same when training, and only weights from added layers update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRb7ozyvF0uv"
      },
      "source": [
        "# Adding the classification part to the existing model\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(default_densenet.output)\n",
        "x = tf.keras.layers.Dense(len(mlb.classes_), activation='sigmoid', name = 'prediction_layer')(x)\n",
        "\n",
        "\n",
        "mlcf_model = tf.keras.models.Model(inputs = default_densenet.input, outputs= x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix8b3nMcIHB-"
      },
      "source": [
        "# Define some required parameter for training\n",
        "init_lr = 1e-4\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "valid_batch_size = 32\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=init_lr, decay=init_lr / epochs)\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 5, restore_best_weights= True, mode = 'max')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9HnBjxdIHFB"
      },
      "source": [
        "# Compile model\n",
        "mlcf_model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L88ogxuIHI-"
      },
      "source": [
        "# Data generator to be used for training\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2)\n",
        "train_generator = data_generator.flow(X_train, y_train, batch_size = 32, subset = 'training', seed = 14)\n",
        "val_generator = data_generator.flow(X_train, y_train, batch_size = 32, subset = 'validation', seed = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFDUXuSWIHL-",
        "outputId": "bec68e3f-8838-43cb-97c8-ec0a6f2eccb0"
      },
      "source": [
        "history = mlcf_model.fit(train_generator, epochs = epochs, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "59/59 [==============================] - 24s 292ms/step - loss: 0.5244 - acc: 0.0023 - val_loss: 0.1377 - val_acc: 0.0598\n",
            "Epoch 2/100\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.1088 - acc: 0.1129 - val_loss: 0.0577 - val_acc: 0.2030\n",
            "Epoch 3/100\n",
            "59/59 [==============================] - 15s 258ms/step - loss: 0.0507 - acc: 0.2133 - val_loss: 0.0363 - val_acc: 0.2457\n",
            "Epoch 4/100\n",
            "59/59 [==============================] - 15s 259ms/step - loss: 0.0331 - acc: 0.2664 - val_loss: 0.0270 - val_acc: 0.2756\n",
            "Epoch 5/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0253 - acc: 0.2808 - val_loss: 0.0221 - val_acc: 0.2927\n",
            "Epoch 6/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0209 - acc: 0.2989 - val_loss: 0.0191 - val_acc: 0.2927\n",
            "Epoch 7/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0187 - acc: 0.2895 - val_loss: 0.0171 - val_acc: 0.2927\n",
            "Epoch 8/100\n",
            "59/59 [==============================] - 15s 259ms/step - loss: 0.0165 - acc: 0.2862 - val_loss: 0.0158 - val_acc: 0.3056\n",
            "Epoch 9/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0151 - acc: 0.3041 - val_loss: 0.0148 - val_acc: 0.3077\n",
            "Epoch 10/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0144 - acc: 0.3053 - val_loss: 0.0141 - val_acc: 0.3120\n",
            "Epoch 11/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0132 - acc: 0.3085 - val_loss: 0.0135 - val_acc: 0.3098\n",
            "Epoch 12/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0127 - acc: 0.3056 - val_loss: 0.0131 - val_acc: 0.3098\n",
            "Epoch 13/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0123 - acc: 0.3187 - val_loss: 0.0127 - val_acc: 0.3141\n",
            "Epoch 14/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0121 - acc: 0.3184 - val_loss: 0.0124 - val_acc: 0.3184\n",
            "Epoch 15/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0116 - acc: 0.3378 - val_loss: 0.0122 - val_acc: 0.3184\n",
            "Epoch 16/100\n",
            "59/59 [==============================] - 15s 262ms/step - loss: 0.0114 - acc: 0.3184 - val_loss: 0.0120 - val_acc: 0.3248\n",
            "Epoch 17/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0113 - acc: 0.3500 - val_loss: 0.0118 - val_acc: 0.3269\n",
            "Epoch 18/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0108 - acc: 0.3607 - val_loss: 0.0117 - val_acc: 0.3291\n",
            "Epoch 19/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0107 - acc: 0.3626 - val_loss: 0.0116 - val_acc: 0.3312\n",
            "Epoch 20/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0104 - acc: 0.3532 - val_loss: 0.0115 - val_acc: 0.3312\n",
            "Epoch 21/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0103 - acc: 0.3489 - val_loss: 0.0114 - val_acc: 0.3333\n",
            "Epoch 22/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0100 - acc: 0.3342 - val_loss: 0.0113 - val_acc: 0.3355\n",
            "Epoch 23/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0101 - acc: 0.3677 - val_loss: 0.0112 - val_acc: 0.3333\n",
            "Epoch 24/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0100 - acc: 0.3369 - val_loss: 0.0111 - val_acc: 0.3355\n",
            "Epoch 25/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0098 - acc: 0.3686 - val_loss: 0.0110 - val_acc: 0.3355\n",
            "Epoch 26/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0097 - acc: 0.3648 - val_loss: 0.0110 - val_acc: 0.3376\n",
            "Epoch 27/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0098 - acc: 0.3509 - val_loss: 0.0109 - val_acc: 0.3355\n",
            "Epoch 28/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0097 - acc: 0.3433 - val_loss: 0.0109 - val_acc: 0.3419\n",
            "Epoch 29/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0094 - acc: 0.3589 - val_loss: 0.0108 - val_acc: 0.3397\n",
            "Epoch 30/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0095 - acc: 0.3561 - val_loss: 0.0108 - val_acc: 0.3440\n",
            "Epoch 31/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0092 - acc: 0.3706 - val_loss: 0.0108 - val_acc: 0.3419\n",
            "Epoch 32/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0091 - acc: 0.3737 - val_loss: 0.0107 - val_acc: 0.3440\n",
            "Epoch 33/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0092 - acc: 0.3709 - val_loss: 0.0107 - val_acc: 0.3462\n",
            "Epoch 34/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0089 - acc: 0.3632 - val_loss: 0.0106 - val_acc: 0.3462\n",
            "Epoch 35/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0092 - acc: 0.3686 - val_loss: 0.0106 - val_acc: 0.3462\n",
            "Epoch 36/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0090 - acc: 0.3654 - val_loss: 0.0106 - val_acc: 0.3483\n",
            "Epoch 37/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0086 - acc: 0.3662 - val_loss: 0.0105 - val_acc: 0.3504\n",
            "Epoch 38/100\n",
            "59/59 [==============================] - 15s 259ms/step - loss: 0.0087 - acc: 0.3861 - val_loss: 0.0105 - val_acc: 0.3504\n",
            "Epoch 39/100\n",
            "59/59 [==============================] - 15s 262ms/step - loss: 0.0087 - acc: 0.3739 - val_loss: 0.0105 - val_acc: 0.3504\n",
            "Epoch 40/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0084 - acc: 0.3769 - val_loss: 0.0105 - val_acc: 0.3504\n",
            "Epoch 41/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0085 - acc: 0.3810 - val_loss: 0.0104 - val_acc: 0.3504\n",
            "Epoch 42/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0083 - acc: 0.3668 - val_loss: 0.0104 - val_acc: 0.3526\n",
            "Epoch 43/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0084 - acc: 0.3841 - val_loss: 0.0104 - val_acc: 0.3504\n",
            "Epoch 44/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0082 - acc: 0.3983 - val_loss: 0.0104 - val_acc: 0.3504\n",
            "Epoch 45/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0082 - acc: 0.3765 - val_loss: 0.0103 - val_acc: 0.3526\n",
            "Epoch 46/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0079 - acc: 0.3808 - val_loss: 0.0103 - val_acc: 0.3547\n",
            "Epoch 47/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0080 - acc: 0.3730 - val_loss: 0.0103 - val_acc: 0.3590\n",
            "Epoch 48/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0077 - acc: 0.3699 - val_loss: 0.0103 - val_acc: 0.3611\n",
            "Epoch 49/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0079 - acc: 0.3842 - val_loss: 0.0102 - val_acc: 0.3611\n",
            "Epoch 50/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0079 - acc: 0.3616 - val_loss: 0.0102 - val_acc: 0.3590\n",
            "Epoch 51/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0077 - acc: 0.3628 - val_loss: 0.0102 - val_acc: 0.3590\n",
            "Epoch 52/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0075 - acc: 0.3959 - val_loss: 0.0102 - val_acc: 0.3611\n",
            "Epoch 53/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0074 - acc: 0.3824 - val_loss: 0.0102 - val_acc: 0.3611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4rgAqEQN5W8"
      },
      "source": [
        "layer_names = [layer.name for layer in mlcf_model.layers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxpTKUoDN5aq"
      },
      "source": [
        "layer_idx = layer_names.index('conv5_block1_0_bn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4TnsledIHO4"
      },
      "source": [
        "for layer in mlcf_model.layers[layer_idx:]:\n",
        "  layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9kILkx4IHSW"
      },
      "source": [
        "# A new learning rate is defined, since a keras guide (https://keras.io/guides/transfer_learning/) suggests to lower it. Search for \"It's also critical to use a very low learning\"\n",
        "new_lr = 1e-5\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=new_lr, decay=new_lr / epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbp0znSmKZXS"
      },
      "source": [
        "# Compile model\n",
        "mlcf_model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSv-DlwjKZab",
        "outputId": "2269cd13-2b74-4cd8-9539-76d5a00d2cfd"
      },
      "source": [
        "history_fined = mlcf_model.fit(train_generator, epochs = 150, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks, initial_epoch = history.epoch[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 53/150\n",
            "59/59 [==============================] - 28s 323ms/step - loss: 0.0084 - acc: 0.3801 - val_loss: 0.0104 - val_acc: 0.3590\n",
            "Epoch 54/150\n",
            "59/59 [==============================] - 17s 287ms/step - loss: 0.0083 - acc: 0.3578 - val_loss: 0.0105 - val_acc: 0.3568\n",
            "Epoch 55/150\n",
            "59/59 [==============================] - 17s 289ms/step - loss: 0.0080 - acc: 0.3764 - val_loss: 0.0104 - val_acc: 0.3568\n",
            "Epoch 56/150\n",
            "59/59 [==============================] - 17s 290ms/step - loss: 0.0077 - acc: 0.3731 - val_loss: 0.0103 - val_acc: 0.3568\n",
            "Epoch 57/150\n",
            "59/59 [==============================] - 17s 291ms/step - loss: 0.0077 - acc: 0.3940 - val_loss: 0.0103 - val_acc: 0.3590\n",
            "Epoch 58/150\n",
            "59/59 [==============================] - 17s 291ms/step - loss: 0.0077 - acc: 0.3875 - val_loss: 0.0102 - val_acc: 0.3590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz5kqM7aKZdq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgfa0_MJKZgg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb5PyEC7KZkA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JEB9mtbKZmk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np7WJ9mqK3Xn"
      },
      "source": [
        "## Using 2021 data only (only with dp labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU9Ieo_RZCSq"
      },
      "source": [
        "# Utils functions\n",
        "def extract_concepts(root_paths, image_id_concepts_dict = dict()):\n",
        "\n",
        "    for idx, name in enumerate(root_paths):\n",
        "      with open(name, \"r\", encoding= 'utf-8-sig') as f:\n",
        "        reader = csv.reader(f, delimiter = '\\t')\n",
        "        \n",
        "        if name == '/content/training-images-concepts-by-semantic/concepts-file/training-concepts-dp-only.csv':\n",
        "          image_path = '/content/ImageCLEF2021_ConceptDetection_Training-Set/ImageCLEF2021_ConceptDetection_Training-Set/Training-Images/'\n",
        "        else:\n",
        "          image_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images/'\n",
        "        for i, line in enumerate(reader):\n",
        "          if len(line[1]) < 1:\n",
        "            image_id_concepts_dict[image_path+line[0]+'.jpg'] = []\n",
        "          else:\n",
        "            image_id_concepts_dict[image_path+line[0]+'.jpg'] = list(line[1].split(';'))\n",
        "\n",
        "    return image_id_concepts_dict\n",
        "\n",
        "\n",
        "def transform_images(path_to_image):\n",
        "  #path_to_image = os.path.join(training_images_dir, image)\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_to_image, target_size= (224,224))\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img = tf.keras.applications.densenet.preprocess_input(img)\n",
        "\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukKfXlMkjoff"
      },
      "source": [
        "# Path and csv name to concepts file for training and validation images\n",
        "path_to_concepts = ['/content/training-images-concepts-by-semantic/concepts-file/training-concepts-dp-only.csv',\n",
        "                    '/content/val-concepts-dp-only.csv']\n",
        "\n",
        "#Extract concepts for the validation and training images and save to dict\n",
        "image_id_concepts_dict = extract_concepts(path_to_concepts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JHcagS6kGNR"
      },
      "source": [
        "# Define array where images array will be saved for training, and where the concepts for each image will be saved (Y)\n",
        "X = []\n",
        "Y = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7QdBnfykT4G"
      },
      "source": [
        "# Load images\n",
        "\n",
        "for image in image_id_concepts_dict.keys():\n",
        "  X.append(transform_images(image))\n",
        "  Y.append(image_id_concepts_dict[image])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvIq0cCbkcNp",
        "outputId": "8ac0764c-080c-4b23-f4fb-ed287a5aa94d"
      },
      "source": [
        "# Transform arrays to numpy arrays\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ftK-pGCkWzY",
        "outputId": "c9d3f2ee-4369-45cf-d36f-152f9c5d71c4"
      },
      "source": [
        "# Use a multilabelbinarizer to transform the concepts into a binary format for training\n",
        "mlb = MultiLabelBinarizer()\n",
        "Y = mlb.fit_transform(Y)\n",
        "print(len(mlb.classes_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffGSQMY3p663"
      },
      "source": [
        "Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPCv8syjk3C9"
      },
      "source": [
        "default_densenet = tf.keras.applications.densenet.DenseNet121(include_top=False, weights= 'imagenet') # Load model (only feature extraction part) with imagenet weights\n",
        "default_densenet.trainable = False # Freeze all layers of the model, so weights remain the same when training, and only weights from added layers update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXfZoTEKmcN_"
      },
      "source": [
        "# Adding the classification part to the existing model\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(default_densenet.output)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(len(mlb.classes_), activation='sigmoid', name = 'prediction_layer')(x)\n",
        "\n",
        "\n",
        "dp_model = tf.keras.models.Model(inputs = default_densenet.input, outputs= x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQpZofHWnInz"
      },
      "source": [
        "# Define some required parameter for training\n",
        "init_lr = 1e-4\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "valid_batch_size = 32\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=init_lr, decay=init_lr / epochs)\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 10, restore_best_weights= True, mode = 'max')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz_E-S3Rngfk"
      },
      "source": [
        "# Compile model\n",
        "dp_model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-Rrh69yn4eW"
      },
      "source": [
        "# Data generator to be used for training\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2)\n",
        "train_generator = data_generator.flow(X, Y, batch_size = 32, subset = 'training', seed = 14)\n",
        "val_generator = data_generator.flow(X, Y, batch_size = 32, subset = 'validation', seed = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crT2vsWPq3s7",
        "outputId": "18db5e80-7de1-4bc2-b638-dfc27f6100a5"
      },
      "source": [
        "history = dp_model.fit(train_generator, epochs = epochs, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "82/82 [==============================] - 33s 315ms/step - loss: 0.3821 - acc: 0.1387 - val_loss: 0.0297 - val_acc: 0.6390\n",
            "Epoch 2/100\n",
            "82/82 [==============================] - 21s 257ms/step - loss: 0.0260 - acc: 0.6836 - val_loss: 0.0216 - val_acc: 0.7619\n",
            "Epoch 3/100\n",
            "82/82 [==============================] - 21s 258ms/step - loss: 0.0199 - acc: 0.7961 - val_loss: 0.0191 - val_acc: 0.8003\n",
            "Epoch 4/100\n",
            "82/82 [==============================] - 21s 258ms/step - loss: 0.0169 - acc: 0.8443 - val_loss: 0.0176 - val_acc: 0.8203\n",
            "Epoch 5/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0156 - acc: 0.8549 - val_loss: 0.0168 - val_acc: 0.8295\n",
            "Epoch 6/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0141 - acc: 0.8641 - val_loss: 0.0161 - val_acc: 0.8341\n",
            "Epoch 7/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0138 - acc: 0.8740 - val_loss: 0.0156 - val_acc: 0.8372\n",
            "Epoch 8/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0126 - acc: 0.8815 - val_loss: 0.0152 - val_acc: 0.8372\n",
            "Epoch 9/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0118 - acc: 0.8953 - val_loss: 0.0148 - val_acc: 0.8433\n",
            "Epoch 10/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0111 - acc: 0.9040 - val_loss: 0.0144 - val_acc: 0.8541\n",
            "Epoch 11/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0111 - acc: 0.8915 - val_loss: 0.0142 - val_acc: 0.8510\n",
            "Epoch 12/100\n",
            "82/82 [==============================] - 21s 258ms/step - loss: 0.0104 - acc: 0.9098 - val_loss: 0.0141 - val_acc: 0.8571\n",
            "Epoch 13/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0096 - acc: 0.9157 - val_loss: 0.0138 - val_acc: 0.8587\n",
            "Epoch 14/100\n",
            "82/82 [==============================] - 21s 258ms/step - loss: 0.0097 - acc: 0.9127 - val_loss: 0.0136 - val_acc: 0.8648\n",
            "Epoch 15/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0090 - acc: 0.9065 - val_loss: 0.0135 - val_acc: 0.8633\n",
            "Epoch 16/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0088 - acc: 0.9151 - val_loss: 0.0134 - val_acc: 0.8633\n",
            "Epoch 17/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0085 - acc: 0.9185 - val_loss: 0.0131 - val_acc: 0.8648\n",
            "Epoch 18/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0080 - acc: 0.9279 - val_loss: 0.0130 - val_acc: 0.8664\n",
            "Epoch 19/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0078 - acc: 0.9216 - val_loss: 0.0128 - val_acc: 0.8648\n",
            "Epoch 20/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0076 - acc: 0.9204 - val_loss: 0.0127 - val_acc: 0.8679\n",
            "Epoch 21/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0075 - acc: 0.9127 - val_loss: 0.0129 - val_acc: 0.8633\n",
            "Epoch 22/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0067 - acc: 0.9272 - val_loss: 0.0128 - val_acc: 0.8679\n",
            "Epoch 23/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0067 - acc: 0.9329 - val_loss: 0.0125 - val_acc: 0.8725\n",
            "Epoch 24/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0062 - acc: 0.9313 - val_loss: 0.0125 - val_acc: 0.8725\n",
            "Epoch 25/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0060 - acc: 0.9341 - val_loss: 0.0125 - val_acc: 0.8694\n",
            "Epoch 26/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0062 - acc: 0.9285 - val_loss: 0.0123 - val_acc: 0.8725\n",
            "Epoch 27/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0058 - acc: 0.9274 - val_loss: 0.0123 - val_acc: 0.8756\n",
            "Epoch 28/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0055 - acc: 0.9276 - val_loss: 0.0124 - val_acc: 0.8725\n",
            "Epoch 29/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0053 - acc: 0.9254 - val_loss: 0.0123 - val_acc: 0.8740\n",
            "Epoch 30/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0050 - acc: 0.9343 - val_loss: 0.0123 - val_acc: 0.8740\n",
            "Epoch 31/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0049 - acc: 0.9283 - val_loss: 0.0120 - val_acc: 0.8756\n",
            "Epoch 32/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0044 - acc: 0.9340 - val_loss: 0.0122 - val_acc: 0.8725\n",
            "Epoch 33/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0044 - acc: 0.9316 - val_loss: 0.0120 - val_acc: 0.8725\n",
            "Epoch 34/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0043 - acc: 0.9332 - val_loss: 0.0121 - val_acc: 0.8710\n",
            "Epoch 35/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0043 - acc: 0.9289 - val_loss: 0.0122 - val_acc: 0.8756\n",
            "Epoch 36/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0040 - acc: 0.9305 - val_loss: 0.0121 - val_acc: 0.8740\n",
            "Epoch 37/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0039 - acc: 0.9297 - val_loss: 0.0121 - val_acc: 0.8740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v-jwVi5sCPa"
      },
      "source": [
        "layer_names = [layer.name for layer in default_densenet.layers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z1gMLWQbYK4"
      },
      "source": [
        "layer_idx = layer_names.index('conv5_block1_0_bn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0PDYu31bYob"
      },
      "source": [
        "for layer in default_densenet.layers[layer_idx:]:\n",
        "  layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFab0v9EvQNe"
      },
      "source": [
        "# A new learning rate is defined, since a keras guide (https://keras.io/guides/transfer_learning/) suggests to lower it. Search for \"It's also critical to use a very low learning\"\n",
        "new_lr = 1e-5\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=new_lr, decay=new_lr / epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMHFisDXvnxf"
      },
      "source": [
        "# Compile model\n",
        "dp_model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVu7Ze1cvufk",
        "outputId": "07f513df-504f-4436-fc0b-715ab8911bda"
      },
      "source": [
        "history_fined = dp_model.fit(train_generator, epochs = epochs, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "82/82 [==============================] - 34s 319ms/step - loss: 0.0080 - acc: 0.9060 - val_loss: 0.0124 - val_acc: 0.8694\n",
            "Epoch 2/100\n",
            "82/82 [==============================] - 24s 288ms/step - loss: 0.0069 - acc: 0.9212 - val_loss: 0.0123 - val_acc: 0.8710\n",
            "Epoch 3/100\n",
            "82/82 [==============================] - 24s 289ms/step - loss: 0.0063 - acc: 0.9254 - val_loss: 0.0122 - val_acc: 0.8740\n",
            "Epoch 4/100\n",
            "82/82 [==============================] - 24s 289ms/step - loss: 0.0057 - acc: 0.9271 - val_loss: 0.0121 - val_acc: 0.8771\n",
            "Epoch 5/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0054 - acc: 0.9317 - val_loss: 0.0119 - val_acc: 0.8802\n",
            "Epoch 6/100\n",
            "82/82 [==============================] - 24s 290ms/step - loss: 0.0051 - acc: 0.9317 - val_loss: 0.0119 - val_acc: 0.8802\n",
            "Epoch 7/100\n",
            "82/82 [==============================] - 24s 290ms/step - loss: 0.0045 - acc: 0.9373 - val_loss: 0.0118 - val_acc: 0.8802\n",
            "Epoch 8/100\n",
            "82/82 [==============================] - 24s 290ms/step - loss: 0.0045 - acc: 0.9252 - val_loss: 0.0118 - val_acc: 0.8802\n",
            "Epoch 9/100\n",
            "82/82 [==============================] - 24s 292ms/step - loss: 0.0048 - acc: 0.9222 - val_loss: 0.0117 - val_acc: 0.8802\n",
            "Epoch 10/100\n",
            "82/82 [==============================] - 24s 290ms/step - loss: 0.0043 - acc: 0.9305 - val_loss: 0.0117 - val_acc: 0.8802\n",
            "Epoch 11/100\n",
            "82/82 [==============================] - 24s 289ms/step - loss: 0.0039 - acc: 0.9300 - val_loss: 0.0116 - val_acc: 0.8802\n",
            "Epoch 12/100\n",
            "82/82 [==============================] - 24s 291ms/step - loss: 0.0037 - acc: 0.9305 - val_loss: 0.0116 - val_acc: 0.8802\n",
            "Epoch 13/100\n",
            "82/82 [==============================] - 24s 290ms/step - loss: 0.0035 - acc: 0.9305 - val_loss: 0.0116 - val_acc: 0.8802\n",
            "Epoch 14/100\n",
            "82/82 [==============================] - 24s 291ms/step - loss: 0.0032 - acc: 0.9347 - val_loss: 0.0116 - val_acc: 0.8802\n",
            "Epoch 15/100\n",
            "82/82 [==============================] - 24s 291ms/step - loss: 0.0031 - acc: 0.9326 - val_loss: 0.0115 - val_acc: 0.8802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_DnMIX3wtUi",
        "outputId": "62406529-1692-47e3-c5b6-9fb33d5ccedf"
      },
      "source": [
        "# Now lets use the validation images to create a submission file and evaluate it.\n",
        "val_x_predict = []\n",
        "validation_images_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images'\n",
        "\n",
        "for image in tqdm(os.listdir(validation_images_path), position= 0):\n",
        "  path_to_image = os.path.join(validation_images_path, image)\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_to_image, target_size = (224,224)) # Load actual image\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img) # Transform image to array of shape (input_shape)\n",
        "  img = tf.keras.applications.densenet.preprocess_input(img) # This preprocess_input normalizes the pixel values based on imagenet dataset and rescale to a 0-1 values.\n",
        "  val_x_predict.append(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:04<00:00, 120.93it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwAzbYadxflw"
      },
      "source": [
        "val_x_predict = np.array(val_x_predict) # A numpy array is needed as input for the model\n",
        "val_predictions = dp_model.predict(val_x_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8s5RxD-xtsF"
      },
      "source": [
        "# Use previous threshold with better f1-score\n",
        "val_predictions[val_predictions>=0.4] = 1\n",
        "val_predictions[val_predictions<0.4] = 0\n",
        "val_labels_predicted = mlb.inverse_transform(val_predictions) #This returns a list of tuples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV3pAuHiyEsl",
        "outputId": "0ec03d13-d307-4a0c-e078-6b39cfc1482c"
      },
      "source": [
        "# The concept(s) are needed as strings separated by ; if applicable\n",
        "val_labels_united = []\n",
        "for prediction in val_labels_predicted:\n",
        "  str_concepts = ''\n",
        "  for concept in prediction:\n",
        "    str_concepts += concept+';'\n",
        "  val_labels_united.append(str_concepts[0:-1])\n",
        "\n",
        "# The image id needs to be included in the submission\n",
        "val_images_ids = []\n",
        "for image in tqdm(os.listdir(validation_images_path), position= 0):\n",
        "  val_images_ids.append(image.split('.')[0])\n",
        "\n",
        "# Pass to df  to use to_csv function\n",
        "predictions_df = pd.DataFrame({'image_ids': val_images_ids})\n",
        "predictions_df['predictions'] = pd.Series(val_labels_united)\n",
        "predictions_df.to_csv('/content/mlcf-best-model-dp-only-dp-labels.csv', index= False, sep ='\\t', header= False) # Dont include headers, and image_id and concepts need to be separated by tab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 190615.52it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RitYnPOWyTtz"
      },
      "source": [
        "dp_model.save('dp-classifier-partial-unfreeze-threshold40-use-for-predictions.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGdAx29UfS48"
      },
      "source": [
        "with open(\"mlb_dp_classifier.pkl\", 'wb') as f:\n",
        "    pickle.dump(mlb, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ij0MTvCf5pk"
      },
      "source": [
        "## Using 2021 data only (only with bpo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpQYmO2hgI8P"
      },
      "source": [
        "# Utils functions\n",
        "def extract_concepts(root_paths, image_id_concepts_dict = dict()):\n",
        "\n",
        "    for idx, name in enumerate(root_paths):\n",
        "      with open(name, \"r\", encoding= 'utf-8-sig') as f:\n",
        "        reader = csv.reader(f, delimiter = '\\t')\n",
        "        \n",
        "        if name == '/content/training-images-concepts-by-semantic/concepts-file/training-concepts-bpo-only.csv':\n",
        "          image_path = '/content/ImageCLEF2021_ConceptDetection_Training-Set/ImageCLEF2021_ConceptDetection_Training-Set/Training-Images/'\n",
        "        else:\n",
        "          image_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images/'\n",
        "        for i, line in enumerate(reader):\n",
        "          if len(line[1]) < 1:\n",
        "            image_id_concepts_dict[image_path+line[0]+'.jpg'] = []\n",
        "          else:\n",
        "            image_id_concepts_dict[image_path+line[0]+'.jpg'] = list(line[1].split(';'))\n",
        "\n",
        "    return image_id_concepts_dict\n",
        "\n",
        "\n",
        "def transform_images(path_to_image):\n",
        "  #path_to_image = os.path.join(training_images_dir, image)\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_to_image, target_size= (224,224))\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img = tf.keras.applications.densenet.preprocess_input(img)\n",
        "\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MumzZYjIgI_W"
      },
      "source": [
        "# Path and csv name to concepts file for training and validation images\n",
        "path_to_concepts = ['/content/training-images-concepts-by-semantic/concepts-file/training-concepts-bpo-only.csv',\n",
        "                    '/content/val-concepts-bpo-only.csv']\n",
        "\n",
        "#Extract concepts for the validation and training images and save to dict\n",
        "image_id_concepts_dict = extract_concepts(path_to_concepts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn5znk8bgJCS"
      },
      "source": [
        "# Define array where images array will be saved for training, and where the concepts for each image will be saved (Y)\n",
        "X = []\n",
        "Y = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tseTR0DLgJFY"
      },
      "source": [
        "# Load images\n",
        "for image in image_id_concepts_dict.keys():\n",
        "  X.append(transform_images(image))\n",
        "  Y.append(image_id_concepts_dict[image])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Tha0GShGOq",
        "outputId": "139821b1-8193-4eeb-82ac-0310e84e76d8"
      },
      "source": [
        "# Transform arrays to numpy arrays\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1q_mnOchGR4",
        "outputId": "2cb9bdd1-67ef-4541-9e95-1bf1b72fc393"
      },
      "source": [
        "# Use a multilabelbinarizer to transform the concepts into a binary format for training\n",
        "mlb = MultiLabelBinarizer()\n",
        "Y = mlb.fit_transform(Y)\n",
        "print(len(mlb.classes_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkGy1pwoh2i3"
      },
      "source": [
        "Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4BCE5anh2jE"
      },
      "source": [
        "default_densenet = tf.keras.applications.densenet.DenseNet121(include_top=False, weights= 'imagenet') # Load model (only feature extraction part) with imagenet weights\n",
        "default_densenet.trainable = False # Freeze all layers of the model, so weights remain the same when training, and only weights from added layers update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSGKaWGch2jF"
      },
      "source": [
        "# Adding the classification part to the existing model\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(default_densenet.output)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(len(mlb.classes_), activation='sigmoid', name = 'prediction_layer')(x)\n",
        "\n",
        "\n",
        "bpo_model = tf.keras.models.Model(inputs = default_densenet.input, outputs= x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puxVeuJVh2jF"
      },
      "source": [
        "# Define some required parameter for training\n",
        "init_lr = 1e-4\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "valid_batch_size = 32\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=init_lr, decay=init_lr / epochs)\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 5, restore_best_weights= True, mode = 'max')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2d_Jtmnh2jF"
      },
      "source": [
        "# Compile model\n",
        "bpo_model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9lCANvqh2jG"
      },
      "source": [
        "# Data generator to be used for training\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2)\n",
        "train_generator = data_generator.flow(X, Y, batch_size = 32, subset = 'training', seed = 14)\n",
        "val_generator = data_generator.flow(X, Y, batch_size = 32, subset = 'validation', seed = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycUV3S4Bh2jG",
        "outputId": "a86967ff-3480-44bf-c3b7-30363a0daaa3"
      },
      "source": [
        "history = bpo_model.fit(train_generator, epochs = epochs, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "82/82 [==============================] - 63s 321ms/step - loss: 0.4465 - acc: 3.2262e-04 - val_loss: 0.0152 - val_acc: 0.0031\n",
            "Epoch 2/100\n",
            "82/82 [==============================] - 21s 258ms/step - loss: 0.0138 - acc: 0.0024 - val_loss: 0.0106 - val_acc: 0.0123\n",
            "Epoch 3/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0118 - acc: 0.0182 - val_loss: 0.0101 - val_acc: 0.0108\n",
            "Epoch 4/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0112 - acc: 0.0259 - val_loss: 0.0100 - val_acc: 0.0138\n",
            "Epoch 5/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0109 - acc: 0.0268 - val_loss: 0.0099 - val_acc: 0.0215\n",
            "Epoch 6/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0106 - acc: 0.0241 - val_loss: 0.0098 - val_acc: 0.0246\n",
            "Epoch 7/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0106 - acc: 0.0345 - val_loss: 0.0097 - val_acc: 0.0338\n",
            "Epoch 8/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0105 - acc: 0.0482 - val_loss: 0.0096 - val_acc: 0.0369\n",
            "Epoch 9/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0103 - acc: 0.0487 - val_loss: 0.0096 - val_acc: 0.0430\n",
            "Epoch 10/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0103 - acc: 0.0624 - val_loss: 0.0095 - val_acc: 0.0538\n",
            "Epoch 11/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0098 - acc: 0.0719 - val_loss: 0.0094 - val_acc: 0.0584\n",
            "Epoch 12/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0099 - acc: 0.0793 - val_loss: 0.0093 - val_acc: 0.0584\n",
            "Epoch 13/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0097 - acc: 0.0931 - val_loss: 0.0092 - val_acc: 0.0707\n",
            "Epoch 14/100\n",
            "82/82 [==============================] - 21s 262ms/step - loss: 0.0094 - acc: 0.0949 - val_loss: 0.0091 - val_acc: 0.0737\n",
            "Epoch 15/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0093 - acc: 0.0950 - val_loss: 0.0091 - val_acc: 0.0876\n",
            "Epoch 16/100\n",
            "82/82 [==============================] - 21s 259ms/step - loss: 0.0092 - acc: 0.1116 - val_loss: 0.0090 - val_acc: 0.0768\n",
            "Epoch 17/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0091 - acc: 0.1140 - val_loss: 0.0089 - val_acc: 0.0876\n",
            "Epoch 18/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0089 - acc: 0.1322 - val_loss: 0.0088 - val_acc: 0.0814\n",
            "Epoch 19/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0086 - acc: 0.1426 - val_loss: 0.0087 - val_acc: 0.0845\n",
            "Epoch 20/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0084 - acc: 0.1528 - val_loss: 0.0086 - val_acc: 0.0937\n",
            "Epoch 21/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0080 - acc: 0.1669 - val_loss: 0.0085 - val_acc: 0.0906\n",
            "Epoch 22/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0081 - acc: 0.1719 - val_loss: 0.0084 - val_acc: 0.1075\n",
            "Epoch 23/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0081 - acc: 0.1895 - val_loss: 0.0084 - val_acc: 0.1045\n",
            "Epoch 24/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0077 - acc: 0.1870 - val_loss: 0.0083 - val_acc: 0.1183\n",
            "Epoch 25/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0074 - acc: 0.2126 - val_loss: 0.0082 - val_acc: 0.1152\n",
            "Epoch 26/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0074 - acc: 0.2369 - val_loss: 0.0082 - val_acc: 0.1244\n",
            "Epoch 27/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0069 - acc: 0.2346 - val_loss: 0.0081 - val_acc: 0.1229\n",
            "Epoch 28/100\n",
            "82/82 [==============================] - 21s 262ms/step - loss: 0.0071 - acc: 0.2485 - val_loss: 0.0080 - val_acc: 0.1336\n",
            "Epoch 29/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0069 - acc: 0.2696 - val_loss: 0.0080 - val_acc: 0.1167\n",
            "Epoch 30/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0066 - acc: 0.2798 - val_loss: 0.0080 - val_acc: 0.1260\n",
            "Epoch 31/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0065 - acc: 0.2805 - val_loss: 0.0079 - val_acc: 0.1367\n",
            "Epoch 32/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0061 - acc: 0.2994 - val_loss: 0.0079 - val_acc: 0.1429\n",
            "Epoch 33/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0060 - acc: 0.3033 - val_loss: 0.0078 - val_acc: 0.1459\n",
            "Epoch 34/100\n",
            "82/82 [==============================] - 21s 262ms/step - loss: 0.0057 - acc: 0.3436 - val_loss: 0.0078 - val_acc: 0.1475\n",
            "Epoch 35/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0057 - acc: 0.3409 - val_loss: 0.0077 - val_acc: 0.1459\n",
            "Epoch 36/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0056 - acc: 0.3411 - val_loss: 0.0077 - val_acc: 0.1459\n",
            "Epoch 37/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0053 - acc: 0.3544 - val_loss: 0.0077 - val_acc: 0.1459\n",
            "Epoch 38/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0052 - acc: 0.3682 - val_loss: 0.0076 - val_acc: 0.1567\n",
            "Epoch 39/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0050 - acc: 0.4000 - val_loss: 0.0076 - val_acc: 0.1536\n",
            "Epoch 40/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0049 - acc: 0.4106 - val_loss: 0.0076 - val_acc: 0.1736\n",
            "Epoch 41/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0049 - acc: 0.4111 - val_loss: 0.0076 - val_acc: 0.1690\n",
            "Epoch 42/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0046 - acc: 0.4170 - val_loss: 0.0076 - val_acc: 0.1644\n",
            "Epoch 43/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0045 - acc: 0.4184 - val_loss: 0.0075 - val_acc: 0.1843\n",
            "Epoch 44/100\n",
            "82/82 [==============================] - 21s 261ms/step - loss: 0.0043 - acc: 0.4562 - val_loss: 0.0075 - val_acc: 0.1659\n",
            "Epoch 45/100\n",
            "82/82 [==============================] - 21s 260ms/step - loss: 0.0042 - acc: 0.4745 - val_loss: 0.0075 - val_acc: 0.1797\n",
            "Epoch 46/100\n",
            "82/82 [==============================] - 21s 262ms/step - loss: 0.0042 - acc: 0.4667 - val_loss: 0.0075 - val_acc: 0.1782\n",
            "Epoch 47/100\n",
            "82/82 [==============================] - 22s 263ms/step - loss: 0.0038 - acc: 0.4726 - val_loss: 0.0075 - val_acc: 0.1843\n",
            "Epoch 48/100\n",
            "82/82 [==============================] - 22s 264ms/step - loss: 0.0039 - acc: 0.4837 - val_loss: 0.0074 - val_acc: 0.1828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M_MkP1hh2jH"
      },
      "source": [
        "layer_names = [layer.name for layer in default_densenet.layers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UWoGT8Kh2jH"
      },
      "source": [
        "layer_idx = layer_names.index('conv5_block1_0_bn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pptbnU6yh2jH"
      },
      "source": [
        "for layer in default_densenet.layers[layer_idx:]:\n",
        "  layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_duLNlBhh2jI"
      },
      "source": [
        "# A new learning rate is defined, since a keras guide (https://keras.io/guides/transfer_learning/) suggests to lower it. Search for \"It's also critical to use a very low learning\"\n",
        "new_lr = 1e-5\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=new_lr, decay=new_lr / epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4GjLmpmh2jI"
      },
      "source": [
        "# Compile model\n",
        "bpo_model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Coj6kezIh2jI",
        "outputId": "431898c2-e6c8-481d-fc59-c7f3e1432ec3"
      },
      "source": [
        "history_fined = bpo_model.fit(train_generator, epochs = epochs, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "82/82 [==============================] - 35s 321ms/step - loss: 0.0056 - acc: 0.3342 - val_loss: 0.0076 - val_acc: 0.1736\n",
            "Epoch 2/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0052 - acc: 0.3801 - val_loss: 0.0076 - val_acc: 0.1813\n",
            "Epoch 3/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0050 - acc: 0.3898 - val_loss: 0.0076 - val_acc: 0.1720\n",
            "Epoch 4/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0048 - acc: 0.4468 - val_loss: 0.0075 - val_acc: 0.1720\n",
            "Epoch 5/100\n",
            "82/82 [==============================] - 24s 294ms/step - loss: 0.0046 - acc: 0.4490 - val_loss: 0.0075 - val_acc: 0.1751\n",
            "Epoch 6/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0044 - acc: 0.4491 - val_loss: 0.0075 - val_acc: 0.1751\n",
            "Epoch 7/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0043 - acc: 0.4544 - val_loss: 0.0075 - val_acc: 0.1828\n",
            "Epoch 8/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0041 - acc: 0.4607 - val_loss: 0.0074 - val_acc: 0.1859\n",
            "Epoch 9/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0043 - acc: 0.4712 - val_loss: 0.0074 - val_acc: 0.1859\n",
            "Epoch 10/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0039 - acc: 0.4862 - val_loss: 0.0074 - val_acc: 0.1828\n",
            "Epoch 11/100\n",
            "82/82 [==============================] - 24s 294ms/step - loss: 0.0038 - acc: 0.5188 - val_loss: 0.0074 - val_acc: 0.1828\n",
            "Epoch 12/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0037 - acc: 0.5143 - val_loss: 0.0074 - val_acc: 0.1828\n",
            "Epoch 13/100\n",
            "82/82 [==============================] - 24s 296ms/step - loss: 0.0036 - acc: 0.5019 - val_loss: 0.0074 - val_acc: 0.1889\n",
            "Epoch 14/100\n",
            "82/82 [==============================] - 24s 296ms/step - loss: 0.0035 - acc: 0.5301 - val_loss: 0.0073 - val_acc: 0.1905\n",
            "Epoch 15/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0036 - acc: 0.5443 - val_loss: 0.0073 - val_acc: 0.1920\n",
            "Epoch 16/100\n",
            "82/82 [==============================] - 24s 294ms/step - loss: 0.0032 - acc: 0.5297 - val_loss: 0.0073 - val_acc: 0.1951\n",
            "Epoch 17/100\n",
            "82/82 [==============================] - 24s 295ms/step - loss: 0.0032 - acc: 0.5404 - val_loss: 0.0073 - val_acc: 0.1935\n",
            "Epoch 18/100\n",
            "82/82 [==============================] - 24s 293ms/step - loss: 0.0032 - acc: 0.5381 - val_loss: 0.0073 - val_acc: 0.1935\n",
            "Epoch 19/100\n",
            "82/82 [==============================] - 24s 294ms/step - loss: 0.0032 - acc: 0.5371 - val_loss: 0.0073 - val_acc: 0.1905\n",
            "Epoch 20/100\n",
            "82/82 [==============================] - 24s 296ms/step - loss: 0.0031 - acc: 0.5409 - val_loss: 0.0073 - val_acc: 0.1920\n",
            "Epoch 21/100\n",
            "82/82 [==============================] - 24s 293ms/step - loss: 0.0030 - acc: 0.5523 - val_loss: 0.0073 - val_acc: 0.1982\n",
            "Epoch 22/100\n",
            "82/82 [==============================] - 24s 294ms/step - loss: 0.0029 - acc: 0.5616 - val_loss: 0.0073 - val_acc: 0.1982\n",
            "Epoch 23/100\n",
            "82/82 [==============================] - 24s 293ms/step - loss: 0.0028 - acc: 0.5631 - val_loss: 0.0073 - val_acc: 0.1982\n",
            "Epoch 24/100\n",
            "82/82 [==============================] - 24s 294ms/step - loss: 0.0027 - acc: 0.5659 - val_loss: 0.0073 - val_acc: 0.1966\n",
            "Epoch 25/100\n",
            "82/82 [==============================] - 24s 294ms/step - loss: 0.0026 - acc: 0.5791 - val_loss: 0.0073 - val_acc: 0.1982\n",
            "Epoch 26/100\n",
            "82/82 [==============================] - 24s 294ms/step - loss: 0.0026 - acc: 0.5818 - val_loss: 0.0073 - val_acc: 0.1982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Khgkq9OhGbX",
        "outputId": "c03ff609-018a-46a7-ec73-87da285d5689"
      },
      "source": [
        "# Now lets use the validation images to create a submission file and evaluate it.\n",
        "val_x_predict = []\n",
        "validation_images_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images'\n",
        "\n",
        "for image in tqdm(os.listdir(validation_images_path), position= 0):\n",
        "  path_to_image = os.path.join(validation_images_path, image)\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_to_image, target_size = (224,224)) # Load actual image\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img) # Transform image to array of shape (input_shape)\n",
        "  img = tf.keras.applications.densenet.preprocess_input(img) # This preprocess_input normalizes the pixel values based on imagenet dataset and rescale to a 0-1 values.\n",
        "  val_x_predict.append(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:04<00:00, 112.00it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3XFB120hGec"
      },
      "source": [
        "val_x_predict = np.array(val_x_predict) # A numpy array is needed as input for the model\n",
        "val_predictions = bpo_model.predict(val_x_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stsaS98ChGhg"
      },
      "source": [
        "# Use previous threshold with better f1-score\n",
        "val_predictions[val_predictions>=0.1] = 1\n",
        "val_predictions[val_predictions<0.1] = 0\n",
        "val_labels_predicted = mlb.inverse_transform(val_predictions) #This returns a list of tuples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DdHiNNXhGlA",
        "outputId": "4076a5b9-9ff6-4c4b-e410-afcdfd54db4d"
      },
      "source": [
        "# The concept(s) are needed as strings separated by ; if applicable\n",
        "val_labels_united = []\n",
        "for prediction in val_labels_predicted:\n",
        "  str_concepts = ''\n",
        "  for concept in prediction:\n",
        "    str_concepts += concept+';'\n",
        "  val_labels_united.append(str_concepts[0:-1])\n",
        "\n",
        "# The image id needs to be included in the submission\n",
        "val_images_ids = []\n",
        "for image in tqdm(os.listdir(validation_images_path), position= 0):\n",
        "  val_images_ids.append(image.split('.')[0])\n",
        "\n",
        "# Pass to df  to use to_csv function\n",
        "predictions_df = pd.DataFrame({'image_ids': val_images_ids})\n",
        "predictions_df['predictions'] = pd.Series(val_labels_united)\n",
        "predictions_df.to_csv('/content/mlcf-best-model-bpo-only-bpo-labels.csv', index= False, sep ='\\t', header= False) # Dont include headers, and image_id and concepts need to be separated by tab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 339729.79it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_QfpZR3hGoG"
      },
      "source": [
        "bpo_model.save('bpo-classifier-partial-unfreeze-threshold1-use-for-predictions.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImhHsVLLhGrX"
      },
      "source": [
        "with open(\"mlb_bpo_classifier.pkl\", 'wb') as f:\n",
        "    pickle.dump(mlb, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFPZWQTFqGzR"
      },
      "source": [
        "dp_predictions = pd.read_csv('/content/mlcf-best-model-dp-only-dp-labels.csv', header=None, delimiter='\\t', names=['ImageId', 'dp_tags'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqpqp2xYqG2e"
      },
      "source": [
        "bpo_predictions = pd.read_csv('/content/mlcf-best-model-bpo-only-bpo-labels.csv', header=None, delimiter='\\t', names=['ImageId', 'bpo_tags'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMMC_XH6qG8e"
      },
      "source": [
        "dp_bpo_merged = pd.merge(dp_predictions,bpo_predictions, on='ImageId')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdLGvxUHqG_i"
      },
      "source": [
        "dp_bpo_merged['dp_bpo_tags'] = dp_bpo_merged[dp_bpo_merged.columns[1:]].apply(lambda row: ';'.join(row.dropna()), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jsA39zpqUBZ"
      },
      "source": [
        "dp_bpo_merged.to_csv('/content/mlcf-best-models-dp-bpo-labels.csv', index= False, sep ='\\t', header= False, columns=['ImageId','dp_bpo_tags'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAJ1ckUHrEXF"
      },
      "source": [
        "Merging both the dp and bpo predictions gives a 0.5808 f1 score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8SQxv6pQh7o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysawk23LQibf"
      },
      "source": [
        "## Using 2021 data only (only with blr)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQzgFSkXRdE9"
      },
      "source": [
        "# Utils functions\n",
        "def extract_concepts(root_paths, image_id_concepts_dict = dict()):\n",
        "\n",
        "    for idx, name in enumerate(root_paths):\n",
        "      with open(name, \"r\", encoding= 'utf-8-sig') as f:\n",
        "        reader = csv.reader(f, delimiter = '\\t')\n",
        "        \n",
        "        if name == '/content/training-images-concepts-by-semantic/concepts-file/training-concepts-blr-only.csv':\n",
        "          image_path = '/content/ImageCLEF2021_ConceptDetection_Training-Set/ImageCLEF2021_ConceptDetection_Training-Set/Training-Images/'\n",
        "        else:\n",
        "          image_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images/'\n",
        "        for i, line in enumerate(reader):\n",
        "          if len(line[1]) < 1:\n",
        "            image_id_concepts_dict[image_path+line[0]+'.jpg'] = []\n",
        "          else:\n",
        "            image_id_concepts_dict[image_path+line[0]+'.jpg'] = list(line[1].split(';'))\n",
        "\n",
        "    return image_id_concepts_dict\n",
        "\n",
        "\n",
        "def transform_images(path_to_image):\n",
        "  #path_to_image = os.path.join(training_images_dir, image)\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_to_image, target_size= (224,224))\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img = tf.keras.applications.densenet.preprocess_input(img)\n",
        "\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11fdZunwRdFK"
      },
      "source": [
        "# Path and csv name to concepts file for training and validation images\n",
        "path_to_concepts = ['/content/training-images-concepts-by-semantic/concepts-file/training-concepts-blr-only.csv',\n",
        "                    '/content/val-concepts-blr-only.csv']\n",
        "\n",
        "#Extract concepts for the validation and training images and save to dict\n",
        "image_id_concepts_dict = extract_concepts(path_to_concepts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zky7FMPRdFL"
      },
      "source": [
        "# Define array where images array will be saved for training, and where the concepts for each image will be saved (Y)\n",
        "X = []\n",
        "Y = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D68dRRaRdFL"
      },
      "source": [
        "# Load images\n",
        "for image in image_id_concepts_dict.keys():\n",
        "  X.append(transform_images(image))\n",
        "  Y.append(image_id_concepts_dict[image])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-RN15MkRdFL",
        "outputId": "0e6fbb28-43d3-4646-d3e1-33b72d3ec7be"
      },
      "source": [
        "# Transform arrays to numpy arrays\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hKsC_t8RdFM",
        "outputId": "22f96ec2-a6d9-40e3-c3e9-6f8c3b46d5b8"
      },
      "source": [
        "# Use a multilabelbinarizer to transform the concepts into a binary format for training\n",
        "mlb = MultiLabelBinarizer()\n",
        "Y = mlb.fit_transform(Y)\n",
        "print(len(mlb.classes_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEpIXH7wRdFN"
      },
      "source": [
        "Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTZORd5gRdFN",
        "outputId": "d4e4c863-35bd-4b5b-f6d1-3569392c17ab"
      },
      "source": [
        "default_densenet = tf.keras.applications.densenet.DenseNet121(include_top=False, weights= 'imagenet') # Load model (only feature extraction part) with imagenet weights\n",
        "default_densenet.trainable = False # Freeze all layers of the model, so weights remain the same when training, and only weights from added layers update"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO73kWBdRdFN"
      },
      "source": [
        "# Adding the classification part to the existing model\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(default_densenet.output)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(len(mlb.classes_), activation='sigmoid', name = 'prediction_layer')(x)\n",
        "\n",
        "\n",
        "blr_model = tf.keras.models.Model(inputs = default_densenet.input, outputs= x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CXVNph-RdFO"
      },
      "source": [
        "# Define some required parameter for training\n",
        "init_lr = 1e-4\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "valid_batch_size = 32\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=init_lr, decay=init_lr / epochs)\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 5, restore_best_weights= True, mode = 'max')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaxwCivPRdFO"
      },
      "source": [
        "# Compile model\n",
        "blr_model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BEjnB4YRdFO"
      },
      "source": [
        "# Data generator to be used for training\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2)\n",
        "train_generator = data_generator.flow(X, Y, batch_size = 32, subset = 'training', seed = 14)\n",
        "val_generator = data_generator.flow(X, Y, batch_size = 32, subset = 'validation', seed = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj35qJZnRdFO",
        "outputId": "9c0b4eb0-d654-4f5d-e1c0-2ccb77e93bb7"
      },
      "source": [
        "history = blr_model.fit(train_generator, epochs = epochs, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "82/82 [==============================] - 51s 158ms/step - loss: 0.3872 - acc: 0.0118 - val_loss: 0.0140 - val_acc: 0.0722\n",
            "Epoch 2/100\n",
            "82/82 [==============================] - 9s 111ms/step - loss: 0.0124 - acc: 0.1063 - val_loss: 0.0097 - val_acc: 0.1306\n",
            "Epoch 3/100\n",
            "82/82 [==============================] - 9s 113ms/step - loss: 0.0102 - acc: 0.1475 - val_loss: 0.0091 - val_acc: 0.1260\n",
            "Epoch 4/100\n",
            "82/82 [==============================] - 9s 113ms/step - loss: 0.0103 - acc: 0.1251 - val_loss: 0.0089 - val_acc: 0.2473\n",
            "Epoch 5/100\n",
            "82/82 [==============================] - 9s 115ms/step - loss: 0.0094 - acc: 0.1969 - val_loss: 0.0087 - val_acc: 0.1690\n",
            "Epoch 6/100\n",
            "82/82 [==============================] - 9s 115ms/step - loss: 0.0093 - acc: 0.1590 - val_loss: 0.0086 - val_acc: 0.1521\n",
            "Epoch 7/100\n",
            "82/82 [==============================] - 10s 116ms/step - loss: 0.0089 - acc: 0.1882 - val_loss: 0.0085 - val_acc: 0.2012\n",
            "Epoch 8/100\n",
            "82/82 [==============================] - 10s 117ms/step - loss: 0.0085 - acc: 0.1251 - val_loss: 0.0085 - val_acc: 0.3948\n",
            "Epoch 9/100\n",
            "82/82 [==============================] - 9s 116ms/step - loss: 0.0088 - acc: 0.2847 - val_loss: 0.0083 - val_acc: 0.2657\n",
            "Epoch 10/100\n",
            "82/82 [==============================] - 9s 116ms/step - loss: 0.0081 - acc: 0.1865 - val_loss: 0.0082 - val_acc: 0.2396\n",
            "Epoch 11/100\n",
            "82/82 [==============================] - 9s 115ms/step - loss: 0.0081 - acc: 0.2626 - val_loss: 0.0082 - val_acc: 0.1352\n",
            "Epoch 12/100\n",
            "82/82 [==============================] - 9s 115ms/step - loss: 0.0081 - acc: 0.1440 - val_loss: 0.0081 - val_acc: 0.1536\n",
            "Epoch 13/100\n",
            "82/82 [==============================] - 9s 115ms/step - loss: 0.0076 - acc: 0.1964 - val_loss: 0.0080 - val_acc: 0.1889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLV69W40RdFP"
      },
      "source": [
        "layer_names = [layer.name for layer in default_densenet.layers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4ZSRtqsRdFP"
      },
      "source": [
        "layer_idx = layer_names.index('conv5_block1_0_bn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaMSUWwJRdFP"
      },
      "source": [
        "for layer in default_densenet.layers[layer_idx:]:\n",
        "  layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p7AfLE1RdFP"
      },
      "source": [
        "# A new learning rate is defined, since a keras guide (https://keras.io/guides/transfer_learning/) suggests to lower it. Search for \"It's also critical to use a very low learning\"\n",
        "new_lr = 1e-5\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=new_lr, decay=new_lr / epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8omisfjRdFQ"
      },
      "source": [
        "# Compile model\n",
        "blr_model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmmPZ4A0RdFQ",
        "outputId": "98cc8c08-c8aa-4008-f9fc-6bb80c19fdc7"
      },
      "source": [
        "history_fined = blr_model.fit(train_generator, epochs = epochs, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "82/82 [==============================] - 19s 151ms/step - loss: 0.0089 - acc: 0.1989 - val_loss: 0.0084 - val_acc: 0.3164\n",
            "Epoch 2/100\n",
            "82/82 [==============================] - 11s 131ms/step - loss: 0.0083 - acc: 0.2549 - val_loss: 0.0083 - val_acc: 0.2596\n",
            "Epoch 3/100\n",
            "82/82 [==============================] - 11s 133ms/step - loss: 0.0076 - acc: 0.2318 - val_loss: 0.0082 - val_acc: 0.2273\n",
            "Epoch 4/100\n",
            "82/82 [==============================] - 11s 132ms/step - loss: 0.0075 - acc: 0.2314 - val_loss: 0.0081 - val_acc: 0.2058\n",
            "Epoch 5/100\n",
            "82/82 [==============================] - 11s 131ms/step - loss: 0.0071 - acc: 0.2302 - val_loss: 0.0080 - val_acc: 0.2181\n",
            "Epoch 6/100\n",
            "82/82 [==============================] - 11s 130ms/step - loss: 0.0069 - acc: 0.2466 - val_loss: 0.0079 - val_acc: 0.2089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoiVR93TQn58",
        "outputId": "d010d6ed-1a59-4fbe-88ce-0c7a11728bbc"
      },
      "source": [
        "# Now lets use the validation images to create a submission file and evaluate it.\n",
        "val_x_predict = []\n",
        "val_x_ids = []\n",
        "validation_images_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images'\n",
        "\n",
        "for image in tqdm(os.listdir(validation_images_path), position= 0):\n",
        "  path_to_image = os.path.join(validation_images_path, image)\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_to_image, target_size = (224,224)) # Load actual image\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img) # Transform image to array of shape (input_shape)\n",
        "  img = tf.keras.applications.densenet.preprocess_input(img) # This preprocess_input normalizes the pixel values based on imagenet dataset and rescale to a 0-1 values.\n",
        "  val_x_predict.append(img)\n",
        "  val_x_ids.append(image.split('.')[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:03<00:00, 137.20it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc24zzlPQn9A"
      },
      "source": [
        "val_x_predict = np.array(val_x_predict) # A numpy array is needed as input for the model\n",
        "val_predictions = blr_model.predict(val_x_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qlNPMXgUp9w",
        "outputId": "efe67a21-9cd4-4298-d0bc-e034fd6bf597"
      },
      "source": [
        "val_predictions[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.9230539e-03, 6.5643666e-04, 3.9436316e-04, 2.0860463e-04,\n",
              "       5.6231231e-04, 4.0287017e-05, 3.5653258e-04, 2.1965045e-03,\n",
              "       3.2209608e-04, 4.7119358e-03, 1.3389805e-02, 1.6430472e-03,\n",
              "       2.5318735e-03, 1.7232983e-04, 8.8644703e-04, 4.8705048e-04,\n",
              "       9.5687853e-04, 5.0304802e-03, 1.2588501e-04, 1.7467537e-04,\n",
              "       2.1316929e-04, 2.6105015e-04, 6.9832487e-04, 2.5129046e-03,\n",
              "       3.6980954e-04, 3.5331075e-04, 1.4628364e-04, 6.3982472e-04,\n",
              "       3.8793168e-04, 5.7095318e-04, 3.7747432e-04, 2.2042077e-03,\n",
              "       2.3669214e-04, 8.7233551e-04, 8.7851065e-04, 5.1259104e-04,\n",
              "       3.2021333e-05, 2.7847196e-05, 6.6841755e-04, 2.1642186e-04,\n",
              "       1.7088711e-04, 1.7257048e-03, 3.7882547e-04, 8.4804968e-05,\n",
              "       1.6336015e-04, 1.4383319e-03, 1.3294074e-03, 1.0389987e-03,\n",
              "       6.0987956e-04, 1.8747467e-04, 4.1042283e-04, 3.3807885e-04,\n",
              "       3.9068301e-04, 1.0203137e-03, 1.5733196e-04, 7.0605056e-05,\n",
              "       5.3868396e-04, 6.7578820e-03, 1.1992079e-03, 1.1883827e-04,\n",
              "       6.7438459e-04, 5.8424636e-04, 4.8896847e-05, 2.4690072e-04,\n",
              "       3.0139231e-04, 1.2222520e-03, 4.8509132e-04, 2.7347074e-04,\n",
              "       1.4895390e-04, 9.3620975e-04, 1.0336471e-03, 2.9037503e-04,\n",
              "       1.9087376e-04, 2.3069507e-03, 1.5718368e-04, 2.4577969e-04,\n",
              "       2.5200189e-04, 1.2915359e-04, 1.0484598e-03, 4.6952427e-03,\n",
              "       2.3857626e-04, 9.3181916e-05, 2.0264855e-04, 6.3822989e-04,\n",
              "       4.3135305e-04, 1.4189882e-04, 3.7083778e-04, 1.0163604e-04,\n",
              "       3.9221355e-04, 9.4763661e-04, 7.8158692e-04, 2.3953880e-04,\n",
              "       2.4974144e-03, 8.1301830e-04, 9.4711017e-05, 3.5481161e-04,\n",
              "       3.2171706e-04, 7.0768656e-05, 2.3654659e-04, 1.4445082e-03,\n",
              "       2.6834446e-03, 3.0799519e-04, 6.3037983e-04, 1.4741416e-03,\n",
              "       4.4825196e-04, 5.7836398e-03, 7.2706962e-04, 2.4083340e-04,\n",
              "       1.7411363e-03, 6.4251217e-04, 3.7561831e-04, 1.0622446e-04,\n",
              "       6.8209681e-04, 1.2745691e-03, 2.9778891e-04, 3.4731335e-04,\n",
              "       3.4642249e-04, 6.2938296e-04, 5.1958389e-03, 3.7001056e-04,\n",
              "       2.6524902e-04, 6.4358959e-04, 2.5980617e-04, 2.2540949e-03,\n",
              "       7.7490774e-03, 1.5661782e-03, 2.8549968e-03, 2.8045819e-04,\n",
              "       7.1568176e-04, 8.4724475e-04, 5.8760859e-05, 7.0765108e-04,\n",
              "       1.7154040e-03, 1.0993631e-04, 2.1621655e-03, 6.1347277e-04,\n",
              "       2.7743410e-04, 2.3197975e-04, 6.6344842e-04, 2.6057794e-04,\n",
              "       3.2183179e-04, 2.3471555e-03, 8.9707313e-04, 1.1492065e-04,\n",
              "       4.6704322e-04, 4.2421379e-04, 3.5525367e-04, 4.6115596e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldHSX6J_QoA4"
      },
      "source": [
        "# Use previous threshold with better f1-score\n",
        "val_predictions[val_predictions>=0.05] = 1\n",
        "val_predictions[val_predictions<0.05] = 0\n",
        "val_labels_predicted = mlb.inverse_transform(val_predictions) #This returns a list of tuples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzsSAf-kQoDj"
      },
      "source": [
        "# The concept(s) are needed as strings separated by ; if applicable\n",
        "val_labels_united = []\n",
        "for idx,prediction in enumerate(val_labels_predicted):\n",
        "  str_concepts = ''\n",
        "  for concept in prediction:\n",
        "    str_concepts += concept+';'\n",
        "  val_labels_united.append([val_x_ids[idx],str_concepts[0:-1]])\n",
        "\n",
        "\n",
        "# Pass to df  to use to_csv function\n",
        "predictions_df = pd.DataFrame(val_labels_united, columns = ['ImageId','concepts'])\n",
        "predictions_df.to_csv('/content/mlcf-best-model-blr-only-blr-labels.csv', index= False, sep ='\\t', header= False) # Dont include headers, and image_id and concepts need to be separated by tab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY-HitRZQgM4"
      },
      "source": [
        "Merging the previous outputs (dp and bpo) with blr output lower the f1-score on the validation set to 0.567"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hookq9NQoG6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGax_CNMQoJ9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEdKAtPAQoNG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kns8pc7ZDiBH"
      },
      "source": [
        "## Using 2021 + 2020 data (without autoencoders) and only with diagnostic procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE17LZmwD83t"
      },
      "source": [
        "path_to_concepts = ['/content/images-combined-dp-only.csv']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kWGANPYD87G"
      },
      "source": [
        "def extract_concepts_all(root_paths, image_id_concepts_dict = dict()):\n",
        "    for idx, name in enumerate(root_paths):\n",
        "        with open(name, \"r\", encoding= 'utf-8-sig') as f:\n",
        "          reader = csv.reader(f, delimiter = '\\t')\n",
        "          for i, line in enumerate(reader):\n",
        "            if len(line[1])> 1:\n",
        "              image_id_concepts_dict[line[0]] = list(line[1].split(\";\"))\n",
        "            else:\n",
        "              image_id_concepts_dict[line[0]] = []\n",
        "    \n",
        "    return image_id_concepts_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7LG8r7RD895"
      },
      "source": [
        "#Extract concepts for the multiple concept files\n",
        "image_id_concepts_dict = extract_concepts_all(path_to_concepts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmZ7HE49D9A6",
        "outputId": "88e43fc2-e58e-4aec-a46e-2c7d53f84d2e"
      },
      "source": [
        "# Since we are working with around 9K images. We will only load the images absolute path and the concepts to a dataframe and then use a generator to load them during training.\n",
        "# Here, we will create a dataframe with the images path\n",
        "all_images_path = []\n",
        "# Training images\n",
        "for image in tqdm(image_id_concepts_dict.keys(), position = 0):\n",
        "  all_images_path.append([image])\n",
        "df_all_images = pd.DataFrame(all_images_path, columns=['image_path'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 83979/83979 [00:00<00:00, 206828.24it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf6cZpfgay5q",
        "outputId": "97540ba3-ee13-4adc-9cb2-17983413b438"
      },
      "source": [
        "concepts = []\n",
        "for image in tqdm(image_id_concepts_dict.keys(), position=0):\n",
        "  concepts.append(image_id_concepts_dict[image])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 83979/83979 [00:00<00:00, 1116411.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhmvnqtBcIU-"
      },
      "source": [
        "mlb = MultiLabelBinarizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keIfzi0OemEW"
      },
      "source": [
        "# Since we will use flow_from_dataframe in the training, we put both the images absolute path and the encoded labels\n",
        "df_use_densenet = pd.concat([df_all_images, pd.DataFrame(np.array(mlb.fit_transform(concepts)))], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hM7GgHfB3bd",
        "outputId": "6a52036d-d56e-45bb-ff48-8119098963ab"
      },
      "source": [
        "len(mlb.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUj2dE36nbf2"
      },
      "source": [
        "concepts_binarized = np.array(mlb.transform(concepts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiiiEoovH_vx"
      },
      "source": [
        "# Train split dataset, because a portion is needed to set the threshold (to see if to assign the concept or not) and another portion to see the overall f1-score\n",
        "df_use_train, df_test = train_test_split(df_use_densenet, test_size = 0.05, shuffle = True, random_state = 14) # test will be used to get a final f1-score\n",
        "df_train, df_val = train_test_split(df_use_train, test_size=0.05, shuffle=True, random_state=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCYdGppZnpKF"
      },
      "source": [
        "concepts_binarized_use_train, concepts_binarized_test = train_test_split(concepts_binarized, test_size = 0.05, shuffle = True, random_state = 14)\n",
        "concepts_binarized_train, concepts_binarized_val = train_test_split(concepts_binarized_use_train, test_size = 0.05, shuffle = True, random_state = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADYZGiUQgPxr",
        "outputId": "6b3e9fa1-e14c-44a8-eb0b-f7b523d27e9b"
      },
      "source": [
        "print(df_train.shape)\n",
        "print(df_val.shape)\n",
        "print(df_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75791, 231)\n",
            "(3989, 231)\n",
            "(4199, 231)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J256DsiDH_za"
      },
      "source": [
        "default_densenet = tf.keras.applications.densenet.DenseNet121(include_top=False, weights= 'imagenet') # Load model (only feature extraction part) with imagenet weights\n",
        "default_densenet.trainable = False # Freeze all layers of the model, so weights remain the same when training, and only weights from added layers update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq8d8eklH_2R"
      },
      "source": [
        "# Adding the classification part to the existing model\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(default_densenet.output)\n",
        "x = tf.keras.layers.Dense(len(mlb.classes_), activation='sigmoid', name = 'prediction_layer')(x)\n",
        "\n",
        "\n",
        "model = tf.keras.models.Model(inputs = default_densenet.input, outputs= x) # Final model to be trained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9U-t2TiH_5z"
      },
      "source": [
        "# Define some required parameter for training\n",
        "init_lr = 1e-4\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "valid_batch_size = 32\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=init_lr, decay=init_lr / epochs)\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 3, restore_best_weights= True, mode = 'max')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enM_kqD5I7HX"
      },
      "source": [
        "# Compile model\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klcvv7nyI7LK",
        "outputId": "cd0e9c5a-a9ec-4bae-ae75-14da045080a2"
      },
      "source": [
        "# Data generator\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2, rescale=1./255) # This will split the training dataframe, and also rescale the values from loaded images\n",
        "\n",
        "# Train generator\n",
        "train_generator = data_generator.flow_from_dataframe(df_train,x_col='image_path', y_col=df_train.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw',batch_size=64, shuffle=True, seed=14, subset='training')\n",
        "\n",
        "# Validation generator\n",
        "val_generator = data_generator.flow_from_dataframe(df_train,x_col='image_path', y_col=df_train.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw',batch_size=64, shuffle=True, seed=14, subset='validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60633 validated image filenames.\n",
            "Found 15158 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plzMyYTWI7Nr",
        "outputId": "0a9d556b-cd2c-47bc-e504-da368716a10b"
      },
      "source": [
        "# Model training (only the classification layers that have been added)\n",
        "history = model.fit(train_generator, epochs = epochs, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks, batch_size = 64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "948/948 [==============================] - 557s 576ms/step - loss: 0.1587 - acc: 0.3079 - val_loss: 0.0239 - val_acc: 0.6876\n",
            "Epoch 2/100\n",
            "948/948 [==============================] - 537s 567ms/step - loss: 0.0223 - acc: 0.7105 - val_loss: 0.0197 - val_acc: 0.7579\n",
            "Epoch 3/100\n",
            "948/948 [==============================] - 534s 563ms/step - loss: 0.0192 - acc: 0.7639 - val_loss: 0.0181 - val_acc: 0.7954\n",
            "Epoch 4/100\n",
            "948/948 [==============================] - 530s 559ms/step - loss: 0.0179 - acc: 0.7937 - val_loss: 0.0172 - val_acc: 0.7977\n",
            "Epoch 5/100\n",
            "948/948 [==============================] - 525s 554ms/step - loss: 0.0167 - acc: 0.8015 - val_loss: 0.0166 - val_acc: 0.8177\n",
            "Epoch 6/100\n",
            "948/948 [==============================] - 522s 551ms/step - loss: 0.0163 - acc: 0.8151 - val_loss: 0.0162 - val_acc: 0.8173\n",
            "Epoch 7/100\n",
            "948/948 [==============================] - 528s 557ms/step - loss: 0.0159 - acc: 0.8162 - val_loss: 0.0158 - val_acc: 0.8212\n",
            "Epoch 8/100\n",
            "948/948 [==============================] - 535s 565ms/step - loss: 0.0156 - acc: 0.8231 - val_loss: 0.0156 - val_acc: 0.8198\n",
            "Epoch 9/100\n",
            "948/948 [==============================] - 536s 566ms/step - loss: 0.0150 - acc: 0.8213 - val_loss: 0.0154 - val_acc: 0.8184\n",
            "Epoch 10/100\n",
            "948/948 [==============================] - 534s 563ms/step - loss: 0.0150 - acc: 0.8204 - val_loss: 0.0152 - val_acc: 0.8239\n",
            "Epoch 11/100\n",
            "948/948 [==============================] - 534s 563ms/step - loss: 0.0148 - acc: 0.8256 - val_loss: 0.0151 - val_acc: 0.8293\n",
            "Epoch 12/100\n",
            "948/948 [==============================] - 532s 561ms/step - loss: 0.0147 - acc: 0.8237 - val_loss: 0.0150 - val_acc: 0.8287\n",
            "Epoch 13/100\n",
            "948/948 [==============================] - 528s 557ms/step - loss: 0.0145 - acc: 0.8218 - val_loss: 0.0150 - val_acc: 0.8326\n",
            "Epoch 14/100\n",
            "948/948 [==============================] - 527s 556ms/step - loss: 0.0142 - acc: 0.8277 - val_loss: 0.0149 - val_acc: 0.8210\n",
            "Epoch 15/100\n",
            "948/948 [==============================] - 531s 560ms/step - loss: 0.0141 - acc: 0.8266 - val_loss: 0.0148 - val_acc: 0.8126\n",
            "Epoch 16/100\n",
            "948/948 [==============================] - 541s 571ms/step - loss: 0.0142 - acc: 0.8268 - val_loss: 0.0148 - val_acc: 0.8297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peNTJeL_ge3c"
      },
      "source": [
        "layer_names = [layer.name for layer in default_densenet.layers]\n",
        "layer_idx = layer_names.index('conv4_block7_0_bn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4Di_4mXge8j"
      },
      "source": [
        "for layer in default_densenet.layers[layer_idx:]:\n",
        "  layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW9D_5PiI7T6"
      },
      "source": [
        "# A new learning rate is defined, since a keras guide (https://keras.io/guides/transfer_learning/) suggests to lower it. Search for \"It's also critical to use a very low learning\"\n",
        "new_lr = 1e-5\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=init_lr, decay=new_lr / epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uLkX8HKH_8J"
      },
      "source": [
        "# Compile model\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-AgAGthLY11",
        "outputId": "9a19a301-29f2-43d7-a877-841f96f06955"
      },
      "source": [
        "# Model training (of the entire model)\n",
        "history_fined = model.fit(train_generator, epochs = epochs, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "948/948 [==============================] - 718s 745ms/step - loss: 0.0143 - acc: 0.8297 - val_loss: 0.0133 - val_acc: 0.8613\n",
            "Epoch 2/100\n",
            "948/948 [==============================] - 704s 742ms/step - loss: 0.0110 - acc: 0.8639 - val_loss: 0.0133 - val_acc: 0.8652\n",
            "Epoch 3/100\n",
            "948/948 [==============================] - 701s 739ms/step - loss: 0.0089 - acc: 0.8744 - val_loss: 0.0133 - val_acc: 0.8385\n",
            "Epoch 4/100\n",
            "948/948 [==============================] - 701s 740ms/step - loss: 0.0062 - acc: 0.8853 - val_loss: 0.0146 - val_acc: 0.8553\n",
            "Epoch 5/100\n",
            "948/948 [==============================] - 704s 742ms/step - loss: 0.0046 - acc: 0.8874 - val_loss: 0.0159 - val_acc: 0.8560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFUPWvdbSF1p",
        "outputId": "1b3ad00f-c80f-4999-fb0c-f86d185bdff8"
      },
      "source": [
        "val_gen_pred = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) # This will split the training dataframe, and also rescale the values from loaded images\n",
        "\n",
        "# Validation data generator for threshold tunning\n",
        "\n",
        "val_generator_pred = val_gen_pred.flow_from_dataframe(df_val,x_col='image_path', y_col=df_val.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw',batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3989 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IlzaR8SLavn",
        "outputId": "8484f4a6-702b-4367-d1f4-dda79ed49820"
      },
      "source": [
        "# Since the predictions made by the model is a list of probabilities that a particular concept (from the one seen in training) is present, i.e [0.01, 0.5,...]\n",
        "# It is needed to set a threshold for prob (0-1) that maximizes this f1 score.\n",
        "probs = np.arange(0.05,1.0,0.05)\n",
        "scores = []\n",
        "for prob in probs:\n",
        "  preds = model.predict(val_generator_pred) # Use the validation set\n",
        "  preds[preds>=prob] = 1\n",
        "  preds[preds<prob] = 0\n",
        "  scores.append(tuple((f1_score(concepts_binarized_val, preds, average=\"micro\"),prob)))\n",
        "  print(tuple((f1_score(concepts_binarized_val, preds, average=\"micro\"),prob)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.1405668611328035, 0.05)\n",
            "(0.16292392300641614, 0.1)\n",
            "(0.1763962597927723, 0.15000000000000002)\n",
            "(0.1913403162319034, 0.2)\n",
            "(0.18704436575713393, 0.25)\n",
            "(0.19669091427756383, 0.3)\n",
            "(0.1872724625018203, 0.35000000000000003)\n",
            "(0.1949955581877406, 0.4)\n",
            "(0.18706333107955828, 0.45)\n",
            "(0.19473203410475032, 0.5)\n",
            "(0.1936822688494351, 0.55)\n",
            "(0.19885217930820537, 0.6000000000000001)\n",
            "(0.20611941466468425, 0.6500000000000001)\n",
            "(0.20233217774976364, 0.7000000000000001)\n",
            "(0.19413919413919412, 0.7500000000000001)\n",
            "(0.1978974400128401, 0.8)\n",
            "(0.19786269430051814, 0.8500000000000001)\n",
            "(0.20309303657638492, 0.9000000000000001)\n",
            "(0.19704926231557887, 0.9500000000000001)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9smtnoJ7La1u"
      },
      "source": [
        "model.save('mlcf-dp-model-2021-2021-images-latest.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gkCvJU2La4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc288b7b-1cca-41a9-918c-78ff79161bcb"
      },
      "source": [
        "# Lets load all the validation images 2021\n",
        "\n",
        "val_images_path_ids = [] # This list will contain the absolute path of each image and their id\n",
        "validation_images_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images'\n",
        "\n",
        "#Extract images path and images ids\n",
        "for image in tqdm(os.listdir(validation_images_path), position= 0):\n",
        "  path_to_image = os.path.join(validation_images_path, image)\n",
        "  val_images_path_ids.append([path_to_image,image.split('.')[0]])\n",
        "\n",
        "val_images_path_ids_df = pd.DataFrame(val_images_path_ids, columns=['image_path','image_id']) # Dataframe to use in the prediction process"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 180944.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vmELdLEaf98"
      },
      "source": [
        "# Load images using the same preprocessing method used in training\n",
        "val_images_x = []\n",
        "for idx, row in val_images_path_ids_df.iterrows():\n",
        "  path_image = row['image_path']\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_image, target_size = (224,224)) # Load actual image\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)/255 # Transform image to array of shape (input_shape), and normalize values by dividing them over 255\n",
        "  val_images_x.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3q_MYk-agJB"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "val_images_preds = model.predict(np.array(val_images_x)) # Predict\n",
        "val_images_preds[val_images_preds>=0.6500000000000001] = 1\n",
        "val_images_preds[val_images_preds<0.6500000000000001] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6pxfIvSagPb"
      },
      "source": [
        "# Transformation of transformed labels to actual concepts\n",
        "\n",
        "val_labels_predicted = mlb.inverse_transform(val_images_preds) # Use the transformer that was used in the autoencoder model training\n",
        "\n",
        "# Join predicted concepts and separate them by ;\n",
        "val_labels_united = []\n",
        "for prediction in val_labels_predicted:\n",
        "  str_concepts = ''\n",
        "  for concept in prediction:\n",
        "    str_concepts += concept+';'\n",
        "  val_labels_united.append(str_concepts[0:-1])\n",
        "\n",
        "# The image id needs to be included in the submission\n",
        "val_images_ids = []\n",
        "for idx, row in val_images_path_ids_df.iterrows():\n",
        "  val_images_ids.append(row['image_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wypqLh7_agVR"
      },
      "source": [
        "# Create submission csv file that will contain the image_id \\t concepts\n",
        "final_predictions_val = pd.DataFrame({'image_ids': val_images_ids})\n",
        "final_predictions_val['predictions'] = pd.Series(val_labels_united)\n",
        "final_predictions_val.to_csv('/content/predictions-multilabel-classifier-using-all-images.csv', \n",
        "                             index= False, sep ='\\t', header= False) # Dont include headers, and image_id and concepts need to be separated by tab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImA4IIw-dGmH"
      },
      "source": [
        "with open(\"mlb_mlcf_dp_labels_2021_2020.pkl\", 'wb') as f:\n",
        "    pickle.dump(mlb, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0gtRHUUcmij"
      },
      "source": [
        "## Using 2021 + 2020 data (without autoencoders) and only with bpo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMdC4WThdALD"
      },
      "source": [
        "path_to_concepts = ['/content/images-combined-bpo-only.csv']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G1gqE8gdALG"
      },
      "source": [
        "def extract_concepts_all(root_paths, image_id_concepts_dict = dict()):\n",
        "    for idx, name in enumerate(root_paths):\n",
        "        with open(name, \"r\", encoding= 'utf-8-sig') as f:\n",
        "          reader = csv.reader(f, delimiter = '\\t')\n",
        "          for i, line in enumerate(reader):\n",
        "            if len(line[1])> 1:\n",
        "              image_id_concepts_dict[line[0]] = list(line[1].split(\";\"))\n",
        "            else:\n",
        "              image_id_concepts_dict[line[0]] = []\n",
        "    \n",
        "    return image_id_concepts_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O1i0yFhdALH"
      },
      "source": [
        "#Extract concepts for the multiple concept files\n",
        "image_id_concepts_dict = extract_concepts_all(path_to_concepts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SZLuaCveB0a",
        "outputId": "79d2c1ec-2ac3-4808-d096-95a81ebd71be"
      },
      "source": [
        "len(image_id_concepts_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq5fPyF3dALI",
        "outputId": "8f49fe87-e98b-493b-d89a-63cc76cc750c"
      },
      "source": [
        "# Since we are working with around 9K images. We will only load the images absolute path and the concepts to a dataframe and then use a generator to load them during training.\n",
        "# Here, we will create a dataframe with the images path\n",
        "all_images_path = []\n",
        "# Training images\n",
        "for image in tqdm(image_id_concepts_dict.keys(), position = 0):\n",
        "  all_images_path.append([image])\n",
        "df_all_images = pd.DataFrame(all_images_path, columns=['image_path'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 83979/83979 [00:00<00:00, 341298.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEQJVzENdALJ",
        "outputId": "fc73907f-5fa3-4e35-f0ff-800a35a1f8da"
      },
      "source": [
        "concepts = []\n",
        "for image in tqdm(image_id_concepts_dict.keys(), position=0):\n",
        "  concepts.append(image_id_concepts_dict[image])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 83979/83979 [00:00<00:00, 1184447.80it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR04lOqFdALJ"
      },
      "source": [
        "mlb = MultiLabelBinarizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qu91oqydALK"
      },
      "source": [
        "# Since we will use flow_from_dataframe in the training, we put both the images absolute path and the encoded labels\n",
        "df_use_densenet = pd.concat([df_all_images, pd.DataFrame(np.array(mlb.fit_transform(concepts)))], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0aFgMhZd0P5",
        "outputId": "07011cd4-2ec7-4e4b-a629-b13f48b605e6"
      },
      "source": [
        "len(df_use_densenet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfyFMyt2dALK",
        "outputId": "7958033c-6a2a-4728-fb7a-152811a5a4c3"
      },
      "source": [
        "len(mlb.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jps87MQEdALK"
      },
      "source": [
        "concepts_binarized = np.array(mlb.transform(concepts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyqmaSTGdALL"
      },
      "source": [
        "# Train split dataset, because a portion is needed to set the threshold (to see if to assign the concept or not) and another portion to see the overall f1-score\n",
        "df_use_train, df_test = train_test_split(df_use_densenet, test_size = 0.05, shuffle = True, random_state = 14) # test will be used to get a final f1-score\n",
        "df_train, df_val = train_test_split(df_use_train, test_size=0.05, shuffle=True, random_state=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMKAhp2YdALL"
      },
      "source": [
        "concepts_binarized_use_train, concepts_binarized_test = train_test_split(concepts_binarized, test_size = 0.05, shuffle = True, random_state = 14)\n",
        "concepts_binarized_train, concepts_binarized_val = train_test_split(concepts_binarized_use_train, test_size = 0.05, shuffle = True, random_state = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEkD5FcPdALL",
        "outputId": "b0f97149-4cda-4718-d42d-a4b5112b4812"
      },
      "source": [
        "print(df_train.shape)\n",
        "print(df_val.shape)\n",
        "print(df_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75791, 726)\n",
            "(3989, 726)\n",
            "(4199, 726)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhJclPHNdALM"
      },
      "source": [
        "default_densenet = tf.keras.applications.densenet.DenseNet121(include_top=False, weights= 'imagenet') # Load model (only feature extraction part) with imagenet weights\n",
        "default_densenet.trainable = False # Freeze all layers of the model, so weights remain the same when training, and only weights from added layers update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmZXlvtPdALM"
      },
      "source": [
        "# Adding the classification part to the existing model\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(default_densenet.output)\n",
        "x = tf.keras.layers.Dense(len(mlb.classes_), activation='sigmoid', name = 'prediction_layer')(x)\n",
        "\n",
        "\n",
        "model = tf.keras.models.Model(inputs = default_densenet.input, outputs= x) # Final model to be trained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OZQdMXrdALM"
      },
      "source": [
        "# Define some required parameter for training\n",
        "init_lr = 1e-4\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "valid_batch_size = 32\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=init_lr, decay=init_lr / epochs)\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 3, restore_best_weights= True, mode = 'max')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb9xLDeCdALN"
      },
      "source": [
        "# Compile model\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aukotVQPdALN",
        "outputId": "e4c812d1-168f-4213-9f6d-2708ccc94382"
      },
      "source": [
        "# Data generator\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2, rescale=1./255) # This will split the training dataframe, and also rescale the values from loaded images\n",
        "\n",
        "# Train generator\n",
        "train_generator = data_generator.flow_from_dataframe(df_train,x_col='image_path', y_col=df_train.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw',batch_size=64, shuffle=True, seed=14, subset='training')\n",
        "\n",
        "# Validation generator\n",
        "val_generator = data_generator.flow_from_dataframe(df_train,x_col='image_path', y_col=df_train.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw',batch_size=64, shuffle=True, seed=14, subset='validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60633 validated image filenames.\n",
            "Found 15158 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzin2YiRdALO"
      },
      "source": [
        "layer_names = [layer.name for layer in default_densenet.layers]\n",
        "layer_idx = layer_names.index('conv4_block7_0_bn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5_n3OLfdALO"
      },
      "source": [
        "for layer in default_densenet.layers[layer_idx:]:\n",
        "  layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs169Vf1dALO"
      },
      "source": [
        "# A new learning rate is defined, since a keras guide (https://keras.io/guides/transfer_learning/) suggests to lower it. Search for \"It's also critical to use a very low learning\"\n",
        "new_lr = 1e-5\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=init_lr, decay=new_lr / epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NV26mgVdALO"
      },
      "source": [
        "# Compile model\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S005vYrSdALP"
      },
      "source": [
        "# Model training (of the entire model)\n",
        "history_fined = model.fit(train_generator, epochs = epochs, validation_data= val_generator, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f29ug7tJdALP"
      },
      "source": [
        "val_gen_pred = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) # This will split the training dataframe, and also rescale the values from loaded images\n",
        "\n",
        "# Validation data generator for threshold tunning\n",
        "\n",
        "val_generator_pred = val_gen_pred.flow_from_dataframe(df_val,x_col='image_path', y_col=df_val.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw',batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdfQ9m-3dALP"
      },
      "source": [
        "# Since the predictions made by the model is a list of probabilities that a particular concept (from the one seen in training) is present, i.e [0.01, 0.5,...]\n",
        "# It is needed to set a threshold for prob (0-1) that maximizes this f1 score.\n",
        "probs = np.arange(0.05,1.0,0.05)\n",
        "scores = []\n",
        "for prob in probs:\n",
        "  preds = model.predict(val_generator_pred) # Use the validation set\n",
        "  preds[preds>=prob] = 1\n",
        "  preds[preds<prob] = 0\n",
        "  scores.append(tuple((f1_score(concepts_binarized_val, preds, average=\"micro\"),prob)))\n",
        "  print(tuple((f1_score(concepts_binarized_val, preds, average=\"micro\"),prob)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3jMQ-lJdALQ"
      },
      "source": [
        "model.save('mlcf-bpo-model-2021-2021-images-latest.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeZsC909dALQ",
        "outputId": "dc288b7b-1cca-41a9-918c-78ff79161bcb"
      },
      "source": [
        "# Lets load all the validation images 2021\n",
        "\n",
        "val_images_path_ids = [] # This list will contain the absolute path of each image and their id\n",
        "validation_images_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images'\n",
        "\n",
        "#Extract images path and images ids\n",
        "for image in tqdm(os.listdir(validation_images_path), position= 0):\n",
        "  path_to_image = os.path.join(validation_images_path, image)\n",
        "  val_images_path_ids.append([path_to_image,image.split('.')[0]])\n",
        "\n",
        "val_images_path_ids_df = pd.DataFrame(val_images_path_ids, columns=['image_path','image_id']) # Dataframe to use in the prediction process"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 180944.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B-Nxhe9dALQ"
      },
      "source": [
        "# Load images using the same preprocessing method used in training\n",
        "val_images_x = []\n",
        "for idx, row in val_images_path_ids_df.iterrows():\n",
        "  path_image = row['image_path']\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_image, target_size = (224,224)) # Load actual image\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)/255 # Transform image to array of shape (input_shape), and normalize values by dividing them over 255\n",
        "  val_images_x.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0TDoye4dALS"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "val_images_preds = model.predict(np.array(val_images_x)) # Predict\n",
        "val_images_preds[val_images_preds>=0.6500000000000001] = 1\n",
        "val_images_preds[val_images_preds<0.6500000000000001] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7PKfEt1dALS"
      },
      "source": [
        "# Transformation of transformed labels to actual concepts\n",
        "\n",
        "val_labels_predicted = mlb.inverse_transform(val_images_preds) # Use the transformer that was used in the autoencoder model training\n",
        "\n",
        "# Join predicted concepts and separate them by ;\n",
        "val_labels_united = []\n",
        "for prediction in val_labels_predicted:\n",
        "  str_concepts = ''\n",
        "  for concept in prediction:\n",
        "    str_concepts += concept+';'\n",
        "  val_labels_united.append(str_concepts[0:-1])\n",
        "\n",
        "# The image id needs to be included in the submission\n",
        "val_images_ids = []\n",
        "for idx, row in val_images_path_ids_df.iterrows():\n",
        "  val_images_ids.append(row['image_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PyV1_AkdALT"
      },
      "source": [
        "# Create submission csv file that will contain the image_id \\t concepts\n",
        "final_predictions_val = pd.DataFrame({'image_ids': val_images_ids})\n",
        "final_predictions_val['predictions'] = pd.Series(val_labels_united)\n",
        "final_predictions_val.to_csv('/content/predictions-multilabel-classifier-using-all-images-bpo.csv', \n",
        "                             index= False, sep ='\\t', header= False) # Dont include headers, and image_id and concepts need to be separated by tab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Y4cwEHe4PE"
      },
      "source": [
        "with open(\"mlb_mlcf_bpo_labels_2021_2020.pkl\", 'wb') as f:\n",
        "    pickle.dump(mlb, f)t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkbdJIhiBXtO"
      },
      "source": [
        "# Multi-label Classification with autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S1m5WLS_7Cx"
      },
      "source": [
        "## Using 2021 + 2020 data (and using autoencoder trained using all concepts)\n",
        "\n",
        "Right now, when we use MultilabelBinarizer to transform the labels, the final dimension of the vector is around 1585 length (1s and 0s). By using a autoencoder, we are trying to reduce the dimensionality of our labels (output), and what the autoencoder will do, is to learn how to take a set of 1s and 0s, and reproduce those 1s and 0s again. However, the layers within the autoencoder will have a lower dimension. From having a label of length 1585, the encoder will transform it into a vector of 100 (**ENCODED LABELS**), and the decoder will be in charge of transforming that reduce vector into the orriginal one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MkqDRTe5M2P"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnggQzfIAA9C"
      },
      "source": [
        "# Function to extract concepts from the training and validation images from 2021, and also from selected images from 2020 ImageCLEF dataset\n",
        "# These selected images are images that strictly have the same concepts of this year dataset, therefore, 6,556 images from last year dataset are being used\n",
        "def extract_concepts_all(root_paths, image_id_concepts_dict = dict()):\n",
        "    \"\"\"\n",
        "      Function that extract concepts for a concept file (csv and json), and stores them in a dictionary, \n",
        "      where the key is the absolute path of the image and the values are the concepts.\n",
        "\n",
        "      root_paths: a 1-d list that contains the absolute paths of the concept files\n",
        "      image_id_concepts_dict: dictionary that will contain the data from the concepts file\n",
        "\n",
        "      Returns: a dictionary with the absolute images paths as keys and their corresponding concepts as values.\n",
        "\n",
        "    \"\"\"\n",
        "    for idx, name in enumerate(root_paths):\n",
        "      if idx!=2:\n",
        "        with open(name, \"r\", encoding= 'utf-8-sig') as f:\n",
        "          reader = csv.reader(f, delimiter = '\\t')\n",
        "          if name =='/content/Training_Set_Concepts.csv':\n",
        "            path_image = '/content/ImageCLEF2021_ConceptDetection_Training-Set/ImageCLEF2021_ConceptDetection_Training-Set/Training-Images/'\n",
        "\n",
        "          if name == '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation_Set_Concepts.csv':\n",
        "            path_image = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images/'\n",
        "\n",
        "          for i, line in enumerate(reader):\n",
        "            if idx != 2:\n",
        "              \n",
        "              # It is recommended to check where the image has assigned concepts. This is relevant when separating concepts by sematic type\n",
        "              # If the image does not have a concept, an empty list will be passed.\n",
        "              if len(line[1]) < 1:\n",
        "                image_id_concepts_dict[path_image+line[0]+'.jpg'] = []\n",
        "              else:\n",
        "                image_id_concepts_dict[path_image+line[0]+'.jpg'] = list(line[1].split(';'))\n",
        "            else:\n",
        "                if len(line[1]) < 1:\n",
        "                  image_id_concepts_dict[line[0]] = []\n",
        "\n",
        "                else:\n",
        "                  image_id_concepts_dict[line[0]] = list(line[1].split(';'))\n",
        "      else:\n",
        "        # This section is strictly for the selected images from 2020 dataset\n",
        "        images_2020 = json.load(open(name))\n",
        "        for image in images_2020.keys():\n",
        "          if len(images_2020[image]) > 8:\n",
        "            image_id_concepts_dict[image] = images_2020[image].split(';')\n",
        "          else:\n",
        "            image_id_concepts_dict[image] = [images_2020[image]]\n",
        "\n",
        "\n",
        "    return image_id_concepts_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhpYNoLPAA9M"
      },
      "source": [
        "#Extract concepts for the multiple concept files\n",
        "path_to_concepts = ['/content/Training_Set_Concepts.csv','/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation_Set_Concepts.csv',\n",
        "                    '/content/images_2020_to_be_considered.json']\n",
        "image_id_concepts_dict = extract_concepts_all(path_to_concepts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo8b1qUQJgdU",
        "outputId": "8edc7d85-6bda-4336-ff6a-eac6da71e119"
      },
      "source": [
        "# Since we are working with around 9K images. We will only load the images absolute path and the concepts to a dataframe and then use a generator to load them during training.\n",
        "# Here, we will create a dataframe with the images path\n",
        "X = []\n",
        "df_all_images_ids = pd.DataFrame(columns=['image_path'])\n",
        "# Training images\n",
        "for image in tqdm(image_id_concepts_dict.keys(), position = 0):\n",
        "  X.append(image)\n",
        "df_all_images_ids['image_path'] = X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9792/9792 [00:00<00:00, 1593737.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWGDGLNbDmU2"
      },
      "source": [
        "# Transforming and encoding process\n",
        "# Since we need the encoded labels, we will use the transformer used in the autoencoder process\n",
        "\n",
        "#Load transformer\n",
        "with open(\"/content/mlb_autoencoder_all_labels.pkl\", 'rb') as f:\n",
        "    mlb = pickle.load(f)\n",
        "\n",
        "# Put all concepts in a list of lists to be passed to the transformer\n",
        "labels =[]\n",
        "for image in tqdm(image_id_concepts_dict.keys(), position=0):\n",
        "  labels.append(image_id_concepts_dict[image])\n",
        "\n",
        "labels_transformed = mlb.transform(labels) # This will be used to get the encoded labels\n",
        "\n",
        "# Load trained encoder\n",
        "encoder = tf.keras.models.load_model('/content/encoder-all-combined-images.h5', compile=False)\n",
        "\n",
        "# Encode transformed labels\n",
        "Y = np.array(encoder.predict(labels_transformed))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A8SihJLWfsw"
      },
      "source": [
        "# Since we will use flow_from_dataframe in the training, we put both the images absolute path and the encoded labels\n",
        "df_use_densenet = pd.concat([df_all_images_ids, pd.DataFrame(Y)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JQ0Jb-RAA9S"
      },
      "source": [
        "# Train split dataset, because a portion is needed to set the threshold (to see if to assign the concept or not) and another portion to see the overall f1-score\n",
        "df_train, df_test = train_test_split(df_use_densenet, test_size = 0.2, shuffle = True, random_state = 14) # test will be used to get a final f1-score\n",
        "y_train, y_test = train_test_split(Y,test_size = 0.2, shuffle = True, random_state = 14)\n",
        "labels_transformed_train, labels_transformed_test = train_test_split(labels_transformed,test_size = 0.2, shuffle = True, random_state = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V_hiyIF5293"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RipWOgnB5Oyx"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF2QdS7VAA9S"
      },
      "source": [
        "default_densenet = tf.keras.applications.densenet.DenseNet121(include_top=False, weights= 'imagenet') # Load model (only feature extraction part) with imagenet weights\n",
        "default_densenet.trainable = False # Freeze all layers of the model, so weights remain the same when training, and only weights from added layers update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rW8iPvrAA9T"
      },
      "source": [
        "# Adding the classification part to the existing model\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(default_densenet.output)\n",
        "x = tf.keras.layers.Dense(100, activation='sigmoid', name = 'prediction_layer')(x)\n",
        "\n",
        "\n",
        "model = tf.keras.models.Model(inputs = default_densenet.input, outputs= x) # Final model to be trained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xuq7ZToAA9T"
      },
      "source": [
        "# Define some required parameter for training\n",
        "init_lr = 1e-4\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "valid_batch_size = 32\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=init_lr, decay=init_lr / epochs)\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 10, restore_best_weights= True, mode = 'max')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51IG7BblAA9T"
      },
      "source": [
        "# Compile model. Since the output is no longer an array of 1s and 0s, the loss function can change to a different one.\n",
        "model.compile(loss = 'mean_squared_error', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRgk8cFLAA9T"
      },
      "source": [
        "# Data generator\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2, rescale=1./255) # This will split the training dataframe, and also rescale the values from loaded images\n",
        "\n",
        "# Train generator\n",
        "train_generator = data_generator.flow_from_dataframe(df_train,x_col='image_path', y_col=df_train.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw',batch_size=32, shuffle=True, seed=14, subset='training')\n",
        "\n",
        "# Validation generator\n",
        "val_generator = data_generator.flow_from_dataframe(df_train,x_col='image_path', y_col=df_train.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw',batch_size=32, shuffle=True, seed=14, subset='validation')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtmNccmJAA9U",
        "outputId": "3be297c0-ae65-4576-be0b-891528b04dfa"
      },
      "source": [
        "# Model training (only the classification layers that have been added)\n",
        "history = model.fit(train_generator, epochs = epochs, validation_data= val_generator, validation_steps = 20, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "196/196 [==============================] - 87s 265ms/step - loss: 0.3647 - acc: 0.0440 - val_loss: 0.2724 - val_acc: 0.1172\n",
            "Epoch 2/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2724 - acc: 0.1110 - val_loss: 0.2592 - val_acc: 0.1234\n",
            "Epoch 3/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2604 - acc: 0.1269 - val_loss: 0.2418 - val_acc: 0.1203\n",
            "Epoch 4/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2457 - acc: 0.1241 - val_loss: 0.2406 - val_acc: 0.1281\n",
            "Epoch 5/100\n",
            "196/196 [==============================] - 43s 222ms/step - loss: 0.2401 - acc: 0.1333 - val_loss: 0.2364 - val_acc: 0.1078\n",
            "Epoch 6/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2321 - acc: 0.1194 - val_loss: 0.2288 - val_acc: 0.1266\n",
            "Epoch 7/100\n",
            "196/196 [==============================] - 44s 222ms/step - loss: 0.2321 - acc: 0.1219 - val_loss: 0.2315 - val_acc: 0.1016\n",
            "Epoch 8/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2281 - acc: 0.1265 - val_loss: 0.2229 - val_acc: 0.1187\n",
            "Epoch 9/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2224 - acc: 0.1455 - val_loss: 0.2284 - val_acc: 0.1328\n",
            "Epoch 10/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2220 - acc: 0.1466 - val_loss: 0.2246 - val_acc: 0.1625\n",
            "Epoch 11/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2211 - acc: 0.1633 - val_loss: 0.2195 - val_acc: 0.1594\n",
            "Epoch 12/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2181 - acc: 0.1819 - val_loss: 0.2154 - val_acc: 0.1406\n",
            "Epoch 13/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2168 - acc: 0.1841 - val_loss: 0.2159 - val_acc: 0.1578\n",
            "Epoch 14/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2169 - acc: 0.1900 - val_loss: 0.2103 - val_acc: 0.1937\n",
            "Epoch 15/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2160 - acc: 0.2024 - val_loss: 0.2160 - val_acc: 0.1766\n",
            "Epoch 16/100\n",
            "196/196 [==============================] - 44s 222ms/step - loss: 0.2105 - acc: 0.2075 - val_loss: 0.2161 - val_acc: 0.1922\n",
            "Epoch 17/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2103 - acc: 0.2190 - val_loss: 0.2080 - val_acc: 0.2141\n",
            "Epoch 18/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2124 - acc: 0.2138 - val_loss: 0.2165 - val_acc: 0.2141\n",
            "Epoch 19/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2116 - acc: 0.2402 - val_loss: 0.2220 - val_acc: 0.2297\n",
            "Epoch 20/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2101 - acc: 0.2415 - val_loss: 0.2170 - val_acc: 0.2313\n",
            "Epoch 21/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2086 - acc: 0.2555 - val_loss: 0.2121 - val_acc: 0.2453\n",
            "Epoch 22/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2073 - acc: 0.2610 - val_loss: 0.2139 - val_acc: 0.2375\n",
            "Epoch 23/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2098 - acc: 0.2621 - val_loss: 0.2098 - val_acc: 0.2500\n",
            "Epoch 24/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2079 - acc: 0.2694 - val_loss: 0.2071 - val_acc: 0.2609\n",
            "Epoch 25/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2095 - acc: 0.2860 - val_loss: 0.2006 - val_acc: 0.3000\n",
            "Epoch 26/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2046 - acc: 0.2872 - val_loss: 0.2076 - val_acc: 0.2656\n",
            "Epoch 27/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2043 - acc: 0.3012 - val_loss: 0.2107 - val_acc: 0.2688\n",
            "Epoch 28/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2059 - acc: 0.2893 - val_loss: 0.2032 - val_acc: 0.2922\n",
            "Epoch 29/100\n",
            "196/196 [==============================] - 43s 221ms/step - loss: 0.2053 - acc: 0.3025 - val_loss: 0.2038 - val_acc: 0.2953\n",
            "Epoch 30/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2005 - acc: 0.3172 - val_loss: 0.2081 - val_acc: 0.2781\n",
            "Epoch 31/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2020 - acc: 0.3020 - val_loss: 0.2046 - val_acc: 0.2906\n",
            "Epoch 32/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2007 - acc: 0.3038 - val_loss: 0.1999 - val_acc: 0.3000\n",
            "Epoch 33/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2057 - acc: 0.3011 - val_loss: 0.2017 - val_acc: 0.3063\n",
            "Epoch 34/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2033 - acc: 0.3105 - val_loss: 0.2035 - val_acc: 0.3063\n",
            "Epoch 35/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 0.2005 - acc: 0.3115 - val_loss: 0.2064 - val_acc: 0.3328\n",
            "Epoch 36/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2021 - acc: 0.3196 - val_loss: 0.2117 - val_acc: 0.3109\n",
            "Epoch 37/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2025 - acc: 0.3200 - val_loss: 0.2060 - val_acc: 0.3078\n",
            "Epoch 38/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.1999 - acc: 0.3170 - val_loss: 0.2017 - val_acc: 0.3391\n",
            "Epoch 39/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.1992 - acc: 0.3384 - val_loss: 0.2008 - val_acc: 0.3063\n",
            "Epoch 40/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2008 - acc: 0.3198 - val_loss: 0.2014 - val_acc: 0.3219\n",
            "Epoch 41/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2024 - acc: 0.3365 - val_loss: 0.1996 - val_acc: 0.3469\n",
            "Epoch 42/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2001 - acc: 0.3354 - val_loss: 0.2044 - val_acc: 0.3063\n",
            "Epoch 43/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.1967 - acc: 0.3316 - val_loss: 0.2012 - val_acc: 0.3250\n",
            "Epoch 44/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.2002 - acc: 0.3376 - val_loss: 0.1970 - val_acc: 0.3516\n",
            "Epoch 45/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 0.1959 - acc: 0.3203 - val_loss: 0.1971 - val_acc: 0.3344\n",
            "Epoch 46/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2008 - acc: 0.3396 - val_loss: 0.2039 - val_acc: 0.3453\n",
            "Epoch 47/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.1980 - acc: 0.3312 - val_loss: 0.2064 - val_acc: 0.3219\n",
            "Epoch 48/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2021 - acc: 0.3421 - val_loss: 0.2048 - val_acc: 0.3281\n",
            "Epoch 49/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 0.1986 - acc: 0.3267 - val_loss: 0.1997 - val_acc: 0.3281\n",
            "Epoch 50/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.1978 - acc: 0.3388 - val_loss: 0.1992 - val_acc: 0.3484\n",
            "Epoch 51/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.1965 - acc: 0.3424 - val_loss: 0.1955 - val_acc: 0.3203\n",
            "Epoch 52/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 0.1962 - acc: 0.3395 - val_loss: 0.1956 - val_acc: 0.3672\n",
            "Epoch 53/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 0.1949 - acc: 0.3615 - val_loss: 0.1984 - val_acc: 0.3266\n",
            "Epoch 54/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.2000 - acc: 0.3563 - val_loss: 0.1994 - val_acc: 0.3109\n",
            "Epoch 55/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.1968 - acc: 0.3364 - val_loss: 0.1933 - val_acc: 0.3406\n",
            "Epoch 56/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.1958 - acc: 0.3466 - val_loss: 0.1991 - val_acc: 0.3719\n",
            "Epoch 57/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 0.1957 - acc: 0.3596 - val_loss: 0.1915 - val_acc: 0.3328\n",
            "Epoch 58/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.1955 - acc: 0.3330 - val_loss: 0.2011 - val_acc: 0.3438\n",
            "Epoch 59/100\n",
            "196/196 [==============================] - 43s 217ms/step - loss: 0.1945 - acc: 0.3524 - val_loss: 0.2013 - val_acc: 0.3719\n",
            "Epoch 60/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 0.1990 - acc: 0.3603 - val_loss: 0.2084 - val_acc: 0.3234\n",
            "Epoch 61/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 0.1949 - acc: 0.3445 - val_loss: 0.2000 - val_acc: 0.3266\n",
            "Epoch 62/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 0.1950 - acc: 0.3407 - val_loss: 0.1955 - val_acc: 0.3469\n",
            "Epoch 63/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 0.1955 - acc: 0.3523 - val_loss: 0.2000 - val_acc: 0.3141\n",
            "Epoch 64/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 0.1973 - acc: 0.3493 - val_loss: 0.1943 - val_acc: 0.3562\n",
            "Epoch 65/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 0.1944 - acc: 0.3437 - val_loss: 0.2005 - val_acc: 0.3516\n",
            "Epoch 66/100\n",
            "196/196 [==============================] - 43s 217ms/step - loss: 0.1942 - acc: 0.3456 - val_loss: 0.2039 - val_acc: 0.3203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8cnVwQQAA9U"
      },
      "source": [
        "# Now that our classification layer has been trained, we can unfreeze the rest of the model, which are the convolutional blocks\n",
        "default_densenet.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0sXvIWiAA9V"
      },
      "source": [
        "# A new learning rate is defined, since a keras guide (https://keras.io/guides/transfer_learning/) suggests to lower it. Search for \"It's also critical to use a very low learning\"\n",
        "new_lr = 1e-5\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=new_lr, decay=new_lr / epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgWHGdEMAA9V"
      },
      "source": [
        "# Compile model\n",
        "model.compile(loss = 'mean_squared_error', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma5FZXNhAA9V",
        "outputId": "460dbf12-6f79-4bbe-ca0d-80d583f4058c"
      },
      "source": [
        "# Model training (of the entire model)\n",
        "history_fined = model.fit(train_generator, epochs = epochs, validation_data= val_generator, validation_steps = 20, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "196/196 [==============================] - 86s 380ms/step - loss: 0.2214 - acc: 0.2139 - val_loss: 0.1949 - val_acc: 0.3094\n",
            "Epoch 2/100\n",
            "196/196 [==============================] - 72s 366ms/step - loss: 0.1939 - acc: 0.3054 - val_loss: 0.1893 - val_acc: 0.3547\n",
            "Epoch 3/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1776 - acc: 0.3165 - val_loss: 0.1859 - val_acc: 0.3125\n",
            "Epoch 4/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1721 - acc: 0.3485 - val_loss: 0.1932 - val_acc: 0.3266\n",
            "Epoch 5/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1715 - acc: 0.3302 - val_loss: 0.1822 - val_acc: 0.3266\n",
            "Epoch 6/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1632 - acc: 0.3607 - val_loss: 0.1775 - val_acc: 0.3141\n",
            "Epoch 7/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1612 - acc: 0.3637 - val_loss: 0.1824 - val_acc: 0.3141\n",
            "Epoch 8/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1581 - acc: 0.3777 - val_loss: 0.1811 - val_acc: 0.3359\n",
            "Epoch 9/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1605 - acc: 0.3721 - val_loss: 0.1743 - val_acc: 0.3328\n",
            "Epoch 10/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1538 - acc: 0.3944 - val_loss: 0.1706 - val_acc: 0.3500\n",
            "Epoch 11/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1513 - acc: 0.4024 - val_loss: 0.1820 - val_acc: 0.3594\n",
            "Epoch 12/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1529 - acc: 0.4022 - val_loss: 0.1798 - val_acc: 0.3406\n",
            "Epoch 13/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1475 - acc: 0.4164 - val_loss: 0.1872 - val_acc: 0.3797\n",
            "Epoch 14/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1467 - acc: 0.4438 - val_loss: 0.1764 - val_acc: 0.3672\n",
            "Epoch 15/100\n",
            "196/196 [==============================] - 73s 369ms/step - loss: 0.1456 - acc: 0.4474 - val_loss: 0.1970 - val_acc: 0.3625\n",
            "Epoch 16/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1404 - acc: 0.4606 - val_loss: 0.1817 - val_acc: 0.3812\n",
            "Epoch 17/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1414 - acc: 0.4596 - val_loss: 0.1850 - val_acc: 0.4234\n",
            "Epoch 18/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1387 - acc: 0.4873 - val_loss: 0.1977 - val_acc: 0.3672\n",
            "Epoch 19/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1377 - acc: 0.4978 - val_loss: 0.1876 - val_acc: 0.4031\n",
            "Epoch 20/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1399 - acc: 0.5081 - val_loss: 0.1863 - val_acc: 0.4094\n",
            "Epoch 21/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1372 - acc: 0.4968 - val_loss: 0.1864 - val_acc: 0.4016\n",
            "Epoch 22/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1348 - acc: 0.5262 - val_loss: 0.1881 - val_acc: 0.4094\n",
            "Epoch 23/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1343 - acc: 0.5050 - val_loss: 0.1846 - val_acc: 0.4016\n",
            "Epoch 24/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1347 - acc: 0.5257 - val_loss: 0.1773 - val_acc: 0.4031\n",
            "Epoch 25/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1339 - acc: 0.5205 - val_loss: 0.1885 - val_acc: 0.4359\n",
            "Epoch 26/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1305 - acc: 0.5353 - val_loss: 0.1890 - val_acc: 0.4141\n",
            "Epoch 27/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1319 - acc: 0.5322 - val_loss: 0.1798 - val_acc: 0.4250\n",
            "Epoch 28/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1321 - acc: 0.5469 - val_loss: 0.1766 - val_acc: 0.4000\n",
            "Epoch 29/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1321 - acc: 0.5388 - val_loss: 0.1824 - val_acc: 0.4437\n",
            "Epoch 30/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1308 - acc: 0.5374 - val_loss: 0.1801 - val_acc: 0.4250\n",
            "Epoch 31/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1308 - acc: 0.5551 - val_loss: 0.1835 - val_acc: 0.4047\n",
            "Epoch 32/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1302 - acc: 0.5527 - val_loss: 0.1844 - val_acc: 0.4141\n",
            "Epoch 33/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1275 - acc: 0.5644 - val_loss: 0.1794 - val_acc: 0.4250\n",
            "Epoch 34/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1270 - acc: 0.5567 - val_loss: 0.1835 - val_acc: 0.4328\n",
            "Epoch 35/100\n",
            "196/196 [==============================] - 73s 369ms/step - loss: 0.1252 - acc: 0.5844 - val_loss: 0.1854 - val_acc: 0.4391\n",
            "Epoch 36/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1264 - acc: 0.5545 - val_loss: 0.1865 - val_acc: 0.4047\n",
            "Epoch 37/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1265 - acc: 0.5830 - val_loss: 0.1788 - val_acc: 0.4531\n",
            "Epoch 38/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1272 - acc: 0.5842 - val_loss: 0.1985 - val_acc: 0.4328\n",
            "Epoch 39/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1248 - acc: 0.5687 - val_loss: 0.1815 - val_acc: 0.4391\n",
            "Epoch 40/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1271 - acc: 0.5906 - val_loss: 0.1907 - val_acc: 0.4125\n",
            "Epoch 41/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1239 - acc: 0.5937 - val_loss: 0.1806 - val_acc: 0.4078\n",
            "Epoch 42/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1278 - acc: 0.5964 - val_loss: 0.1874 - val_acc: 0.4391\n",
            "Epoch 43/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1238 - acc: 0.5985 - val_loss: 0.1888 - val_acc: 0.4516\n",
            "Epoch 44/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1266 - acc: 0.5872 - val_loss: 0.1871 - val_acc: 0.4406\n",
            "Epoch 45/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1262 - acc: 0.5968 - val_loss: 0.1763 - val_acc: 0.4172\n",
            "Epoch 46/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1261 - acc: 0.6165 - val_loss: 0.1825 - val_acc: 0.4422\n",
            "Epoch 47/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1260 - acc: 0.6137 - val_loss: 0.1894 - val_acc: 0.4547\n",
            "Epoch 48/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1261 - acc: 0.5946 - val_loss: 0.1809 - val_acc: 0.4500\n",
            "Epoch 49/100\n",
            "196/196 [==============================] - 72s 369ms/step - loss: 0.1238 - acc: 0.6087 - val_loss: 0.1839 - val_acc: 0.4094\n",
            "Epoch 50/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1233 - acc: 0.6187 - val_loss: 0.1747 - val_acc: 0.4406\n",
            "Epoch 51/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1210 - acc: 0.6376 - val_loss: 0.1857 - val_acc: 0.4656\n",
            "Epoch 52/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1243 - acc: 0.6205 - val_loss: 0.1904 - val_acc: 0.4484\n",
            "Epoch 53/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1224 - acc: 0.6405 - val_loss: 0.1862 - val_acc: 0.4484\n",
            "Epoch 54/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1239 - acc: 0.6236 - val_loss: 0.1760 - val_acc: 0.4391\n",
            "Epoch 55/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1248 - acc: 0.6467 - val_loss: 0.1813 - val_acc: 0.4672\n",
            "Epoch 56/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1243 - acc: 0.6364 - val_loss: 0.1883 - val_acc: 0.4297\n",
            "Epoch 57/100\n",
            "196/196 [==============================] - 73s 369ms/step - loss: 0.1238 - acc: 0.6466 - val_loss: 0.1837 - val_acc: 0.4406\n",
            "Epoch 58/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1256 - acc: 0.6529 - val_loss: 0.1804 - val_acc: 0.4516\n",
            "Epoch 59/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1256 - acc: 0.6475 - val_loss: 0.1853 - val_acc: 0.4563\n",
            "Epoch 60/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1230 - acc: 0.6338 - val_loss: 0.1792 - val_acc: 0.4453\n",
            "Epoch 61/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1246 - acc: 0.6417 - val_loss: 0.1756 - val_acc: 0.4703\n",
            "Epoch 62/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1200 - acc: 0.6565 - val_loss: 0.1890 - val_acc: 0.4641\n",
            "Epoch 63/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1211 - acc: 0.6606 - val_loss: 0.1750 - val_acc: 0.4531\n",
            "Epoch 64/100\n",
            "196/196 [==============================] - 73s 369ms/step - loss: 0.1225 - acc: 0.6565 - val_loss: 0.1815 - val_acc: 0.4578\n",
            "Epoch 65/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1209 - acc: 0.6615 - val_loss: 0.1835 - val_acc: 0.4406\n",
            "Epoch 66/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 0.1230 - acc: 0.6548 - val_loss: 0.1861 - val_acc: 0.4547\n",
            "Epoch 67/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1254 - acc: 0.6679 - val_loss: 0.1867 - val_acc: 0.4641\n",
            "Epoch 68/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1225 - acc: 0.6549 - val_loss: 0.1832 - val_acc: 0.4328\n",
            "Epoch 69/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1222 - acc: 0.6818 - val_loss: 0.1828 - val_acc: 0.4531\n",
            "Epoch 70/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1227 - acc: 0.6751 - val_loss: 0.1912 - val_acc: 0.4703\n",
            "Epoch 71/100\n",
            "196/196 [==============================] - 73s 370ms/step - loss: 0.1201 - acc: 0.6596 - val_loss: 0.1830 - val_acc: 0.4344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SA8ojWQ6TwR"
      },
      "source": [
        "### Evaluate the model on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOolAW8yjdwK"
      },
      "source": [
        "# Test data generator (same process that it was used in the training generators)\n",
        "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Here, the test split is being used, even though a y_col is being defined, it wont be used when predicting\n",
        "test_generator = test_gen.flow_from_dataframe(df_test,x_col='image_path', y_col=df_test.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw', shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmnd-A-mjd-j"
      },
      "source": [
        "# Predictions\n",
        "predictions = model.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDfDRS0C6CTp"
      },
      "source": [
        "# Decoding predictions\n",
        "# In the preprocessing part, the encoder was used. Now, those encoded predictions need to be decoded into 1s and 0s learned by the autoencoder\n",
        "\n",
        "decoder = tf.keras.models.load_model('/content/decoder-all-combined-images.h5', compile=False) # Load decoder\n",
        "decoded_predictions = decoder.predict(predictions) # Decode predictions\n",
        "\n",
        "# In the process of training the autoencoder, a threshold was tuned to decide what is the value to consider when setting the predictions of the decoder to 1s and 0s\n",
        "# When tunning this value, 0.35... was the one with highest f1 score\n",
        "\n",
        "decoded_predictions[decoded_predictions>=0.35000000000000003] = 1\n",
        "decoded_predictions[decoded_predictions<0.35000000000000003] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuOGdyyu6Z46"
      },
      "source": [
        "# Compute f1-score\n",
        "# A higher f1-score is expected for this, because of combining all the images (train and val 2021 images). However, this score is using unseen data\n",
        "test_f1_score = f1_score(labels_transformed_test, decoded_predictions, average=\"micro\")\n",
        "print('F1-score (on test set): ' + str(test_f1_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vhywf7U7JVC",
        "outputId": "4b783b78-51d2-45e9-c052-23c6b03d6eb4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score (on test set): 0.6639718346590169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkXfmiU97lp0"
      },
      "source": [
        "# Save model\n",
        "model.save('/content/multilabel-classifier-using-autoencoder-all-smt.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDRMbXVh7155"
      },
      "source": [
        "### Create a submission file for evaluation (using evaluate-f1.py script)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj1PyWyE8Dym",
        "outputId": "c30c7cb0-55ac-42df-c07d-7d7d9de53317"
      },
      "source": [
        "# Lets load all the validation images 2021\n",
        "\n",
        "val_images_path_ids = [] # This list will contain the absolute path of each image and their id\n",
        "validation_images_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images'\n",
        "\n",
        "#Extract images path and images ids\n",
        "for image in tqdm(os.listdir(validation_images_path), position= 0):\n",
        "  path_to_image = os.path.join(validation_images_path, image)\n",
        "  val_images_path_ids.append([path_to_image,image.split('.')[0]])\n",
        "\n",
        "val_images_path_ids_df = pd.DataFrame(val_images_path_ids, columns=['image_path','image_id']) # Dataframe to use in the prediction process"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 256312.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Ixk1TA-GNn"
      },
      "source": [
        "# Load images using the same preprocessing method used in training\n",
        "val_images_x = []\n",
        "for idx, row in val_images_path_ids_df.iterrows():\n",
        "  path_image = row['image_path']\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_image, target_size = (224,224)) # Load actual image\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)/255 # Transform image to array of shape (input_shape), and normalize values by dividing them over 255\n",
        "  val_images_x.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GiTp7pc_Z3d"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "val_images_preds = model.predict(np.array(val_images_x)) # Predict\n",
        "decoded_val_predictions = decoder.predict(val_images_preds) # Decode\n",
        "decoded_val_predictions[decoded_val_predictions>=0.35000000000000003] = 1\n",
        "decoded_val_predictions[decoded_val_predictions<0.35000000000000003] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9lkIPtC_0qU"
      },
      "source": [
        "# Transformation of transformed labels to actual concepts\n",
        "\n",
        "val_labels_predicted = mlb.inverse_transform(decoded_val_predictions) # Use the transformer that was used in the autoencoder model training\n",
        "\n",
        "# Join predicted concepts and separate them by ;\n",
        "val_labels_united = []\n",
        "for prediction in val_labels_predicted:\n",
        "  str_concepts = ''\n",
        "  for concept in prediction:\n",
        "    str_concepts += concept+';'\n",
        "  val_labels_united.append(str_concepts[0:-1])\n",
        "\n",
        "# The image id needs to be included in the submission\n",
        "val_images_ids = []\n",
        "for idx, row in val_images_path_ids_df.iterrows():\n",
        "  val_images_ids.append(row['image_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W0oJ8y9AELb"
      },
      "source": [
        "# Create submission csv file that will contain the image_id \\t concepts\n",
        "final_predictions_val = pd.DataFrame({'image_ids': val_images_ids})\n",
        "final_predictions_val['predictions'] = pd.Series(val_labels_united)\n",
        "final_predictions_val.to_csv('/content/predictions-multilabel-classifier-using-autoencoder-all-labels-v1.csv', \n",
        "                             index= False, sep ='\\t', header= False) # Dont include headers, and image_id and concepts need to be separated by tab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVKY9oEcAJRb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdLjT49YFARJ"
      },
      "source": [
        "### Using trained model to generate features for images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p4t1ePHFGOF"
      },
      "source": [
        "auto_encoded_mlcf = tf.keras.models.load_model('/content/multilabel-classifier-using-autoencoder-all-smt.h5', compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgAsZ30VGMuO"
      },
      "source": [
        "get_layer_output = tf.keras.backend.function([auto_encoded_mlcf.layers[0].input],[auto_encoded_mlcf.layers[-2].output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul8oECikFGRT"
      },
      "source": [
        "def feedForward_finetuned(fname,get_layer_output):\n",
        "\n",
        "    img = tf.keras.preprocessing.image.load_img(fname, target_size=(224,224))\n",
        "    x = tf.keras.preprocessing.image.img_to_array(img) / 255\n",
        "    x = np.expand_dims(x, axis = 0)\n",
        "    features = get_layer_output([x])[0]\n",
        "    features = features.flatten()\n",
        "\n",
        "    return features\n",
        "\n",
        "def extract_store_finetuned(path_dir, model, additional_images = None):\n",
        "  \"\"\"\n",
        "    Function that takes a path and passes all the images (inside that directory) to the feedForward function for feature extraction, and then creates\n",
        "    a dataframe containing all features and image ids of the images.\n",
        "    path_dir: full path of the directory that will be searched\n",
        "    model: model to be used for feature extraction\n",
        "\n",
        "    Returns: A pandas DataFrame containing all images and their corresponding features\n",
        "  \"\"\"\n",
        "  id_features_vector = []\n",
        "  print('Extracting features...')\n",
        "\n",
        "  for image in tqdm(os.listdir(path_dir), position= 0, leave = False):\n",
        "    path = os.path.join(path_dir, image)\n",
        "    name_image = os.path.splitext(image)[0]\n",
        "    image_id = int(name_image.replace('synpic',''))\n",
        "\n",
        "    if additional_images == None:\n",
        "      vector = feedForward_finetuned(path, model)\n",
        "      vector = np.insert(vector,0,image_id)\n",
        "      id_features_vector.append(vector)\n",
        "    else:\n",
        "      check_year = [int(2021)]\n",
        "      year_id_vector = np.insert(check_year,0, image_id)\n",
        "      vector = feedForward_finetuned(path, model)\n",
        "      vector = np.insert(vector,0, year_id_vector)\n",
        "      id_features_vector.append(vector)\n",
        "  \n",
        "  if additional_images != None:\n",
        "    images_2020 = json.load(open(additional_images))\n",
        "    check_year = [int(2020)]\n",
        "    for image in images_2020.keys():\n",
        "      path = image\n",
        "      image_id = int(image.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1])\n",
        "      year_id_vector = np.insert(check_year,0,image_id)\n",
        "      print(year_id_vector)\n",
        "      vector = feedForward_finetuned(path, model)\n",
        "      vector = np.insert(vector, 0, year_id_vector)\n",
        "      id_features_vector.append(vector)\n",
        "  else:\n",
        "    pass\n",
        "      \n",
        "  return id_features_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXAiwLw0FGUk",
        "outputId": "7cb0c72d-9991-45a1-e100-d8ddedc09315"
      },
      "source": [
        "# Training set (2021)\n",
        "id_features_vector = extract_store_finetuned('/content/ImageCLEF2021_ConceptDetection_Training-Set/ImageCLEF2021_ConceptDetection_Training-Set/Training-Images', \n",
        "                                             get_layer_output, additional_images = '/content/images_2020_to_be_considered.json')\n",
        "\n",
        "\n",
        "#np.save('/content/features-224-densenet-fined-autoencoded-training-2021.npy', id_features_vector)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2756 [00:00<07:14,  6.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting features...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe truncaron las últimas líneas 5000 del resultado de transmisión.\u001b[0m\n",
            "[1232 2020]\n",
            "[1234 2020]\n",
            "[1236 2020]\n",
            "[1258 2020]\n",
            "[1278 2020]\n",
            "[1281 2020]\n",
            "[1287 2020]\n",
            "[1288 2020]\n",
            "[1294 2020]\n",
            "[1299 2020]\n",
            "[1313 2020]\n",
            "[1319 2020]\n",
            "[1324 2020]\n",
            "[1332 2020]\n",
            "[1334 2020]\n",
            "[1355 2020]\n",
            "[1365 2020]\n",
            "[1373 2020]\n",
            "[1375 2020]\n",
            "[1377 2020]\n",
            "[1399 2020]\n",
            "[1402 2020]\n",
            "[1449 2020]\n",
            "[1453 2020]\n",
            "[1458 2020]\n",
            "[1474 2020]\n",
            "[1477 2020]\n",
            "[1487 2020]\n",
            "[1488 2020]\n",
            "[1495 2020]\n",
            "[1507 2020]\n",
            "[1518 2020]\n",
            "[1519 2020]\n",
            "[1545 2020]\n",
            "[1593 2020]\n",
            "[1595 2020]\n",
            "[1619 2020]\n",
            "[1622 2020]\n",
            "[1639 2020]\n",
            "[1643 2020]\n",
            "[1659 2020]\n",
            "[1680 2020]\n",
            "[1694 2020]\n",
            "[1705 2020]\n",
            "[1710 2020]\n",
            "[1712 2020]\n",
            "[1721 2020]\n",
            "[1745 2020]\n",
            "[1747 2020]\n",
            "[1756 2020]\n",
            "[1774 2020]\n",
            "[1780 2020]\n",
            "[1783 2020]\n",
            "[1787 2020]\n",
            "[1794 2020]\n",
            "[1808 2020]\n",
            "[1821 2020]\n",
            "[1822 2020]\n",
            "[1829 2020]\n",
            "[1842 2020]\n",
            "[1848 2020]\n",
            "[1855 2020]\n",
            "[1860 2020]\n",
            "[1870 2020]\n",
            "[1919 2020]\n",
            "[1920 2020]\n",
            "[1981 2020]\n",
            "[1983 2020]\n",
            "[1985 2020]\n",
            "[1986 2020]\n",
            "[1995 2020]\n",
            "[1996 2020]\n",
            "[2001 2020]\n",
            "[2010 2020]\n",
            "[2013 2020]\n",
            "[2021 2020]\n",
            "[2034 2020]\n",
            "[2037 2020]\n",
            "[2042 2020]\n",
            "[2047 2020]\n",
            "[2054 2020]\n",
            "[2061 2020]\n",
            "[2067 2020]\n",
            "[2071 2020]\n",
            "[2079 2020]\n",
            "[2095 2020]\n",
            "[2097 2020]\n",
            "[2117 2020]\n",
            "[2138 2020]\n",
            "[2140 2020]\n",
            "[2149 2020]\n",
            "[2160 2020]\n",
            "[2163 2020]\n",
            "[2177 2020]\n",
            "[2183 2020]\n",
            "[2190 2020]\n",
            "[2210 2020]\n",
            "[2221 2020]\n",
            "[2225 2020]\n",
            "[2227 2020]\n",
            "[2232 2020]\n",
            "[2242 2020]\n",
            "[2245 2020]\n",
            "[2246 2020]\n",
            "[2249 2020]\n",
            "[2267 2020]\n",
            "[2279 2020]\n",
            "[2285 2020]\n",
            "[2292 2020]\n",
            "[2294 2020]\n",
            "[2330 2020]\n",
            "[2331 2020]\n",
            "[2336 2020]\n",
            "[2348 2020]\n",
            "[2354 2020]\n",
            "[2356 2020]\n",
            "[2401 2020]\n",
            "[2409 2020]\n",
            "[2413 2020]\n",
            "[2439 2020]\n",
            "[2451 2020]\n",
            "[2459 2020]\n",
            "[2461 2020]\n",
            "[2463 2020]\n",
            "[2474 2020]\n",
            "[2476 2020]\n",
            "[2492 2020]\n",
            "[2496 2020]\n",
            "[2502 2020]\n",
            "[2505 2020]\n",
            "[2513 2020]\n",
            "[2529 2020]\n",
            "[2551 2020]\n",
            "[2555 2020]\n",
            "[2560 2020]\n",
            "[2572 2020]\n",
            "[2574 2020]\n",
            "[2587 2020]\n",
            "[2594 2020]\n",
            "[2628 2020]\n",
            "[2639 2020]\n",
            "[2641 2020]\n",
            "[2681 2020]\n",
            "[2694 2020]\n",
            "[2711 2020]\n",
            "[2713 2020]\n",
            "[2719 2020]\n",
            "[2725 2020]\n",
            "[2729 2020]\n",
            "[2736 2020]\n",
            "[2738 2020]\n",
            "[2745 2020]\n",
            "[2748 2020]\n",
            "[2767 2020]\n",
            "[2782 2020]\n",
            "[2785 2020]\n",
            "[2805 2020]\n",
            "[2818 2020]\n",
            "[2874 2020]\n",
            "[2915 2020]\n",
            "[2923 2020]\n",
            "[2928 2020]\n",
            "[2944 2020]\n",
            "[2962 2020]\n",
            "[2976 2020]\n",
            "[2988 2020]\n",
            "[2997 2020]\n",
            "[3003 2020]\n",
            "[3009 2020]\n",
            "[3026 2020]\n",
            "[3037 2020]\n",
            "[3051 2020]\n",
            "[3075 2020]\n",
            "[3084 2020]\n",
            "[3087 2020]\n",
            "[3092 2020]\n",
            "[3098 2020]\n",
            "[3113 2020]\n",
            "[3119 2020]\n",
            "[3142 2020]\n",
            "[3157 2020]\n",
            "[3180 2020]\n",
            "[3184 2020]\n",
            "[3196 2020]\n",
            "[3200 2020]\n",
            "[3203 2020]\n",
            "[3233 2020]\n",
            "[3241 2020]\n",
            "[3266 2020]\n",
            "[3270 2020]\n",
            "[3279 2020]\n",
            "[3320 2020]\n",
            "[3333 2020]\n",
            "[3340 2020]\n",
            "[3370 2020]\n",
            "[3374 2020]\n",
            "[3413 2020]\n",
            "[3415 2020]\n",
            "[3426 2020]\n",
            "[3429 2020]\n",
            "[3433 2020]\n",
            "[3445 2020]\n",
            "[3447 2020]\n",
            "[3451 2020]\n",
            "[3458 2020]\n",
            "[3459 2020]\n",
            "[3516 2020]\n",
            "[3521 2020]\n",
            "[3542 2020]\n",
            "[3554 2020]\n",
            "[3556 2020]\n",
            "[3582 2020]\n",
            "[3601 2020]\n",
            "[3603 2020]\n",
            "[3613 2020]\n",
            "[3616 2020]\n",
            "[3622 2020]\n",
            "[3633 2020]\n",
            "[3637 2020]\n",
            "[3639 2020]\n",
            "[3680 2020]\n",
            "[3689 2020]\n",
            "[3738 2020]\n",
            "[3743 2020]\n",
            "[3763 2020]\n",
            "[3802 2020]\n",
            "[3820 2020]\n",
            "[3825 2020]\n",
            "[3832 2020]\n",
            "[3836 2020]\n",
            "[3838 2020]\n",
            "[3860 2020]\n",
            "[3867 2020]\n",
            "[3873 2020]\n",
            "[3963 2020]\n",
            "[3984 2020]\n",
            "[3989 2020]\n",
            "[4014 2020]\n",
            "[4017 2020]\n",
            "[4018 2020]\n",
            "[4047 2020]\n",
            "[4048 2020]\n",
            "[4085 2020]\n",
            "[4089 2020]\n",
            "[4117 2020]\n",
            "[4118 2020]\n",
            "[4133 2020]\n",
            "[4143 2020]\n",
            "[4163 2020]\n",
            "[4165 2020]\n",
            "[4167 2020]\n",
            "[4183 2020]\n",
            "[4192 2020]\n",
            "[4201 2020]\n",
            "[4210 2020]\n",
            "[4217 2020]\n",
            "[4225 2020]\n",
            "[4229 2020]\n",
            "[4232 2020]\n",
            "[4241 2020]\n",
            "[4269 2020]\n",
            "[4289 2020]\n",
            "[4293 2020]\n",
            "[4298 2020]\n",
            "[4302 2020]\n",
            "[4316 2020]\n",
            "[4354 2020]\n",
            "[4359 2020]\n",
            "[4371 2020]\n",
            "[4399 2020]\n",
            "[4407 2020]\n",
            "[4455 2020]\n",
            "[4456 2020]\n",
            "[4465 2020]\n",
            "[4489 2020]\n",
            "[4529 2020]\n",
            "[4531 2020]\n",
            "[4540 2020]\n",
            "[4555 2020]\n",
            "[4567 2020]\n",
            "[4571 2020]\n",
            "[4578 2020]\n",
            "[4582 2020]\n",
            "[4625 2020]\n",
            "[4630 2020]\n",
            "[4657 2020]\n",
            "[4658 2020]\n",
            "[6409 2020]\n",
            "[6413 2020]\n",
            "[6415 2020]\n",
            "[6424 2020]\n",
            "[6437 2020]\n",
            "[6444 2020]\n",
            "[6446 2020]\n",
            "[6451 2020]\n",
            "[6480 2020]\n",
            "[6486 2020]\n",
            "[6495 2020]\n",
            "[6500 2020]\n",
            "[6505 2020]\n",
            "[6547 2020]\n",
            "[6552 2020]\n",
            "[6561 2020]\n",
            "[6576 2020]\n",
            "[6607 2020]\n",
            "[6608 2020]\n",
            "[6617 2020]\n",
            "[6619 2020]\n",
            "[6628 2020]\n",
            "[6638 2020]\n",
            "[6648 2020]\n",
            "[6661 2020]\n",
            "[6667 2020]\n",
            "[6697 2020]\n",
            "[6698 2020]\n",
            "[6704 2020]\n",
            "[6706 2020]\n",
            "[6713 2020]\n",
            "[6720 2020]\n",
            "[6728 2020]\n",
            "[6732 2020]\n",
            "[6755 2020]\n",
            "[6757 2020]\n",
            "[6776 2020]\n",
            "[6777 2020]\n",
            "[6778 2020]\n",
            "[6779 2020]\n",
            "[6783 2020]\n",
            "[6793 2020]\n",
            "[6800 2020]\n",
            "[6805 2020]\n",
            "[6808 2020]\n",
            "[6811 2020]\n",
            "[6813 2020]\n",
            "[6814 2020]\n",
            "[6822 2020]\n",
            "[6831 2020]\n",
            "[6833 2020]\n",
            "[6839 2020]\n",
            "[6851 2020]\n",
            "[6865 2020]\n",
            "[6868 2020]\n",
            "[6869 2020]\n",
            "[6870 2020]\n",
            "[6873 2020]\n",
            "[6877 2020]\n",
            "[6889 2020]\n",
            "[6894 2020]\n",
            "[6897 2020]\n",
            "[6900 2020]\n",
            "[6908 2020]\n",
            "[6909 2020]\n",
            "[6911 2020]\n",
            "[6930 2020]\n",
            "[6934 2020]\n",
            "[6936 2020]\n",
            "[6939 2020]\n",
            "[6941 2020]\n",
            "[6951 2020]\n",
            "[6969 2020]\n",
            "[6973 2020]\n",
            "[6974 2020]\n",
            "[6983 2020]\n",
            "[6987 2020]\n",
            "[7004 2020]\n",
            "[7008 2020]\n",
            "[7032 2020]\n",
            "[7048 2020]\n",
            "[7052 2020]\n",
            "[7067 2020]\n",
            "[7069 2020]\n",
            "[7086 2020]\n",
            "[7094 2020]\n",
            "[7095 2020]\n",
            "[7098 2020]\n",
            "[7104 2020]\n",
            "[7115 2020]\n",
            "[7116 2020]\n",
            "[7119 2020]\n",
            "[7127 2020]\n",
            "[7129 2020]\n",
            "[7146 2020]\n",
            "[7148 2020]\n",
            "[7156 2020]\n",
            "[7160 2020]\n",
            "[7161 2020]\n",
            "[7162 2020]\n",
            "[7166 2020]\n",
            "[7168 2020]\n",
            "[7178 2020]\n",
            "[7180 2020]\n",
            "[7194 2020]\n",
            "[7199 2020]\n",
            "[7206 2020]\n",
            "[7216 2020]\n",
            "[7217 2020]\n",
            "[7220 2020]\n",
            "[7223 2020]\n",
            "[7235 2020]\n",
            "[7240 2020]\n",
            "[7243 2020]\n",
            "[7245 2020]\n",
            "[7247 2020]\n",
            "[7254 2020]\n",
            "[7259 2020]\n",
            "[7274 2020]\n",
            "[7276 2020]\n",
            "[7280 2020]\n",
            "[7284 2020]\n",
            "[7307 2020]\n",
            "[7310 2020]\n",
            "[7313 2020]\n",
            "[7322 2020]\n",
            "[7325 2020]\n",
            "[7328 2020]\n",
            "[7333 2020]\n",
            "[7347 2020]\n",
            "[7353 2020]\n",
            "[7354 2020]\n",
            "[7366 2020]\n",
            "[7388 2020]\n",
            "[7398 2020]\n",
            "[7404 2020]\n",
            "[7409 2020]\n",
            "[7415 2020]\n",
            "[7417 2020]\n",
            "[7428 2020]\n",
            "[7429 2020]\n",
            "[7436 2020]\n",
            "[7443 2020]\n",
            "[7445 2020]\n",
            "[7457 2020]\n",
            "[7471 2020]\n",
            "[7472 2020]\n",
            "[7475 2020]\n",
            "[7481 2020]\n",
            "[7483 2020]\n",
            "[7489 2020]\n",
            "[7494 2020]\n",
            "[7507 2020]\n",
            "[7508 2020]\n",
            "[7515 2020]\n",
            "[7525 2020]\n",
            "[7528 2020]\n",
            "[7541 2020]\n",
            "[7549 2020]\n",
            "[7560 2020]\n",
            "[7564 2020]\n",
            "[7566 2020]\n",
            "[7567 2020]\n",
            "[7570 2020]\n",
            "[7577 2020]\n",
            "[7589 2020]\n",
            "[7590 2020]\n",
            "[7594 2020]\n",
            "[7611 2020]\n",
            "[7621 2020]\n",
            "[7627 2020]\n",
            "[7630 2020]\n",
            "[7631 2020]\n",
            "[7633 2020]\n",
            "[7636 2020]\n",
            "[7639 2020]\n",
            "[7640 2020]\n",
            "[7658 2020]\n",
            "[7660 2020]\n",
            "[7662 2020]\n",
            "[7675 2020]\n",
            "[7676 2020]\n",
            "[7677 2020]\n",
            "[7686 2020]\n",
            "[7700 2020]\n",
            "[7707 2020]\n",
            "[7717 2020]\n",
            "[7721 2020]\n",
            "[7722 2020]\n",
            "[7739 2020]\n",
            "[7745 2020]\n",
            "[7749 2020]\n",
            "[7763 2020]\n",
            "[7771 2020]\n",
            "[7774 2020]\n",
            "[7789 2020]\n",
            "[7802 2020]\n",
            "[7813 2020]\n",
            "[7817 2020]\n",
            "[7818 2020]\n",
            "[7829 2020]\n",
            "[7836 2020]\n",
            "[7837 2020]\n",
            "[7843 2020]\n",
            "[7845 2020]\n",
            "[7852 2020]\n",
            "[7859 2020]\n",
            "[7872 2020]\n",
            "[7883 2020]\n",
            "[7887 2020]\n",
            "[7893 2020]\n",
            "[7904 2020]\n",
            "[7912 2020]\n",
            "[7913 2020]\n",
            "[7927 2020]\n",
            "[7930 2020]\n",
            "[7950 2020]\n",
            "[7966 2020]\n",
            "[7985 2020]\n",
            "[7988 2020]\n",
            "[7990 2020]\n",
            "[7992 2020]\n",
            "[8003 2020]\n",
            "[8006 2020]\n",
            "[8007 2020]\n",
            "[8017 2020]\n",
            "[8030 2020]\n",
            "[8031 2020]\n",
            "[8039 2020]\n",
            "[8044 2020]\n",
            "[8047 2020]\n",
            "[8062 2020]\n",
            "[8066 2020]\n",
            "[8067 2020]\n",
            "[8073 2020]\n",
            "[8107 2020]\n",
            "[8130 2020]\n",
            "[8133 2020]\n",
            "[8134 2020]\n",
            "[8138 2020]\n",
            "[8141 2020]\n",
            "[8159 2020]\n",
            "[8162 2020]\n",
            "[8164 2020]\n",
            "[8171 2020]\n",
            "[8181 2020]\n",
            "[8186 2020]\n",
            "[8198 2020]\n",
            "[8214 2020]\n",
            "[8215 2020]\n",
            "[8220 2020]\n",
            "[8223 2020]\n",
            "[8242 2020]\n",
            "[8247 2020]\n",
            "[8264 2020]\n",
            "[8270 2020]\n",
            "[8292 2020]\n",
            "[8294 2020]\n",
            "[8303 2020]\n",
            "[8307 2020]\n",
            "[8310 2020]\n",
            "[8321 2020]\n",
            "[8331 2020]\n",
            "[8338 2020]\n",
            "[8361 2020]\n",
            "[8363 2020]\n",
            "[8366 2020]\n",
            "[8373 2020]\n",
            "[8380 2020]\n",
            "[8382 2020]\n",
            "[8385 2020]\n",
            "[8406 2020]\n",
            "[8411 2020]\n",
            "[8419 2020]\n",
            "[8421 2020]\n",
            "[8433 2020]\n",
            "[8435 2020]\n",
            "[8440 2020]\n",
            "[8441 2020]\n",
            "[8442 2020]\n",
            "[8445 2020]\n",
            "[8459 2020]\n",
            "[8465 2020]\n",
            "[8471 2020]\n",
            "[8485 2020]\n",
            "[8490 2020]\n",
            "[8503 2020]\n",
            "[8507 2020]\n",
            "[8518 2020]\n",
            "[8524 2020]\n",
            "[8531 2020]\n",
            "[8543 2020]\n",
            "[8551 2020]\n",
            "[8556 2020]\n",
            "[8572 2020]\n",
            "[8576 2020]\n",
            "[8583 2020]\n",
            "[8589 2020]\n",
            "[8606 2020]\n",
            "[8608 2020]\n",
            "[8609 2020]\n",
            "[8611 2020]\n",
            "[8618 2020]\n",
            "[8624 2020]\n",
            "[8628 2020]\n",
            "[8629 2020]\n",
            "[8640 2020]\n",
            "[8644 2020]\n",
            "[8647 2020]\n",
            "[8661 2020]\n",
            "[8674 2020]\n",
            "[8675 2020]\n",
            "[8676 2020]\n",
            "[8678 2020]\n",
            "[8679 2020]\n",
            "[8686 2020]\n",
            "[8698 2020]\n",
            "[8707 2020]\n",
            "[8716 2020]\n",
            "[8717 2020]\n",
            "[8721 2020]\n",
            "[8727 2020]\n",
            "[8730 2020]\n",
            "[8736 2020]\n",
            "[8742 2020]\n",
            "[8745 2020]\n",
            "[8755 2020]\n",
            "[8768 2020]\n",
            "[8776 2020]\n",
            "[8786 2020]\n",
            "[8792 2020]\n",
            "[8794 2020]\n",
            "[8803 2020]\n",
            "[8820 2020]\n",
            "[8821 2020]\n",
            "[8826 2020]\n",
            "[8845 2020]\n",
            "[8847 2020]\n",
            "[8849 2020]\n",
            "[8871 2020]\n",
            "[8874 2020]\n",
            "[8889 2020]\n",
            "[8890 2020]\n",
            "[8896 2020]\n",
            "[8900 2020]\n",
            "[8904 2020]\n",
            "[8906 2020]\n",
            "[8913 2020]\n",
            "[8914 2020]\n",
            "[8918 2020]\n",
            "[8923 2020]\n",
            "[8925 2020]\n",
            "[8931 2020]\n",
            "[8935 2020]\n",
            "[8937 2020]\n",
            "[8958 2020]\n",
            "[8960 2020]\n",
            "[8964 2020]\n",
            "[8969 2020]\n",
            "[8974 2020]\n",
            "[8976 2020]\n",
            "[8978 2020]\n",
            "[8986 2020]\n",
            "[9006 2020]\n",
            "[9008 2020]\n",
            "[9029 2020]\n",
            "[9030 2020]\n",
            "[9033 2020]\n",
            "[9035 2020]\n",
            "[9041 2020]\n",
            "[9048 2020]\n",
            "[9050 2020]\n",
            "[9052 2020]\n",
            "[9054 2020]\n",
            "[9055 2020]\n",
            "[9059 2020]\n",
            "[9077 2020]\n",
            "[9078 2020]\n",
            "[9082 2020]\n",
            "[9085 2020]\n",
            "[9096 2020]\n",
            "[9101 2020]\n",
            "[9121 2020]\n",
            "[9123 2020]\n",
            "[9127 2020]\n",
            "[9140 2020]\n",
            "[9141 2020]\n",
            "[9148 2020]\n",
            "[9149 2020]\n",
            "[9150 2020]\n",
            "[9153 2020]\n",
            "[9170 2020]\n",
            "[9171 2020]\n",
            "[9172 2020]\n",
            "[9177 2020]\n",
            "[9181 2020]\n",
            "[9191 2020]\n",
            "[9193 2020]\n",
            "[9204 2020]\n",
            "[9206 2020]\n",
            "[9207 2020]\n",
            "[9218 2020]\n",
            "[9224 2020]\n",
            "[9227 2020]\n",
            "[9229 2020]\n",
            "[9244 2020]\n",
            "[9267 2020]\n",
            "[9271 2020]\n",
            "[9285 2020]\n",
            "[9292 2020]\n",
            "[9297 2020]\n",
            "[9299 2020]\n",
            "[9303 2020]\n",
            "[9309 2020]\n",
            "[9312 2020]\n",
            "[9320 2020]\n",
            "[9321 2020]\n",
            "[9325 2020]\n",
            "[9333 2020]\n",
            "[9343 2020]\n",
            "[9357 2020]\n",
            "[9368 2020]\n",
            "[9370 2020]\n",
            "[9371 2020]\n",
            "[9376 2020]\n",
            "[9384 2020]\n",
            "[9398 2020]\n",
            "[9411 2020]\n",
            "[9417 2020]\n",
            "[9419 2020]\n",
            "[9422 2020]\n",
            "[9427 2020]\n",
            "[9430 2020]\n",
            "[9431 2020]\n",
            "[9433 2020]\n",
            "[9442 2020]\n",
            "[9452 2020]\n",
            "[9466 2020]\n",
            "[9470 2020]\n",
            "[9479 2020]\n",
            "[9486 2020]\n",
            "[9487 2020]\n",
            "[9493 2020]\n",
            "[9498 2020]\n",
            "[9515 2020]\n",
            "[9516 2020]\n",
            "[9517 2020]\n",
            "[9535 2020]\n",
            "[9537 2020]\n",
            "[9556 2020]\n",
            "[9557 2020]\n",
            "[9563 2020]\n",
            "[9567 2020]\n",
            "[9575 2020]\n",
            "[9585 2020]\n",
            "[9586 2020]\n",
            "[9593 2020]\n",
            "[9606 2020]\n",
            "[9608 2020]\n",
            "[9614 2020]\n",
            "[9621 2020]\n",
            "[9630 2020]\n",
            "[9632 2020]\n",
            "[9636 2020]\n",
            "[9640 2020]\n",
            "[9642 2020]\n",
            "[9649 2020]\n",
            "[9650 2020]\n",
            "[9653 2020]\n",
            "[9662 2020]\n",
            "[9668 2020]\n",
            "[9669 2020]\n",
            "[9672 2020]\n",
            "[9675 2020]\n",
            "[9684 2020]\n",
            "[9691 2020]\n",
            "[9693 2020]\n",
            "[9697 2020]\n",
            "[9699 2020]\n",
            "[9706 2020]\n",
            "[9709 2020]\n",
            "[9719 2020]\n",
            "[9722 2020]\n",
            "[9726 2020]\n",
            "[9732 2020]\n",
            "[9735 2020]\n",
            "[9736 2020]\n",
            "[9740 2020]\n",
            "[9744 2020]\n",
            "[9745 2020]\n",
            "[9750 2020]\n",
            "[9765 2020]\n",
            "[9767 2020]\n",
            "[9769 2020]\n",
            "[9775 2020]\n",
            "[9777 2020]\n",
            "[9780 2020]\n",
            "[9781 2020]\n",
            "[9818 2020]\n",
            "[9825 2020]\n",
            "[9832 2020]\n",
            "[9847 2020]\n",
            "[9850 2020]\n",
            "[9853 2020]\n",
            "[9855 2020]\n",
            "[9864 2020]\n",
            "[9871 2020]\n",
            "[9879 2020]\n",
            "[9888 2020]\n",
            "[9894 2020]\n",
            "[9895 2020]\n",
            "[9900 2020]\n",
            "[9901 2020]\n",
            "[9904 2020]\n",
            "[9915 2020]\n",
            "[9930 2020]\n",
            "[9936 2020]\n",
            "[9939 2020]\n",
            "[9961 2020]\n",
            "[9962 2020]\n",
            "[9979 2020]\n",
            "[9983 2020]\n",
            "[9993 2020]\n",
            "[9996 2020]\n",
            "[9998 2020]\n",
            "[10007  2020]\n",
            "[10009  2020]\n",
            "[10010  2020]\n",
            "[10012  2020]\n",
            "[10017  2020]\n",
            "[10025  2020]\n",
            "[10036  2020]\n",
            "[10057  2020]\n",
            "[10065  2020]\n",
            "[10066  2020]\n",
            "[10079  2020]\n",
            "[10080  2020]\n",
            "[10085  2020]\n",
            "[10108  2020]\n",
            "[10131  2020]\n",
            "[10134  2020]\n",
            "[10141  2020]\n",
            "[10145  2020]\n",
            "[10146  2020]\n",
            "[10148  2020]\n",
            "[10165  2020]\n",
            "[10167  2020]\n",
            "[10171  2020]\n",
            "[10172  2020]\n",
            "[10178  2020]\n",
            "[10179  2020]\n",
            "[10195  2020]\n",
            "[10211  2020]\n",
            "[10212  2020]\n",
            "[10218  2020]\n",
            "[10228  2020]\n",
            "[10237  2020]\n",
            "[10241  2020]\n",
            "[10253  2020]\n",
            "[10256  2020]\n",
            "[10258  2020]\n",
            "[10262  2020]\n",
            "[10263  2020]\n",
            "[10266  2020]\n",
            "[10272  2020]\n",
            "[10280  2020]\n",
            "[10298  2020]\n",
            "[10314  2020]\n",
            "[10317  2020]\n",
            "[10327  2020]\n",
            "[10336  2020]\n",
            "[10345  2020]\n",
            "[10347  2020]\n",
            "[10348  2020]\n",
            "[10354  2020]\n",
            "[10355  2020]\n",
            "[10359  2020]\n",
            "[10373  2020]\n",
            "[10379  2020]\n",
            "[10380  2020]\n",
            "[10389  2020]\n",
            "[10404  2020]\n",
            "[10408  2020]\n",
            "[10438  2020]\n",
            "[10449  2020]\n",
            "[10451  2020]\n",
            "[10457  2020]\n",
            "[10469  2020]\n",
            "[10475  2020]\n",
            "[10481  2020]\n",
            "[10485  2020]\n",
            "[10495  2020]\n",
            "[10507  2020]\n",
            "[10514  2020]\n",
            "[10526  2020]\n",
            "[10527  2020]\n",
            "[10528  2020]\n",
            "[10532  2020]\n",
            "[10546  2020]\n",
            "[10551  2020]\n",
            "[10552  2020]\n",
            "[10567  2020]\n",
            "[10587  2020]\n",
            "[10595  2020]\n",
            "[10598  2020]\n",
            "[10603  2020]\n",
            "[10619  2020]\n",
            "[10625  2020]\n",
            "[10634  2020]\n",
            "[10638  2020]\n",
            "[10661  2020]\n",
            "[10665  2020]\n",
            "[10672  2020]\n",
            "[10674  2020]\n",
            "[10688  2020]\n",
            "[10697  2020]\n",
            "[10698  2020]\n",
            "[10705  2020]\n",
            "[10714  2020]\n",
            "[10720  2020]\n",
            "[10722  2020]\n",
            "[10726  2020]\n",
            "[10727  2020]\n",
            "[10733  2020]\n",
            "[10742  2020]\n",
            "[10744  2020]\n",
            "[10753  2020]\n",
            "[10754  2020]\n",
            "[10777  2020]\n",
            "[10786  2020]\n",
            "[10787  2020]\n",
            "[10795  2020]\n",
            "[10796  2020]\n",
            "[10798  2020]\n",
            "[10802  2020]\n",
            "[10807  2020]\n",
            "[10810  2020]\n",
            "[10821  2020]\n",
            "[10829  2020]\n",
            "[10841  2020]\n",
            "[10854  2020]\n",
            "[10877  2020]\n",
            "[10887  2020]\n",
            "[10888  2020]\n",
            "[10889  2020]\n",
            "[10898  2020]\n",
            "[10902  2020]\n",
            "[10903  2020]\n",
            "[10923  2020]\n",
            "[10940  2020]\n",
            "[10941  2020]\n",
            "[10946  2020]\n",
            "[10948  2020]\n",
            "[10950  2020]\n",
            "[10953  2020]\n",
            "[10956  2020]\n",
            "[10968  2020]\n",
            "[10986  2020]\n",
            "[10992  2020]\n",
            "[11003  2020]\n",
            "[11006  2020]\n",
            "[11007  2020]\n",
            "[11011  2020]\n",
            "[11016  2020]\n",
            "[11019  2020]\n",
            "[11023  2020]\n",
            "[11038  2020]\n",
            "[11041  2020]\n",
            "[11044  2020]\n",
            "[11045  2020]\n",
            "[11050  2020]\n",
            "[11065  2020]\n",
            "[11083  2020]\n",
            "[11093  2020]\n",
            "[11101  2020]\n",
            "[11114  2020]\n",
            "[11121  2020]\n",
            "[11143  2020]\n",
            "[11149  2020]\n",
            "[11156  2020]\n",
            "[11157  2020]\n",
            "[11159  2020]\n",
            "[11179  2020]\n",
            "[11181  2020]\n",
            "[11184  2020]\n",
            "[11201  2020]\n",
            "[11217  2020]\n",
            "[11243  2020]\n",
            "[11244  2020]\n",
            "[11246  2020]\n",
            "[11250  2020]\n",
            "[11260  2020]\n",
            "[11266  2020]\n",
            "[11270  2020]\n",
            "[11279  2020]\n",
            "[11280  2020]\n",
            "[11284  2020]\n",
            "[11290  2020]\n",
            "[11291  2020]\n",
            "[11293  2020]\n",
            "[11303  2020]\n",
            "[11334  2020]\n",
            "[11358  2020]\n",
            "[11361  2020]\n",
            "[11371  2020]\n",
            "[11372  2020]\n",
            "[11377  2020]\n",
            "[11383  2020]\n",
            "[11388  2020]\n",
            "[11393  2020]\n",
            "[11396  2020]\n",
            "[11403  2020]\n",
            "[11408  2020]\n",
            "[11414  2020]\n",
            "[11443  2020]\n",
            "[11447  2020]\n",
            "[11452  2020]\n",
            "[11454  2020]\n",
            "[11455  2020]\n",
            "[11460  2020]\n",
            "[11466  2020]\n",
            "[11469  2020]\n",
            "[11483  2020]\n",
            "[11494  2020]\n",
            "[11523  2020]\n",
            "[11528  2020]\n",
            "[11530  2020]\n",
            "[11533  2020]\n",
            "[11553  2020]\n",
            "[11554  2020]\n",
            "[11560  2020]\n",
            "[11572  2020]\n",
            "[11583  2020]\n",
            "[11584  2020]\n",
            "[11616  2020]\n",
            "[11639  2020]\n",
            "[11641  2020]\n",
            "[11647  2020]\n",
            "[11667  2020]\n",
            "[11668  2020]\n",
            "[11669  2020]\n",
            "[11672  2020]\n",
            "[11688  2020]\n",
            "[11707  2020]\n",
            "[11708  2020]\n",
            "[11722  2020]\n",
            "[11724  2020]\n",
            "[11726  2020]\n",
            "[11737  2020]\n",
            "[11759  2020]\n",
            "[11767  2020]\n",
            "[11770  2020]\n",
            "[11786  2020]\n",
            "[11788  2020]\n",
            "[11792  2020]\n",
            "[11793  2020]\n",
            "[11828  2020]\n",
            "[11839  2020]\n",
            "[11854  2020]\n",
            "[11862  2020]\n",
            "[11886  2020]\n",
            "[11888  2020]\n",
            "[11889  2020]\n",
            "[11893  2020]\n",
            "[11900  2020]\n",
            "[11904  2020]\n",
            "[11918  2020]\n",
            "[11928  2020]\n",
            "[11934  2020]\n",
            "[11940  2020]\n",
            "[11947  2020]\n",
            "[11953  2020]\n",
            "[11960  2020]\n",
            "[11969  2020]\n",
            "[11972  2020]\n",
            "[11974  2020]\n",
            "[11981  2020]\n",
            "[11982  2020]\n",
            "[11989  2020]\n",
            "[11996  2020]\n",
            "[12055  2020]\n",
            "[12057  2020]\n",
            "[12064  2020]\n",
            "[12067  2020]\n",
            "[12069  2020]\n",
            "[12100  2020]\n",
            "[12101  2020]\n",
            "[12108  2020]\n",
            "[12111  2020]\n",
            "[12120  2020]\n",
            "[12127  2020]\n",
            "[12139  2020]\n",
            "[12140  2020]\n",
            "[12151  2020]\n",
            "[12152  2020]\n",
            "[12158  2020]\n",
            "[12168  2020]\n",
            "[12184  2020]\n",
            "[12188  2020]\n",
            "[12194  2020]\n",
            "[12199  2020]\n",
            "[12207  2020]\n",
            "[12218  2020]\n",
            "[12227  2020]\n",
            "[12238  2020]\n",
            "[12247  2020]\n",
            "[12249  2020]\n",
            "[12257  2020]\n",
            "[12263  2020]\n",
            "[12270  2020]\n",
            "[12276  2020]\n",
            "[12281  2020]\n",
            "[12288  2020]\n",
            "[12296  2020]\n",
            "[12302  2020]\n",
            "[12305  2020]\n",
            "[12306  2020]\n",
            "[12310  2020]\n",
            "[12314  2020]\n",
            "[12315  2020]\n",
            "[12317  2020]\n",
            "[12322  2020]\n",
            "[12326  2020]\n",
            "[12328  2020]\n",
            "[12336  2020]\n",
            "[12341  2020]\n",
            "[12348  2020]\n",
            "[12350  2020]\n",
            "[12364  2020]\n",
            "[12367  2020]\n",
            "[12369  2020]\n",
            "[12386  2020]\n",
            "[12388  2020]\n",
            "[12412  2020]\n",
            "[12413  2020]\n",
            "[12432  2020]\n",
            "[12435  2020]\n",
            "[12440  2020]\n",
            "[12446  2020]\n",
            "[12470  2020]\n",
            "[12473  2020]\n",
            "[12476  2020]\n",
            "[12483  2020]\n",
            "[12492  2020]\n",
            "[12498  2020]\n",
            "[12507  2020]\n",
            "[12510  2020]\n",
            "[12520  2020]\n",
            "[12526  2020]\n",
            "[12543  2020]\n",
            "[12548  2020]\n",
            "[12551  2020]\n",
            "[12552  2020]\n",
            "[12573  2020]\n",
            "[12574  2020]\n",
            "[12582  2020]\n",
            "[12589  2020]\n",
            "[12595  2020]\n",
            "[12600  2020]\n",
            "[12610  2020]\n",
            "[12615  2020]\n",
            "[12619  2020]\n",
            "[12631  2020]\n",
            "[12635  2020]\n",
            "[12638  2020]\n",
            "[12639  2020]\n",
            "[12646  2020]\n",
            "[12648  2020]\n",
            "[12657  2020]\n",
            "[12661  2020]\n",
            "[12662  2020]\n",
            "[12666  2020]\n",
            "[12668  2020]\n",
            "[12671  2020]\n",
            "[12683  2020]\n",
            "[12686  2020]\n",
            "[12693  2020]\n",
            "[12694  2020]\n",
            "[12698  2020]\n",
            "[12709  2020]\n",
            "[12712  2020]\n",
            "[12717  2020]\n",
            "[12718  2020]\n",
            "[12721  2020]\n",
            "[12722  2020]\n",
            "[12732  2020]\n",
            "[12736  2020]\n",
            "[12744  2020]\n",
            "[12753  2020]\n",
            "[12776  2020]\n",
            "[12782  2020]\n",
            "[12784  2020]\n",
            "[12795  2020]\n",
            "[12796  2020]\n",
            "[12809  2020]\n",
            "[12818  2020]\n",
            "[12820  2020]\n",
            "[12831  2020]\n",
            "[12834  2020]\n",
            "[12839  2020]\n",
            "[12841  2020]\n",
            "[12843  2020]\n",
            "[12852  2020]\n",
            "[12858  2020]\n",
            "[12859  2020]\n",
            "[12865  2020]\n",
            "[12866  2020]\n",
            "[12877  2020]\n",
            "[12890  2020]\n",
            "[12916  2020]\n",
            "[12922  2020]\n",
            "[12925  2020]\n",
            "[12937  2020]\n",
            "[12939  2020]\n",
            "[12945  2020]\n",
            "[12954  2020]\n",
            "[12958  2020]\n",
            "[12960  2020]\n",
            "[12961  2020]\n",
            "[12976  2020]\n",
            "[12980  2020]\n",
            "[12981  2020]\n",
            "[13009  2020]\n",
            "[13015  2020]\n",
            "[13018  2020]\n",
            "[13025  2020]\n",
            "[13044  2020]\n",
            "[13049  2020]\n",
            "[13053  2020]\n",
            "[13071  2020]\n",
            "[13072  2020]\n",
            "[13081  2020]\n",
            "[13083  2020]\n",
            "[13107  2020]\n",
            "[13121  2020]\n",
            "[13122  2020]\n",
            "[13125  2020]\n",
            "[13135  2020]\n",
            "[13143  2020]\n",
            "[13154  2020]\n",
            "[13155  2020]\n",
            "[13157  2020]\n",
            "[13163  2020]\n",
            "[13165  2020]\n",
            "[13170  2020]\n",
            "[13176  2020]\n",
            "[13186  2020]\n",
            "[13194  2020]\n",
            "[13198  2020]\n",
            "[13211  2020]\n",
            "[13217  2020]\n",
            "[13231  2020]\n",
            "[13253  2020]\n",
            "[13254  2020]\n",
            "[13261  2020]\n",
            "[13262  2020]\n",
            "[13265  2020]\n",
            "[13277  2020]\n",
            "[13281  2020]\n",
            "[13282  2020]\n",
            "[13287  2020]\n",
            "[13290  2020]\n",
            "[13299  2020]\n",
            "[13301  2020]\n",
            "[13306  2020]\n",
            "[13308  2020]\n",
            "[13342  2020]\n",
            "[13344  2020]\n",
            "[13345  2020]\n",
            "[13347  2020]\n",
            "[13351  2020]\n",
            "[13353  2020]\n",
            "[13370  2020]\n",
            "[13406  2020]\n",
            "[13408  2020]\n",
            "[13422  2020]\n",
            "[13423  2020]\n",
            "[13428  2020]\n",
            "[13449  2020]\n",
            "[13466  2020]\n",
            "[13483  2020]\n",
            "[13488  2020]\n",
            "[13489  2020]\n",
            "[13499  2020]\n",
            "[13500  2020]\n",
            "[13503  2020]\n",
            "[13509  2020]\n",
            "[13535  2020]\n",
            "[13539  2020]\n",
            "[13546  2020]\n",
            "[13549  2020]\n",
            "[13550  2020]\n",
            "[13556  2020]\n",
            "[13559  2020]\n",
            "[13563  2020]\n",
            "[13565  2020]\n",
            "[13572  2020]\n",
            "[13574  2020]\n",
            "[13619  2020]\n",
            "[13622  2020]\n",
            "[13653  2020]\n",
            "[13655  2020]\n",
            "[13659  2020]\n",
            "[13668  2020]\n",
            "[13696  2020]\n",
            "[13699  2020]\n",
            "[13700  2020]\n",
            "[13703  2020]\n",
            "[13706  2020]\n",
            "[13723  2020]\n",
            "[13726  2020]\n",
            "[13732  2020]\n",
            "[13739  2020]\n",
            "[13747  2020]\n",
            "[13748  2020]\n",
            "[13749  2020]\n",
            "[13752  2020]\n",
            "[13753  2020]\n",
            "[13775  2020]\n",
            "[13779  2020]\n",
            "[13783  2020]\n",
            "[13797  2020]\n",
            "[13809  2020]\n",
            "[13818  2020]\n",
            "[13819  2020]\n",
            "[13820  2020]\n",
            "[13832  2020]\n",
            "[13842  2020]\n",
            "[13849  2020]\n",
            "[13850  2020]\n",
            "[13853  2020]\n",
            "[13854  2020]\n",
            "[13856  2020]\n",
            "[13857  2020]\n",
            "[13876  2020]\n",
            "[13899  2020]\n",
            "[13901  2020]\n",
            "[13905  2020]\n",
            "[13906  2020]\n",
            "[13908  2020]\n",
            "[13911  2020]\n",
            "[13921  2020]\n",
            "[13941  2020]\n",
            "[13968  2020]\n",
            "[13979  2020]\n",
            "[13983  2020]\n",
            "[13988  2020]\n",
            "[14004  2020]\n",
            "[14014  2020]\n",
            "[14017  2020]\n",
            "[14040  2020]\n",
            "[14042  2020]\n",
            "[14043  2020]\n",
            "[14044  2020]\n",
            "[14059  2020]\n",
            "[14065  2020]\n",
            "[14067  2020]\n",
            "[14072  2020]\n",
            "[14077  2020]\n",
            "[14091  2020]\n",
            "[14095  2020]\n",
            "[14099  2020]\n",
            "[14114  2020]\n",
            "[14121  2020]\n",
            "[14127  2020]\n",
            "[14130  2020]\n",
            "[14132  2020]\n",
            "[14136  2020]\n",
            "[14140  2020]\n",
            "[14143  2020]\n",
            "[14156  2020]\n",
            "[14169  2020]\n",
            "[14175  2020]\n",
            "[14181  2020]\n",
            "[14183  2020]\n",
            "[14184  2020]\n",
            "[14200  2020]\n",
            "[14209  2020]\n",
            "[14210  2020]\n",
            "[14213  2020]\n",
            "[14214  2020]\n",
            "[14262  2020]\n",
            "[14264  2020]\n",
            "[14270  2020]\n",
            "[14308  2020]\n",
            "[14318  2020]\n",
            "[14324  2020]\n",
            "[14326  2020]\n",
            "[14327  2020]\n",
            "[14330  2020]\n",
            "[14331  2020]\n",
            "[14339  2020]\n",
            "[14341  2020]\n",
            "[14348  2020]\n",
            "[14349  2020]\n",
            "[14351  2020]\n",
            "[14359  2020]\n",
            "[14370  2020]\n",
            "[14380  2020]\n",
            "[14381  2020]\n",
            "[14382  2020]\n",
            "[14426  2020]\n",
            "[14443  2020]\n",
            "[14447  2020]\n",
            "[14450  2020]\n",
            "[14451  2020]\n",
            "[14466  2020]\n",
            "[14470  2020]\n",
            "[14482  2020]\n",
            "[14485  2020]\n",
            "[14487  2020]\n",
            "[14492  2020]\n",
            "[14497  2020]\n",
            "[14513  2020]\n",
            "[14521  2020]\n",
            "[14525  2020]\n",
            "[14531  2020]\n",
            "[14538  2020]\n",
            "[14556  2020]\n",
            "[14559  2020]\n",
            "[14565  2020]\n",
            "[14569  2020]\n",
            "[14574  2020]\n",
            "[14584  2020]\n",
            "[14599  2020]\n",
            "[14603  2020]\n",
            "[14609  2020]\n",
            "[14610  2020]\n",
            "[14614  2020]\n",
            "[14624  2020]\n",
            "[14633  2020]\n",
            "[14634  2020]\n",
            "[14641  2020]\n",
            "[14644  2020]\n",
            "[14647  2020]\n",
            "[14649  2020]\n",
            "[14652  2020]\n",
            "[14654  2020]\n",
            "[14658  2020]\n",
            "[14667  2020]\n",
            "[14676  2020]\n",
            "[14683  2020]\n",
            "[14685  2020]\n",
            "[14687  2020]\n",
            "[14696  2020]\n",
            "[14698  2020]\n",
            "[14708  2020]\n",
            "[14721  2020]\n",
            "[14722  2020]\n",
            "[14736  2020]\n",
            "[14761  2020]\n",
            "[14788  2020]\n",
            "[14793  2020]\n",
            "[14796  2020]\n",
            "[14800  2020]\n",
            "[14806  2020]\n",
            "[14810  2020]\n",
            "[14811  2020]\n",
            "[14816  2020]\n",
            "[14817  2020]\n",
            "[14820  2020]\n",
            "[14828  2020]\n",
            "[14829  2020]\n",
            "[14843  2020]\n",
            "[14847  2020]\n",
            "[14848  2020]\n",
            "[14865  2020]\n",
            "[14870  2020]\n",
            "[14879  2020]\n",
            "[14883  2020]\n",
            "[14898  2020]\n",
            "[14906  2020]\n",
            "[14908  2020]\n",
            "[14914  2020]\n",
            "[14919  2020]\n",
            "[14930  2020]\n",
            "[14942  2020]\n",
            "[14943  2020]\n",
            "[14951  2020]\n",
            "[14952  2020]\n",
            "[14966  2020]\n",
            "[14970  2020]\n",
            "[14976  2020]\n",
            "[14979  2020]\n",
            "[14996  2020]\n",
            "[14999  2020]\n",
            "[15002  2020]\n",
            "[15008  2020]\n",
            "[15015  2020]\n",
            "[15017  2020]\n",
            "[15030  2020]\n",
            "[15034  2020]\n",
            "[15041  2020]\n",
            "[15051  2020]\n",
            "[15053  2020]\n",
            "[15056  2020]\n",
            "[15057  2020]\n",
            "[15059  2020]\n",
            "[15080  2020]\n",
            "[15113  2020]\n",
            "[15124  2020]\n",
            "[15133  2020]\n",
            "[15143  2020]\n",
            "[15146  2020]\n",
            "[15149  2020]\n",
            "[15159  2020]\n",
            "[15160  2020]\n",
            "[15165  2020]\n",
            "[15166  2020]\n",
            "[15180  2020]\n",
            "[15191  2020]\n",
            "[15197  2020]\n",
            "[15198  2020]\n",
            "[15203  2020]\n",
            "[15212  2020]\n",
            "[15222  2020]\n",
            "[15224  2020]\n",
            "[15226  2020]\n",
            "[15235  2020]\n",
            "[15248  2020]\n",
            "[15252  2020]\n",
            "[15260  2020]\n",
            "[15271  2020]\n",
            "[15272  2020]\n",
            "[15274  2020]\n",
            "[15275  2020]\n",
            "[15278  2020]\n",
            "[15290  2020]\n",
            "[15292  2020]\n",
            "[15306  2020]\n",
            "[15307  2020]\n",
            "[15309  2020]\n",
            "[15326  2020]\n",
            "[15332  2020]\n",
            "[15338  2020]\n",
            "[15340  2020]\n",
            "[15346  2020]\n",
            "[15347  2020]\n",
            "[15355  2020]\n",
            "[15359  2020]\n",
            "[15365  2020]\n",
            "[15371  2020]\n",
            "[15375  2020]\n",
            "[15377  2020]\n",
            "[15379  2020]\n",
            "[15381  2020]\n",
            "[15382  2020]\n",
            "[15387  2020]\n",
            "[15403  2020]\n",
            "[15405  2020]\n",
            "[15412  2020]\n",
            "[15419  2020]\n",
            "[15428  2020]\n",
            "[15430  2020]\n",
            "[15431  2020]\n",
            "[15434  2020]\n",
            "[15436  2020]\n",
            "[15437  2020]\n",
            "[15448  2020]\n",
            "[15456  2020]\n",
            "[15463  2020]\n",
            "[15477  2020]\n",
            "[15478  2020]\n",
            "[15487  2020]\n",
            "[15500  2020]\n",
            "[15511  2020]\n",
            "[15517  2020]\n",
            "[15519  2020]\n",
            "[15528  2020]\n",
            "[15545  2020]\n",
            "[15553  2020]\n",
            "[15561  2020]\n",
            "[15569  2020]\n",
            "[15583  2020]\n",
            "[15603  2020]\n",
            "[15604  2020]\n",
            "[15608  2020]\n",
            "[15627  2020]\n",
            "[15630  2020]\n",
            "[15638  2020]\n",
            "[15658  2020]\n",
            "[15665  2020]\n",
            "[15671  2020]\n",
            "[15675  2020]\n",
            "[15678  2020]\n",
            "[15679  2020]\n",
            "[15686  2020]\n",
            "[15687  2020]\n",
            "[15696  2020]\n",
            "[15725  2020]\n",
            "[15730  2020]\n",
            "[15732  2020]\n",
            "[15739  2020]\n",
            "[15741  2020]\n",
            "[15746  2020]\n",
            "[15757  2020]\n",
            "[15758  2020]\n",
            "[15764  2020]\n",
            "[15765  2020]\n",
            "[15782  2020]\n",
            "[15785  2020]\n",
            "[15786  2020]\n",
            "[15788  2020]\n",
            "[15798  2020]\n",
            "[15799  2020]\n",
            "[15802  2020]\n",
            "[15804  2020]\n",
            "[15805  2020]\n",
            "[15814  2020]\n",
            "[15834  2020]\n",
            "[15835  2020]\n",
            "[15848  2020]\n",
            "[15850  2020]\n",
            "[15859  2020]\n",
            "[15860  2020]\n",
            "[15866  2020]\n",
            "[15873  2020]\n",
            "[15877  2020]\n",
            "[15894  2020]\n",
            "[15898  2020]\n",
            "[15902  2020]\n",
            "[15904  2020]\n",
            "[15907  2020]\n",
            "[15911  2020]\n",
            "[15927  2020]\n",
            "[15929  2020]\n",
            "[15933  2020]\n",
            "[15942  2020]\n",
            "[15958  2020]\n",
            "[15986  2020]\n",
            "[15987  2020]\n",
            "[16000  2020]\n",
            "[16008  2020]\n",
            "[16027  2020]\n",
            "[16037  2020]\n",
            "[16038  2020]\n",
            "[16050  2020]\n",
            "[16059  2020]\n",
            "[16064  2020]\n",
            "[16071  2020]\n",
            "[16076  2020]\n",
            "[16078  2020]\n",
            "[16080  2020]\n",
            "[16095  2020]\n",
            "[16114  2020]\n",
            "[16117  2020]\n",
            "[16136  2020]\n",
            "[16148  2020]\n",
            "[16151  2020]\n",
            "[16153  2020]\n",
            "[16162  2020]\n",
            "[16166  2020]\n",
            "[16173  2020]\n",
            "[16188  2020]\n",
            "[16191  2020]\n",
            "[16192  2020]\n",
            "[16200  2020]\n",
            "[16202  2020]\n",
            "[16210  2020]\n",
            "[16220  2020]\n",
            "[16221  2020]\n",
            "[16242  2020]\n",
            "[16249  2020]\n",
            "[16253  2020]\n",
            "[16260  2020]\n",
            "[16271  2020]\n",
            "[16277  2020]\n",
            "[16279  2020]\n",
            "[16280  2020]\n",
            "[16282  2020]\n",
            "[16291  2020]\n",
            "[16292  2020]\n",
            "[16300  2020]\n",
            "[16303  2020]\n",
            "[16316  2020]\n",
            "[16331  2020]\n",
            "[16332  2020]\n",
            "[16333  2020]\n",
            "[16339  2020]\n",
            "[16340  2020]\n",
            "[16359  2020]\n",
            "[16363  2020]\n",
            "[16370  2020]\n",
            "[16387  2020]\n",
            "[16393  2020]\n",
            "[16395  2020]\n",
            "[16398  2020]\n",
            "[16401  2020]\n",
            "[16403  2020]\n",
            "[16406  2020]\n",
            "[16407  2020]\n",
            "[16409  2020]\n",
            "[16411  2020]\n",
            "[16419  2020]\n",
            "[16420  2020]\n",
            "[16425  2020]\n",
            "[16438  2020]\n",
            "[16441  2020]\n",
            "[16447  2020]\n",
            "[16472  2020]\n",
            "[16477  2020]\n",
            "[16480  2020]\n",
            "[16482  2020]\n",
            "[16483  2020]\n",
            "[16486  2020]\n",
            "[16506  2020]\n",
            "[16510  2020]\n",
            "[16519  2020]\n",
            "[16546  2020]\n",
            "[16548  2020]\n",
            "[16552  2020]\n",
            "[16558  2020]\n",
            "[16582  2020]\n",
            "[16587  2020]\n",
            "[16596  2020]\n",
            "[16597  2020]\n",
            "[16599  2020]\n",
            "[16606  2020]\n",
            "[16615  2020]\n",
            "[16653  2020]\n",
            "[16664  2020]\n",
            "[16667  2020]\n",
            "[16668  2020]\n",
            "[16670  2020]\n",
            "[16689  2020]\n",
            "[16694  2020]\n",
            "[16707  2020]\n",
            "[16710  2020]\n",
            "[16720  2020]\n",
            "[16736  2020]\n",
            "[16742  2020]\n",
            "[16757  2020]\n",
            "[16767  2020]\n",
            "[16769  2020]\n",
            "[16779  2020]\n",
            "[16782  2020]\n",
            "[16787  2020]\n",
            "[16794  2020]\n",
            "[16798  2020]\n",
            "[16820  2020]\n",
            "[16824  2020]\n",
            "[16831  2020]\n",
            "[16836  2020]\n",
            "[16839  2020]\n",
            "[16850  2020]\n",
            "[16851  2020]\n",
            "[16852  2020]\n",
            "[16859  2020]\n",
            "[16867  2020]\n",
            "[16871  2020]\n",
            "[16873  2020]\n",
            "[16876  2020]\n",
            "[16893  2020]\n",
            "[16894  2020]\n",
            "[16897  2020]\n",
            "[16910  2020]\n",
            "[16913  2020]\n",
            "[16917  2020]\n",
            "[16923  2020]\n",
            "[16925  2020]\n",
            "[16928  2020]\n",
            "[16938  2020]\n",
            "[16942  2020]\n",
            "[16952  2020]\n",
            "[16963  2020]\n",
            "[16969  2020]\n",
            "[16980  2020]\n",
            "[16990  2020]\n",
            "[17002  2020]\n",
            "[17025  2020]\n",
            "[17026  2020]\n",
            "[17028  2020]\n",
            "[17040  2020]\n",
            "[17043  2020]\n",
            "[17044  2020]\n",
            "[17047  2020]\n",
            "[17057  2020]\n",
            "[17066  2020]\n",
            "[17096  2020]\n",
            "[17099  2020]\n",
            "[17101  2020]\n",
            "[17106  2020]\n",
            "[17117  2020]\n",
            "[17122  2020]\n",
            "[17125  2020]\n",
            "[17126  2020]\n",
            "[17129  2020]\n",
            "[17133  2020]\n",
            "[17134  2020]\n",
            "[17136  2020]\n",
            "[17139  2020]\n",
            "[17142  2020]\n",
            "[17146  2020]\n",
            "[17148  2020]\n",
            "[17161  2020]\n",
            "[17168  2020]\n",
            "[17185  2020]\n",
            "[17218  2020]\n",
            "[17226  2020]\n",
            "[17231  2020]\n",
            "[17240  2020]\n",
            "[17262  2020]\n",
            "[17267  2020]\n",
            "[17269  2020]\n",
            "[17270  2020]\n",
            "[17280  2020]\n",
            "[17287  2020]\n",
            "[17297  2020]\n",
            "[17303  2020]\n",
            "[17308  2020]\n",
            "[17311  2020]\n",
            "[17312  2020]\n",
            "[17317  2020]\n",
            "[17319  2020]\n",
            "[17326  2020]\n",
            "[17335  2020]\n",
            "[17338  2020]\n",
            "[17341  2020]\n",
            "[17355  2020]\n",
            "[17359  2020]\n",
            "[17361  2020]\n",
            "[17385  2020]\n",
            "[17392  2020]\n",
            "[17403  2020]\n",
            "[17404  2020]\n",
            "[17408  2020]\n",
            "[17416  2020]\n",
            "[17417  2020]\n",
            "[17419  2020]\n",
            "[17420  2020]\n",
            "[17425  2020]\n",
            "[17427  2020]\n",
            "[17428  2020]\n",
            "[17430  2020]\n",
            "[17438  2020]\n",
            "[17442  2020]\n",
            "[17475  2020]\n",
            "[17485  2020]\n",
            "[17494  2020]\n",
            "[17496  2020]\n",
            "[17497  2020]\n",
            "[17498  2020]\n",
            "[17508  2020]\n",
            "[17509  2020]\n",
            "[17511  2020]\n",
            "[17514  2020]\n",
            "[17526  2020]\n",
            "[17543  2020]\n",
            "[17544  2020]\n",
            "[17545  2020]\n",
            "[17560  2020]\n",
            "[17563  2020]\n",
            "[17566  2020]\n",
            "[17571  2020]\n",
            "[17572  2020]\n",
            "[17575  2020]\n",
            "[17592  2020]\n",
            "[17595  2020]\n",
            "[17598  2020]\n",
            "[17647  2020]\n",
            "[17651  2020]\n",
            "[17659  2020]\n",
            "[17665  2020]\n",
            "[17670  2020]\n",
            "[17671  2020]\n",
            "[17677  2020]\n",
            "[17678  2020]\n",
            "[17688  2020]\n",
            "[17691  2020]\n",
            "[17693  2020]\n",
            "[17701  2020]\n",
            "[17704  2020]\n",
            "[17707  2020]\n",
            "[17711  2020]\n",
            "[17712  2020]\n",
            "[17742  2020]\n",
            "[17745  2020]\n",
            "[17752  2020]\n",
            "[17756  2020]\n",
            "[17757  2020]\n",
            "[17758  2020]\n",
            "[17761  2020]\n",
            "[17763  2020]\n",
            "[17775  2020]\n",
            "[17776  2020]\n",
            "[17779  2020]\n",
            "[17782  2020]\n",
            "[17803  2020]\n",
            "[17816  2020]\n",
            "[17818  2020]\n",
            "[17824  2020]\n",
            "[17829  2020]\n",
            "[17833  2020]\n",
            "[17844  2020]\n",
            "[17857  2020]\n",
            "[17868  2020]\n",
            "[17872  2020]\n",
            "[17876  2020]\n",
            "[17878  2020]\n",
            "[17897  2020]\n",
            "[17914  2020]\n",
            "[17930  2020]\n",
            "[17936  2020]\n",
            "[17944  2020]\n",
            "[17950  2020]\n",
            "[17957  2020]\n",
            "[17958  2020]\n",
            "[17959  2020]\n",
            "[17965  2020]\n",
            "[17970  2020]\n",
            "[17983  2020]\n",
            "[17986  2020]\n",
            "[17988  2020]\n",
            "[17990  2020]\n",
            "[17997  2020]\n",
            "[18014  2020]\n",
            "[18016  2020]\n",
            "[18020  2020]\n",
            "[18023  2020]\n",
            "[18034  2020]\n",
            "[18037  2020]\n",
            "[18039  2020]\n",
            "[18040  2020]\n",
            "[18041  2020]\n",
            "[18047  2020]\n",
            "[18057  2020]\n",
            "[18062  2020]\n",
            "[18064  2020]\n",
            "[18067  2020]\n",
            "[18080  2020]\n",
            "[18088  2020]\n",
            "[18097  2020]\n",
            "[18100  2020]\n",
            "[18105  2020]\n",
            "[18120  2020]\n",
            "[18134  2020]\n",
            "[18160  2020]\n",
            "[18166  2020]\n",
            "[18170  2020]\n",
            "[18173  2020]\n",
            "[18206  2020]\n",
            "[18211  2020]\n",
            "[18212  2020]\n",
            "[18218  2020]\n",
            "[18224  2020]\n",
            "[18229  2020]\n",
            "[18249  2020]\n",
            "[18259  2020]\n",
            "[18260  2020]\n",
            "[18262  2020]\n",
            "[18265  2020]\n",
            "[18285  2020]\n",
            "[18297  2020]\n",
            "[18303  2020]\n",
            "[18306  2020]\n",
            "[18314  2020]\n",
            "[18336  2020]\n",
            "[18343  2020]\n",
            "[18349  2020]\n",
            "[18351  2020]\n",
            "[18353  2020]\n",
            "[18359  2020]\n",
            "[18361  2020]\n",
            "[18375  2020]\n",
            "[18389  2020]\n",
            "[18410  2020]\n",
            "[18412  2020]\n",
            "[18413  2020]\n",
            "[18414  2020]\n",
            "[18420  2020]\n",
            "[18424  2020]\n",
            "[18426  2020]\n",
            "[18432  2020]\n",
            "[18438  2020]\n",
            "[18440  2020]\n",
            "[18442  2020]\n",
            "[18447  2020]\n",
            "[18454  2020]\n",
            "[18458  2020]\n",
            "[18460  2020]\n",
            "[18462  2020]\n",
            "[18463  2020]\n",
            "[18464  2020]\n",
            "[18474  2020]\n",
            "[18476  2020]\n",
            "[18483  2020]\n",
            "[18486  2020]\n",
            "[18496  2020]\n",
            "[18504  2020]\n",
            "[18505  2020]\n",
            "[18507  2020]\n",
            "[18510  2020]\n",
            "[18516  2020]\n",
            "[18525  2020]\n",
            "[18537  2020]\n",
            "[18545  2020]\n",
            "[18546  2020]\n",
            "[18555  2020]\n",
            "[18556  2020]\n",
            "[18559  2020]\n",
            "[18563  2020]\n",
            "[18568  2020]\n",
            "[18569  2020]\n",
            "[18572  2020]\n",
            "[18575  2020]\n",
            "[18581  2020]\n",
            "[18586  2020]\n",
            "[18597  2020]\n",
            "[18598  2020]\n",
            "[18609  2020]\n",
            "[18623  2020]\n",
            "[18625  2020]\n",
            "[18627  2020]\n",
            "[18638  2020]\n",
            "[18639  2020]\n",
            "[18685  2020]\n",
            "[18702  2020]\n",
            "[18710  2020]\n",
            "[18719  2020]\n",
            "[18724  2020]\n",
            "[18727  2020]\n",
            "[18731  2020]\n",
            "[18733  2020]\n",
            "[18743  2020]\n",
            "[18749  2020]\n",
            "[18757  2020]\n",
            "[18759  2020]\n",
            "[18763  2020]\n",
            "[18765  2020]\n",
            "[18768  2020]\n",
            "[18798  2020]\n",
            "[18823  2020]\n",
            "[18847  2020]\n",
            "[18850  2020]\n",
            "[18859  2020]\n",
            "[18866  2020]\n",
            "[18870  2020]\n",
            "[18880  2020]\n",
            "[18886  2020]\n",
            "[18893  2020]\n",
            "[18896  2020]\n",
            "[18911  2020]\n",
            "[18912  2020]\n",
            "[18931  2020]\n",
            "[18951  2020]\n",
            "[18957  2020]\n",
            "[18958  2020]\n",
            "[18968  2020]\n",
            "[18969  2020]\n",
            "[18981  2020]\n",
            "[18988  2020]\n",
            "[18992  2020]\n",
            "[18999  2020]\n",
            "[19005  2020]\n",
            "[19007  2020]\n",
            "[19009  2020]\n",
            "[19012  2020]\n",
            "[19015  2020]\n",
            "[19029  2020]\n",
            "[19041  2020]\n",
            "[19044  2020]\n",
            "[19048  2020]\n",
            "[19054  2020]\n",
            "[19057  2020]\n",
            "[19070  2020]\n",
            "[19083  2020]\n",
            "[19085  2020]\n",
            "[19095  2020]\n",
            "[19136  2020]\n",
            "[19148  2020]\n",
            "[19155  2020]\n",
            "[19163  2020]\n",
            "[19172  2020]\n",
            "[19177  2020]\n",
            "[19187  2020]\n",
            "[19193  2020]\n",
            "[19205  2020]\n",
            "[19209  2020]\n",
            "[19223  2020]\n",
            "[19226  2020]\n",
            "[19235  2020]\n",
            "[19237  2020]\n",
            "[19241  2020]\n",
            "[19246  2020]\n",
            "[19248  2020]\n",
            "[19251  2020]\n",
            "[19257  2020]\n",
            "[19263  2020]\n",
            "[19264  2020]\n",
            "[19267  2020]\n",
            "[19270  2020]\n",
            "[19271  2020]\n",
            "[19272  2020]\n",
            "[19273  2020]\n",
            "[19283  2020]\n",
            "[19285  2020]\n",
            "[19288  2020]\n",
            "[19291  2020]\n",
            "[19304  2020]\n",
            "[19306  2020]\n",
            "[19317  2020]\n",
            "[19318  2020]\n",
            "[19324  2020]\n",
            "[19328  2020]\n",
            "[19331  2020]\n",
            "[19339  2020]\n",
            "[19343  2020]\n",
            "[19347  2020]\n",
            "[19349  2020]\n",
            "[19354  2020]\n",
            "[19357  2020]\n",
            "[19361  2020]\n",
            "[19382  2020]\n",
            "[19414  2020]\n",
            "[19416  2020]\n",
            "[19420  2020]\n",
            "[19422  2020]\n",
            "[19428  2020]\n",
            "[19430  2020]\n",
            "[19438  2020]\n",
            "[19439  2020]\n",
            "[19455  2020]\n",
            "[19458  2020]\n",
            "[19464  2020]\n",
            "[19465  2020]\n",
            "[19468  2020]\n",
            "[19470  2020]\n",
            "[19476  2020]\n",
            "[19485  2020]\n",
            "[19488  2020]\n",
            "[19489  2020]\n",
            "[19492  2020]\n",
            "[19505  2020]\n",
            "[19513  2020]\n",
            "[19518  2020]\n",
            "[19520  2020]\n",
            "[19521  2020]\n",
            "[19526  2020]\n",
            "[19534  2020]\n",
            "[19548  2020]\n",
            "[19555  2020]\n",
            "[19572  2020]\n",
            "[19573  2020]\n",
            "[19574  2020]\n",
            "[19576  2020]\n",
            "[19580  2020]\n",
            "[19584  2020]\n",
            "[19590  2020]\n",
            "[19594  2020]\n",
            "[19603  2020]\n",
            "[19611  2020]\n",
            "[19636  2020]\n",
            "[19645  2020]\n",
            "[19649  2020]\n",
            "[19682  2020]\n",
            "[19684  2020]\n",
            "[19691  2020]\n",
            "[19694  2020]\n",
            "[19695  2020]\n",
            "[19702  2020]\n",
            "[19730  2020]\n",
            "[19734  2020]\n",
            "[19745  2020]\n",
            "[19746  2020]\n",
            "[19750  2020]\n",
            "[19752  2020]\n",
            "[19758  2020]\n",
            "[19760  2020]\n",
            "[19763  2020]\n",
            "[19773  2020]\n",
            "[19774  2020]\n",
            "[19780  2020]\n",
            "[19784  2020]\n",
            "[19790  2020]\n",
            "[19796  2020]\n",
            "[19798  2020]\n",
            "[19807  2020]\n",
            "[19816  2020]\n",
            "[19821  2020]\n",
            "[19829  2020]\n",
            "[19836  2020]\n",
            "[19837  2020]\n",
            "[19846  2020]\n",
            "[19849  2020]\n",
            "[19856  2020]\n",
            "[19862  2020]\n",
            "[19868  2020]\n",
            "[19881  2020]\n",
            "[19886  2020]\n",
            "[19911  2020]\n",
            "[19914  2020]\n",
            "[19916  2020]\n",
            "[19921  2020]\n",
            "[19928  2020]\n",
            "[19929  2020]\n",
            "[19933  2020]\n",
            "[19934  2020]\n",
            "[19941  2020]\n",
            "[19942  2020]\n",
            "[19946  2020]\n",
            "[19962  2020]\n",
            "[19966  2020]\n",
            "[19969  2020]\n",
            "[19982  2020]\n",
            "[19984  2020]\n",
            "[19987  2020]\n",
            "[19991  2020]\n",
            "[19997  2020]\n",
            "[20016  2020]\n",
            "[20046  2020]\n",
            "[20057  2020]\n",
            "[20082  2020]\n",
            "[20084  2020]\n",
            "[20088  2020]\n",
            "[20091  2020]\n",
            "[20116  2020]\n",
            "[20132  2020]\n",
            "[20135  2020]\n",
            "[20150  2020]\n",
            "[20159  2020]\n",
            "[20170  2020]\n",
            "[20172  2020]\n",
            "[20175  2020]\n",
            "[20186  2020]\n",
            "[20193  2020]\n",
            "[20202  2020]\n",
            "[20214  2020]\n",
            "[20231  2020]\n",
            "[20238  2020]\n",
            "[20246  2020]\n",
            "[20247  2020]\n",
            "[20279  2020]\n",
            "[20281  2020]\n",
            "[20287  2020]\n",
            "[20292  2020]\n",
            "[20298  2020]\n",
            "[20305  2020]\n",
            "[20307  2020]\n",
            "[20314  2020]\n",
            "[20319  2020]\n",
            "[20328  2020]\n",
            "[20340  2020]\n",
            "[20353  2020]\n",
            "[20358  2020]\n",
            "[20368  2020]\n",
            "[20370  2020]\n",
            "[20383  2020]\n",
            "[20387  2020]\n",
            "[20392  2020]\n",
            "[20393  2020]\n",
            "[20394  2020]\n",
            "[20396  2020]\n",
            "[20401  2020]\n",
            "[20412  2020]\n",
            "[20418  2020]\n",
            "[20421  2020]\n",
            "[20423  2020]\n",
            "[20431  2020]\n",
            "[20451  2020]\n",
            "[20465  2020]\n",
            "[20471  2020]\n",
            "[20474  2020]\n",
            "[20476  2020]\n",
            "[20493  2020]\n",
            "[20497  2020]\n",
            "[20501  2020]\n",
            "[20512  2020]\n",
            "[20522  2020]\n",
            "[20525  2020]\n",
            "[20543  2020]\n",
            "[20552  2020]\n",
            "[20556  2020]\n",
            "[20559  2020]\n",
            "[20562  2020]\n",
            "[20563  2020]\n",
            "[20564  2020]\n",
            "[20577  2020]\n",
            "[20581  2020]\n",
            "[20590  2020]\n",
            "[20595  2020]\n",
            "[20618  2020]\n",
            "[20622  2020]\n",
            "[20624  2020]\n",
            "[20641  2020]\n",
            "[20643  2020]\n",
            "[20644  2020]\n",
            "[20649  2020]\n",
            "[20654  2020]\n",
            "[20655  2020]\n",
            "[20656  2020]\n",
            "[20657  2020]\n",
            "[20662  2020]\n",
            "[20673  2020]\n",
            "[20677  2020]\n",
            "[20683  2020]\n",
            "[20690  2020]\n",
            "[20692  2020]\n",
            "[20694  2020]\n",
            "[20706  2020]\n",
            "[20715  2020]\n",
            "[20723  2020]\n",
            "[20745  2020]\n",
            "[20753  2020]\n",
            "[20764  2020]\n",
            "[20765  2020]\n",
            "[20768  2020]\n",
            "[20773  2020]\n",
            "[20775  2020]\n",
            "[20777  2020]\n",
            "[20784  2020]\n",
            "[20794  2020]\n",
            "[20801  2020]\n",
            "[20807  2020]\n",
            "[20822  2020]\n",
            "[20824  2020]\n",
            "[20830  2020]\n",
            "[20832  2020]\n",
            "[20855  2020]\n",
            "[20867  2020]\n",
            "[20868  2020]\n",
            "[20869  2020]\n",
            "[20887  2020]\n",
            "[20896  2020]\n",
            "[20901  2020]\n",
            "[20914  2020]\n",
            "[20916  2020]\n",
            "[20921  2020]\n",
            "[20932  2020]\n",
            "[20944  2020]\n",
            "[20953  2020]\n",
            "[20955  2020]\n",
            "[20970  2020]\n",
            "[20976  2020]\n",
            "[20987  2020]\n",
            "[20990  2020]\n",
            "[20991  2020]\n",
            "[20996  2020]\n",
            "[21006  2020]\n",
            "[21013  2020]\n",
            "[21046  2020]\n",
            "[21063  2020]\n",
            "[21064  2020]\n",
            "[21073  2020]\n",
            "[21080  2020]\n",
            "[21084  2020]\n",
            "[21086  2020]\n",
            "[21094  2020]\n",
            "[21100  2020]\n",
            "[21108  2020]\n",
            "[21111  2020]\n",
            "[21119  2020]\n",
            "[21125  2020]\n",
            "[21126  2020]\n",
            "[21137  2020]\n",
            "[21154  2020]\n",
            "[21157  2020]\n",
            "[21163  2020]\n",
            "[21171  2020]\n",
            "[21175  2020]\n",
            "[21184  2020]\n",
            "[21191  2020]\n",
            "[21193  2020]\n",
            "[21205  2020]\n",
            "[21207  2020]\n",
            "[21208  2020]\n",
            "[21218  2020]\n",
            "[21220  2020]\n",
            "[21230  2020]\n",
            "[21231  2020]\n",
            "[21242  2020]\n",
            "[21245  2020]\n",
            "[21250  2020]\n",
            "[21253  2020]\n",
            "[21258  2020]\n",
            "[21262  2020]\n",
            "[21266  2020]\n",
            "[21269  2020]\n",
            "[21280  2020]\n",
            "[21299  2020]\n",
            "[21327  2020]\n",
            "[21333  2020]\n",
            "[21343  2020]\n",
            "[21350  2020]\n",
            "[21351  2020]\n",
            "[21358  2020]\n",
            "[21366  2020]\n",
            "[21367  2020]\n",
            "[21370  2020]\n",
            "[21382  2020]\n",
            "[21394  2020]\n",
            "[21400  2020]\n",
            "[21402  2020]\n",
            "[21403  2020]\n",
            "[21406  2020]\n",
            "[21411  2020]\n",
            "[21413  2020]\n",
            "[21418  2020]\n",
            "[21424  2020]\n",
            "[21426  2020]\n",
            "[21433  2020]\n",
            "[21442  2020]\n",
            "[21444  2020]\n",
            "[21473  2020]\n",
            "[21484  2020]\n",
            "[21497  2020]\n",
            "[21506  2020]\n",
            "[21508  2020]\n",
            "[21527  2020]\n",
            "[21534  2020]\n",
            "[21539  2020]\n",
            "[21544  2020]\n",
            "[21555  2020]\n",
            "[21558  2020]\n",
            "[21568  2020]\n",
            "[21569  2020]\n",
            "[21575  2020]\n",
            "[21578  2020]\n",
            "[21581  2020]\n",
            "[21587  2020]\n",
            "[21589  2020]\n",
            "[21600  2020]\n",
            "[21602  2020]\n",
            "[21603  2020]\n",
            "[21607  2020]\n",
            "[21614  2020]\n",
            "[21615  2020]\n",
            "[21617  2020]\n",
            "[21622  2020]\n",
            "[21624  2020]\n",
            "[21634  2020]\n",
            "[21636  2020]\n",
            "[21644  2020]\n",
            "[21650  2020]\n",
            "[21652  2020]\n",
            "[21659  2020]\n",
            "[21663  2020]\n",
            "[21665  2020]\n",
            "[21678  2020]\n",
            "[21679  2020]\n",
            "[21680  2020]\n",
            "[21718  2020]\n",
            "[21721  2020]\n",
            "[21745  2020]\n",
            "[21746  2020]\n",
            "[21759  2020]\n",
            "[21762  2020]\n",
            "[21772  2020]\n",
            "[21773  2020]\n",
            "[21785  2020]\n",
            "[21792  2020]\n",
            "[21801  2020]\n",
            "[21805  2020]\n",
            "[21817  2020]\n",
            "[21829  2020]\n",
            "[21834  2020]\n",
            "[21835  2020]\n",
            "[21838  2020]\n",
            "[21858  2020]\n",
            "[21880  2020]\n",
            "[21885  2020]\n",
            "[21886  2020]\n",
            "[21889  2020]\n",
            "[21892  2020]\n",
            "[21905  2020]\n",
            "[21912  2020]\n",
            "[21922  2020]\n",
            "[21943  2020]\n",
            "[21954  2020]\n",
            "[21959  2020]\n",
            "[21966  2020]\n",
            "[21969  2020]\n",
            "[21974  2020]\n",
            "[21993  2020]\n",
            "[22008  2020]\n",
            "[22011  2020]\n",
            "[22017  2020]\n",
            "[22027  2020]\n",
            "[22028  2020]\n",
            "[22051  2020]\n",
            "[22054  2020]\n",
            "[22055  2020]\n",
            "[22073  2020]\n",
            "[22074  2020]\n",
            "[22090  2020]\n",
            "[22110  2020]\n",
            "[22124  2020]\n",
            "[22130  2020]\n",
            "[22132  2020]\n",
            "[22135  2020]\n",
            "[22142  2020]\n",
            "[22143  2020]\n",
            "[22145  2020]\n",
            "[22146  2020]\n",
            "[22149  2020]\n",
            "[22152  2020]\n",
            "[22154  2020]\n",
            "[22165  2020]\n",
            "[22184  2020]\n",
            "[22198  2020]\n",
            "[22200  2020]\n",
            "[22205  2020]\n",
            "[22207  2020]\n",
            "[22212  2020]\n",
            "[22215  2020]\n",
            "[22230  2020]\n",
            "[22254  2020]\n",
            "[22267  2020]\n",
            "[22274  2020]\n",
            "[22288  2020]\n",
            "[22294  2020]\n",
            "[22298  2020]\n",
            "[22299  2020]\n",
            "[22303  2020]\n",
            "[22318  2020]\n",
            "[22322  2020]\n",
            "[22330  2020]\n",
            "[22335  2020]\n",
            "[22336  2020]\n",
            "[22337  2020]\n",
            "[22341  2020]\n",
            "[22342  2020]\n",
            "[22345  2020]\n",
            "[22351  2020]\n",
            "[22358  2020]\n",
            "[22368  2020]\n",
            "[22374  2020]\n",
            "[22375  2020]\n",
            "[22376  2020]\n",
            "[22379  2020]\n",
            "[22386  2020]\n",
            "[22395  2020]\n",
            "[22403  2020]\n",
            "[22407  2020]\n",
            "[22416  2020]\n",
            "[22417  2020]\n",
            "[22420  2020]\n",
            "[22421  2020]\n",
            "[22425  2020]\n",
            "[22428  2020]\n",
            "[22430  2020]\n",
            "[22438  2020]\n",
            "[22445  2020]\n",
            "[22448  2020]\n",
            "[22451  2020]\n",
            "[22459  2020]\n",
            "[22467  2020]\n",
            "[22472  2020]\n",
            "[22485  2020]\n",
            "[22517  2020]\n",
            "[22522  2020]\n",
            "[22524  2020]\n",
            "[22525  2020]\n",
            "[22526  2020]\n",
            "[22527  2020]\n",
            "[22528  2020]\n",
            "[22529  2020]\n",
            "[22530  2020]\n",
            "[22534  2020]\n",
            "[22541  2020]\n",
            "[22546  2020]\n",
            "[22559  2020]\n",
            "[22565  2020]\n",
            "[22601  2020]\n",
            "[22606  2020]\n",
            "[22618  2020]\n",
            "[22629  2020]\n",
            "[22639  2020]\n",
            "[22654  2020]\n",
            "[22661  2020]\n",
            "[22670  2020]\n",
            "[22671  2020]\n",
            "[22673  2020]\n",
            "[22698  2020]\n",
            "[22710  2020]\n",
            "[22726  2020]\n",
            "[22728  2020]\n",
            "[22743  2020]\n",
            "[22744  2020]\n",
            "[22748  2020]\n",
            "[22763  2020]\n",
            "[22768  2020]\n",
            "[22778  2020]\n",
            "[22779  2020]\n",
            "[22783  2020]\n",
            "[22789  2020]\n",
            "[22792  2020]\n",
            "[22799  2020]\n",
            "[22808  2020]\n",
            "[22813  2020]\n",
            "[22822  2020]\n",
            "[22829  2020]\n",
            "[22830  2020]\n",
            "[22831  2020]\n",
            "[22838  2020]\n",
            "[22858  2020]\n",
            "[22867  2020]\n",
            "[22868  2020]\n",
            "[22875  2020]\n",
            "[22893  2020]\n",
            "[22902  2020]\n",
            "[22906  2020]\n",
            "[22907  2020]\n",
            "[22911  2020]\n",
            "[22920  2020]\n",
            "[22925  2020]\n",
            "[22929  2020]\n",
            "[22931  2020]\n",
            "[22954  2020]\n",
            "[22958  2020]\n",
            "[22974  2020]\n",
            "[22976  2020]\n",
            "[22981  2020]\n",
            "[22983  2020]\n",
            "[22984  2020]\n",
            "[22985  2020]\n",
            "[23005  2020]\n",
            "[23026  2020]\n",
            "[23040  2020]\n",
            "[23044  2020]\n",
            "[23064  2020]\n",
            "[23074  2020]\n",
            "[23094  2020]\n",
            "[23103  2020]\n",
            "[23116  2020]\n",
            "[23121  2020]\n",
            "[23123  2020]\n",
            "[23125  2020]\n",
            "[23132  2020]\n",
            "[23137  2020]\n",
            "[23153  2020]\n",
            "[23176  2020]\n",
            "[23180  2020]\n",
            "[23181  2020]\n",
            "[23188  2020]\n",
            "[23189  2020]\n",
            "[23190  2020]\n",
            "[23197  2020]\n",
            "[23224  2020]\n",
            "[23240  2020]\n",
            "[23241  2020]\n",
            "[23242  2020]\n",
            "[23244  2020]\n",
            "[23251  2020]\n",
            "[23261  2020]\n",
            "[23271  2020]\n",
            "[23276  2020]\n",
            "[23278  2020]\n",
            "[23288  2020]\n",
            "[23290  2020]\n",
            "[23298  2020]\n",
            "[23302  2020]\n",
            "[23303  2020]\n",
            "[23309  2020]\n",
            "[23316  2020]\n",
            "[23322  2020]\n",
            "[23326  2020]\n",
            "[23332  2020]\n",
            "[23334  2020]\n",
            "[23341  2020]\n",
            "[23352  2020]\n",
            "[23353  2020]\n",
            "[23356  2020]\n",
            "[23363  2020]\n",
            "[23364  2020]\n",
            "[23370  2020]\n",
            "[23375  2020]\n",
            "[23376  2020]\n",
            "[23377  2020]\n",
            "[23380  2020]\n",
            "[23381  2020]\n",
            "[23389  2020]\n",
            "[23390  2020]\n",
            "[23391  2020]\n",
            "[23397  2020]\n",
            "[23400  2020]\n",
            "[23402  2020]\n",
            "[23404  2020]\n",
            "[23407  2020]\n",
            "[23430  2020]\n",
            "[23437  2020]\n",
            "[23440  2020]\n",
            "[23445  2020]\n",
            "[23456  2020]\n",
            "[23461  2020]\n",
            "[23464  2020]\n",
            "[23468  2020]\n",
            "[23470  2020]\n",
            "[23471  2020]\n",
            "[23473  2020]\n",
            "[23476  2020]\n",
            "[23479  2020]\n",
            "[23480  2020]\n",
            "[23481  2020]\n",
            "[23489  2020]\n",
            "[23492  2020]\n",
            "[23510  2020]\n",
            "[23514  2020]\n",
            "[23523  2020]\n",
            "[23532  2020]\n",
            "[23541  2020]\n",
            "[23544  2020]\n",
            "[23569  2020]\n",
            "[23575  2020]\n",
            "[23579  2020]\n",
            "[23584  2020]\n",
            "[23585  2020]\n",
            "[23589  2020]\n",
            "[23596  2020]\n",
            "[23598  2020]\n",
            "[23624  2020]\n",
            "[23628  2020]\n",
            "[23642  2020]\n",
            "[23646  2020]\n",
            "[23655  2020]\n",
            "[23656  2020]\n",
            "[23659  2020]\n",
            "[23670  2020]\n",
            "[23677  2020]\n",
            "[23684  2020]\n",
            "[23688  2020]\n",
            "[23695  2020]\n",
            "[23701  2020]\n",
            "[23702  2020]\n",
            "[23718  2020]\n",
            "[23728  2020]\n",
            "[23729  2020]\n",
            "[23733  2020]\n",
            "[23735  2020]\n",
            "[23736  2020]\n",
            "[23744  2020]\n",
            "[23746  2020]\n",
            "[23751  2020]\n",
            "[23763  2020]\n",
            "[23770  2020]\n",
            "[23776  2020]\n",
            "[23780  2020]\n",
            "[23782  2020]\n",
            "[23793  2020]\n",
            "[23794  2020]\n",
            "[23801  2020]\n",
            "[23835  2020]\n",
            "[23857  2020]\n",
            "[23859  2020]\n",
            "[23863  2020]\n",
            "[23869  2020]\n",
            "[23873  2020]\n",
            "[23894  2020]\n",
            "[23912  2020]\n",
            "[23913  2020]\n",
            "[23932  2020]\n",
            "[23942  2020]\n",
            "[23948  2020]\n",
            "[23949  2020]\n",
            "[23965  2020]\n",
            "[23969  2020]\n",
            "[23971  2020]\n",
            "[23978  2020]\n",
            "[23984  2020]\n",
            "[23993  2020]\n",
            "[24000  2020]\n",
            "[24009  2020]\n",
            "[24011  2020]\n",
            "[24018  2020]\n",
            "[24044  2020]\n",
            "[24051  2020]\n",
            "[24057  2020]\n",
            "[24064  2020]\n",
            "[24065  2020]\n",
            "[24074  2020]\n",
            "[24084  2020]\n",
            "[24094  2020]\n",
            "[24113  2020]\n",
            "[24114  2020]\n",
            "[24120  2020]\n",
            "[24125  2020]\n",
            "[24126  2020]\n",
            "[24139  2020]\n",
            "[24147  2020]\n",
            "[24148  2020]\n",
            "[24152  2020]\n",
            "[24165  2020]\n",
            "[24174  2020]\n",
            "[24188  2020]\n",
            "[24189  2020]\n",
            "[24193  2020]\n",
            "[24196  2020]\n",
            "[24201  2020]\n",
            "[24206  2020]\n",
            "[24210  2020]\n",
            "[24211  2020]\n",
            "[24219  2020]\n",
            "[24225  2020]\n",
            "[24231  2020]\n",
            "[24245  2020]\n",
            "[24257  2020]\n",
            "[24259  2020]\n",
            "[24266  2020]\n",
            "[24276  2020]\n",
            "[24278  2020]\n",
            "[24280  2020]\n",
            "[24290  2020]\n",
            "[24293  2020]\n",
            "[24294  2020]\n",
            "[24298  2020]\n",
            "[24299  2020]\n",
            "[24302  2020]\n",
            "[24313  2020]\n",
            "[24331  2020]\n",
            "[24345  2020]\n",
            "[24349  2020]\n",
            "[24350  2020]\n",
            "[24355  2020]\n",
            "[24379  2020]\n",
            "[24381  2020]\n",
            "[24395  2020]\n",
            "[24398  2020]\n",
            "[24425  2020]\n",
            "[24432  2020]\n",
            "[24434  2020]\n",
            "[24438  2020]\n",
            "[24446  2020]\n",
            "[24458  2020]\n",
            "[24461  2020]\n",
            "[24471  2020]\n",
            "[24478  2020]\n",
            "[24483  2020]\n",
            "[24484  2020]\n",
            "[24500  2020]\n",
            "[24502  2020]\n",
            "[24506  2020]\n",
            "[24513  2020]\n",
            "[24518  2020]\n",
            "[24520  2020]\n",
            "[24536  2020]\n",
            "[24537  2020]\n",
            "[24550  2020]\n",
            "[24551  2020]\n",
            "[24569  2020]\n",
            "[24572  2020]\n",
            "[24574  2020]\n",
            "[24575  2020]\n",
            "[24580  2020]\n",
            "[24590  2020]\n",
            "[24603  2020]\n",
            "[24608  2020]\n",
            "[24609  2020]\n",
            "[24643  2020]\n",
            "[24661  2020]\n",
            "[24665  2020]\n",
            "[24678  2020]\n",
            "[24690  2020]\n",
            "[24692  2020]\n",
            "[24697  2020]\n",
            "[24700  2020]\n",
            "[24707  2020]\n",
            "[24724  2020]\n",
            "[24727  2020]\n",
            "[24729  2020]\n",
            "[24749  2020]\n",
            "[24750  2020]\n",
            "[24772  2020]\n",
            "[24780  2020]\n",
            "[24789  2020]\n",
            "[24799  2020]\n",
            "[24808  2020]\n",
            "[24811  2020]\n",
            "[24815  2020]\n",
            "[24818  2020]\n",
            "[24819  2020]\n",
            "[24821  2020]\n",
            "[24870  2020]\n",
            "[24874  2020]\n",
            "[24877  2020]\n",
            "[24900  2020]\n",
            "[24914  2020]\n",
            "[24918  2020]\n",
            "[24923  2020]\n",
            "[24924  2020]\n",
            "[24925  2020]\n",
            "[24945  2020]\n",
            "[24949  2020]\n",
            "[24954  2020]\n",
            "[24962  2020]\n",
            "[24972  2020]\n",
            "[24978  2020]\n",
            "[24998  2020]\n",
            "[25001  2020]\n",
            "[25006  2020]\n",
            "[25007  2020]\n",
            "[25008  2020]\n",
            "[25023  2020]\n",
            "[25027  2020]\n",
            "[25029  2020]\n",
            "[25042  2020]\n",
            "[25069  2020]\n",
            "[25073  2020]\n",
            "[25082  2020]\n",
            "[25090  2020]\n",
            "[25117  2020]\n",
            "[25121  2020]\n",
            "[25126  2020]\n",
            "[25134  2020]\n",
            "[25143  2020]\n",
            "[25163  2020]\n",
            "[25164  2020]\n",
            "[25184  2020]\n",
            "[25185  2020]\n",
            "[25188  2020]\n",
            "[25191  2020]\n",
            "[25194  2020]\n",
            "[25197  2020]\n",
            "[25198  2020]\n",
            "[25200  2020]\n",
            "[25210  2020]\n",
            "[25217  2020]\n",
            "[25246  2020]\n",
            "[25247  2020]\n",
            "[25269  2020]\n",
            "[25270  2020]\n",
            "[25272  2020]\n",
            "[25288  2020]\n",
            "[25290  2020]\n",
            "[25295  2020]\n",
            "[25299  2020]\n",
            "[25302  2020]\n",
            "[25311  2020]\n",
            "[25312  2020]\n",
            "[25316  2020]\n",
            "[25319  2020]\n",
            "[25327  2020]\n",
            "[25333  2020]\n",
            "[25349  2020]\n",
            "[25358  2020]\n",
            "[25360  2020]\n",
            "[25363  2020]\n",
            "[25372  2020]\n",
            "[25375  2020]\n",
            "[25381  2020]\n",
            "[25385  2020]\n",
            "[25389  2020]\n",
            "[25390  2020]\n",
            "[25396  2020]\n",
            "[25400  2020]\n",
            "[25402  2020]\n",
            "[25405  2020]\n",
            "[25417  2020]\n",
            "[25421  2020]\n",
            "[25423  2020]\n",
            "[25433  2020]\n",
            "[25438  2020]\n",
            "[25443  2020]\n",
            "[25449  2020]\n",
            "[25451  2020]\n",
            "[25453  2020]\n",
            "[25465  2020]\n",
            "[25476  2020]\n",
            "[25484  2020]\n",
            "[25487  2020]\n",
            "[25492  2020]\n",
            "[25504  2020]\n",
            "[25523  2020]\n",
            "[25525  2020]\n",
            "[25529  2020]\n",
            "[25533  2020]\n",
            "[25540  2020]\n",
            "[25543  2020]\n",
            "[25549  2020]\n",
            "[25553  2020]\n",
            "[25558  2020]\n",
            "[25559  2020]\n",
            "[25561  2020]\n",
            "[25576  2020]\n",
            "[25583  2020]\n",
            "[25585  2020]\n",
            "[25587  2020]\n",
            "[25596  2020]\n",
            "[25605  2020]\n",
            "[25607  2020]\n",
            "[25612  2020]\n",
            "[25613  2020]\n",
            "[25622  2020]\n",
            "[25623  2020]\n",
            "[25632  2020]\n",
            "[25636  2020]\n",
            "[25644  2020]\n",
            "[25654  2020]\n",
            "[25656  2020]\n",
            "[25665  2020]\n",
            "[25669  2020]\n",
            "[25674  2020]\n",
            "[25684  2020]\n",
            "[25705  2020]\n",
            "[25709  2020]\n",
            "[25712  2020]\n",
            "[25716  2020]\n",
            "[25742  2020]\n",
            "[25744  2020]\n",
            "[25747  2020]\n",
            "[25751  2020]\n",
            "[25753  2020]\n",
            "[25773  2020]\n",
            "[25777  2020]\n",
            "[25804  2020]\n",
            "[25808  2020]\n",
            "[25811  2020]\n",
            "[25817  2020]\n",
            "[25830  2020]\n",
            "[25833  2020]\n",
            "[25836  2020]\n",
            "[25842  2020]\n",
            "[25858  2020]\n",
            "[25861  2020]\n",
            "[25866  2020]\n",
            "[25867  2020]\n",
            "[25873  2020]\n",
            "[25878  2020]\n",
            "[25897  2020]\n",
            "[25899  2020]\n",
            "[25901  2020]\n",
            "[25907  2020]\n",
            "[25912  2020]\n",
            "[25917  2020]\n",
            "[25937  2020]\n",
            "[25948  2020]\n",
            "[25955  2020]\n",
            "[25959  2020]\n",
            "[25987  2020]\n",
            "[25999  2020]\n",
            "[26000  2020]\n",
            "[26008  2020]\n",
            "[26010  2020]\n",
            "[26011  2020]\n",
            "[26015  2020]\n",
            "[26017  2020]\n",
            "[26020  2020]\n",
            "[26031  2020]\n",
            "[26041  2020]\n",
            "[26042  2020]\n",
            "[26045  2020]\n",
            "[26066  2020]\n",
            "[26071  2020]\n",
            "[26077  2020]\n",
            "[26082  2020]\n",
            "[26101  2020]\n",
            "[26118  2020]\n",
            "[26121  2020]\n",
            "[26125  2020]\n",
            "[26127  2020]\n",
            "[26131  2020]\n",
            "[26148  2020]\n",
            "[26159  2020]\n",
            "[26168  2020]\n",
            "[26172  2020]\n",
            "[26187  2020]\n",
            "[26191  2020]\n",
            "[26192  2020]\n",
            "[26198  2020]\n",
            "[26201  2020]\n",
            "[26209  2020]\n",
            "[26211  2020]\n",
            "[26215  2020]\n",
            "[26221  2020]\n",
            "[26246  2020]\n",
            "[26249  2020]\n",
            "[26255  2020]\n",
            "[26281  2020]\n",
            "[26282  2020]\n",
            "[26291  2020]\n",
            "[26305  2020]\n",
            "[26309  2020]\n",
            "[26317  2020]\n",
            "[26327  2020]\n",
            "[26343  2020]\n",
            "[26347  2020]\n",
            "[26367  2020]\n",
            "[26370  2020]\n",
            "[26376  2020]\n",
            "[26379  2020]\n",
            "[26381  2020]\n",
            "[26383  2020]\n",
            "[26390  2020]\n",
            "[26391  2020]\n",
            "[26404  2020]\n",
            "[45725  2020]\n",
            "[45733  2020]\n",
            "[45743  2020]\n",
            "[45771  2020]\n",
            "[45789  2020]\n",
            "[45810  2020]\n",
            "[45816  2020]\n",
            "[45855  2020]\n",
            "[45863  2020]\n",
            "[45872  2020]\n",
            "[45879  2020]\n",
            "[45892  2020]\n",
            "[45943  2020]\n",
            "[45948  2020]\n",
            "[45960  2020]\n",
            "[46011  2020]\n",
            "[46046  2020]\n",
            "[46067  2020]\n",
            "[46080  2020]\n",
            "[46092  2020]\n",
            "[46118  2020]\n",
            "[46125  2020]\n",
            "[46165  2020]\n",
            "[46314  2020]\n",
            "[46320  2020]\n",
            "[46323  2020]\n",
            "[46335  2020]\n",
            "[46342  2020]\n",
            "[46365  2020]\n",
            "[46371  2020]\n",
            "[46401  2020]\n",
            "[46405  2020]\n",
            "[46443  2020]\n",
            "[46449  2020]\n",
            "[46452  2020]\n",
            "[46466  2020]\n",
            "[46478  2020]\n",
            "[46480  2020]\n",
            "[46481  2020]\n",
            "[46508  2020]\n",
            "[46521  2020]\n",
            "[46556  2020]\n",
            "[46579  2020]\n",
            "[46620  2020]\n",
            "[46632  2020]\n",
            "[46634  2020]\n",
            "[46636  2020]\n",
            "[46683  2020]\n",
            "[46689  2020]\n",
            "[46693  2020]\n",
            "[46694  2020]\n",
            "[46695  2020]\n",
            "[46720  2020]\n",
            "[46721  2020]\n",
            "[46727  2020]\n",
            "[46728  2020]\n",
            "[46750  2020]\n",
            "[46752  2020]\n",
            "[46762  2020]\n",
            "[46768  2020]\n",
            "[46771  2020]\n",
            "[46777  2020]\n",
            "[46778  2020]\n",
            "[46779  2020]\n",
            "[46812  2020]\n",
            "[46834  2020]\n",
            "[46835  2020]\n",
            "[46849  2020]\n",
            "[46871  2020]\n",
            "[46877  2020]\n",
            "[46895  2020]\n",
            "[46900  2020]\n",
            "[46943  2020]\n",
            "[46955  2020]\n",
            "[46958  2020]\n",
            "[46962  2020]\n",
            "[46977  2020]\n",
            "[46979  2020]\n",
            "[47004  2020]\n",
            "[47030  2020]\n",
            "[47043  2020]\n",
            "[47057  2020]\n",
            "[47059  2020]\n",
            "[47067  2020]\n",
            "[47096  2020]\n",
            "[47111  2020]\n",
            "[47119  2020]\n",
            "[47157  2020]\n",
            "[47164  2020]\n",
            "[47208  2020]\n",
            "[47230  2020]\n",
            "[47253  2020]\n",
            "[47254  2020]\n",
            "[47255  2020]\n",
            "[47291  2020]\n",
            "[47294  2020]\n",
            "[47301  2020]\n",
            "[47304  2020]\n",
            "[47312  2020]\n",
            "[47315  2020]\n",
            "[47334  2020]\n",
            "[47347  2020]\n",
            "[47351  2020]\n",
            "[47358  2020]\n",
            "[47361  2020]\n",
            "[47390  2020]\n",
            "[47401  2020]\n",
            "[47439  2020]\n",
            "[47470  2020]\n",
            "[47471  2020]\n",
            "[47519  2020]\n",
            "[47526  2020]\n",
            "[47553  2020]\n",
            "[47565  2020]\n",
            "[47572  2020]\n",
            "[47588  2020]\n",
            "[47590  2020]\n",
            "[47591  2020]\n",
            "[47595  2020]\n",
            "[47617  2020]\n",
            "[47635  2020]\n",
            "[47660  2020]\n",
            "[47673  2020]\n",
            "[47677  2020]\n",
            "[47678  2020]\n",
            "[47679  2020]\n",
            "[47689  2020]\n",
            "[47707  2020]\n",
            "[47712  2020]\n",
            "[47721  2020]\n",
            "[47724  2020]\n",
            "[47729  2020]\n",
            "[47774  2020]\n",
            "[47806  2020]\n",
            "[47820  2020]\n",
            "[47848  2020]\n",
            "[47858  2020]\n",
            "[47868  2020]\n",
            "[47870  2020]\n",
            "[47883  2020]\n",
            "[47887  2020]\n",
            "[47888  2020]\n",
            "[47906  2020]\n",
            "[47907  2020]\n",
            "[47927  2020]\n",
            "[47956  2020]\n",
            "[47963  2020]\n",
            "[47972  2020]\n",
            "[47976  2020]\n",
            "[47985  2020]\n",
            "[47987  2020]\n",
            "[48008  2020]\n",
            "[48029  2020]\n",
            "[48034  2020]\n",
            "[48039  2020]\n",
            "[48049  2020]\n",
            "[48076  2020]\n",
            "[48078  2020]\n",
            "[48095  2020]\n",
            "[48107  2020]\n",
            "[48115  2020]\n",
            "[48120  2020]\n",
            "[48134  2020]\n",
            "[48138  2020]\n",
            "[48144  2020]\n",
            "[48150  2020]\n",
            "[48161  2020]\n",
            "[48209  2020]\n",
            "[48235  2020]\n",
            "[48237  2020]\n",
            "[48262  2020]\n",
            "[48278  2020]\n",
            "[48297  2020]\n",
            "[48298  2020]\n",
            "[48316  2020]\n",
            "[48321  2020]\n",
            "[48331  2020]\n",
            "[48334  2020]\n",
            "[48359  2020]\n",
            "[48366  2020]\n",
            "[48371  2020]\n",
            "[48387  2020]\n",
            "[48408  2020]\n",
            "[48420  2020]\n",
            "[48431  2020]\n",
            "[48467  2020]\n",
            "[48473  2020]\n",
            "[48478  2020]\n",
            "[48481  2020]\n",
            "[48520  2020]\n",
            "[48522  2020]\n",
            "[48538  2020]\n",
            "[48558  2020]\n",
            "[48614  2020]\n",
            "[48623  2020]\n",
            "[48647  2020]\n",
            "[48648  2020]\n",
            "[48657  2020]\n",
            "[48661  2020]\n",
            "[48662  2020]\n",
            "[48678  2020]\n",
            "[48710  2020]\n",
            "[48711  2020]\n",
            "[48748  2020]\n",
            "[48776  2020]\n",
            "[48782  2020]\n",
            "[48800  2020]\n",
            "[48841  2020]\n",
            "[48861  2020]\n",
            "[48875  2020]\n",
            "[48944  2020]\n",
            "[48973  2020]\n",
            "[48989  2020]\n",
            "[49020  2020]\n",
            "[49029  2020]\n",
            "[49035  2020]\n",
            "[49058  2020]\n",
            "[49082  2020]\n",
            "[49109  2020]\n",
            "[49115  2020]\n",
            "[49150  2020]\n",
            "[49178  2020]\n",
            "[49181  2020]\n",
            "[49187  2020]\n",
            "[49192  2020]\n",
            "[49199  2020]\n",
            "[49221  2020]\n",
            "[49226  2020]\n",
            "[49254  2020]\n",
            "[49256  2020]\n",
            "[49261  2020]\n",
            "[49273  2020]\n",
            "[49318  2020]\n",
            "[49324  2020]\n",
            "[49330  2020]\n",
            "[49335  2020]\n",
            "[49360  2020]\n",
            "[49362  2020]\n",
            "[49364  2020]\n",
            "[49376  2020]\n",
            "[49394  2020]\n",
            "[49462  2020]\n",
            "[49469  2020]\n",
            "[49491  2020]\n",
            "[49500  2020]\n",
            "[49525  2020]\n",
            "[49552  2020]\n",
            "[49560  2020]\n",
            "[49568  2020]\n",
            "[49581  2020]\n",
            "[49617  2020]\n",
            "[49623  2020]\n",
            "[49647  2020]\n",
            "[49658  2020]\n",
            "[49666  2020]\n",
            "[49681  2020]\n",
            "[49683  2020]\n",
            "[49706  2020]\n",
            "[49709  2020]\n",
            "[49718  2020]\n",
            "[49720  2020]\n",
            "[49723  2020]\n",
            "[49767  2020]\n",
            "[49771  2020]\n",
            "[49777  2020]\n",
            "[49822  2020]\n",
            "[49824  2020]\n",
            "[49828  2020]\n",
            "[49833  2020]\n",
            "[49847  2020]\n",
            "[49869  2020]\n",
            "[49882  2020]\n",
            "[49905  2020]\n",
            "[49933  2020]\n",
            "[49960  2020]\n",
            "[49964  2020]\n",
            "[49967  2020]\n",
            "[50038  2020]\n",
            "[50076  2020]\n",
            "[50097  2020]\n",
            "[50131  2020]\n",
            "[50132  2020]\n",
            "[50148  2020]\n",
            "[50180  2020]\n",
            "[50181  2020]\n",
            "[50187  2020]\n",
            "[50190  2020]\n",
            "[50218  2020]\n",
            "[50245  2020]\n",
            "[50246  2020]\n",
            "[50257  2020]\n",
            "[50261  2020]\n",
            "[50285  2020]\n",
            "[50292  2020]\n",
            "[50304  2020]\n",
            "[50306  2020]\n",
            "[50326  2020]\n",
            "[50329  2020]\n",
            "[50338  2020]\n",
            "[50341  2020]\n",
            "[50351  2020]\n",
            "[50353  2020]\n",
            "[50360  2020]\n",
            "[50378  2020]\n",
            "[50385  2020]\n",
            "[50419  2020]\n",
            "[50426  2020]\n",
            "[50442  2020]\n",
            "[50443  2020]\n",
            "[50464  2020]\n",
            "[50474  2020]\n",
            "[50478  2020]\n",
            "[50496  2020]\n",
            "[50502  2020]\n",
            "[50504  2020]\n",
            "[50512  2020]\n",
            "[50513  2020]\n",
            "[50514  2020]\n",
            "[50531  2020]\n",
            "[50565  2020]\n",
            "[50568  2020]\n",
            "[50573  2020]\n",
            "[50596  2020]\n",
            "[50610  2020]\n",
            "[50614  2020]\n",
            "[50616  2020]\n",
            "[50619  2020]\n",
            "[50636  2020]\n",
            "[50642  2020]\n",
            "[50646  2020]\n",
            "[50649  2020]\n",
            "[50669  2020]\n",
            "[50691  2020]\n",
            "[50711  2020]\n",
            "[50720  2020]\n",
            "[50738  2020]\n",
            "[50748  2020]\n",
            "[50820  2020]\n",
            "[50828  2020]\n",
            "[50837  2020]\n",
            "[50840  2020]\n",
            "[50875  2020]\n",
            "[50879  2020]\n",
            "[50907  2020]\n",
            "[50918  2020]\n",
            "[50921  2020]\n",
            "[50932  2020]\n",
            "[50950  2020]\n",
            "[50970  2020]\n",
            "[50995  2020]\n",
            "[51008  2020]\n",
            "[51041  2020]\n",
            "[51063  2020]\n",
            "[51068  2020]\n",
            "[51087  2020]\n",
            "[51101  2020]\n",
            "[51111  2020]\n",
            "[51136  2020]\n",
            "[51144  2020]\n",
            "[51147  2020]\n",
            "[51167  2020]\n",
            "[51181  2020]\n",
            "[51184  2020]\n",
            "[51190  2020]\n",
            "[51200  2020]\n",
            "[51248  2020]\n",
            "[51251  2020]\n",
            "[51263  2020]\n",
            "[51292  2020]\n",
            "[51314  2020]\n",
            "[51325  2020]\n",
            "[51346  2020]\n",
            "[51351  2020]\n",
            "[51360  2020]\n",
            "[51377  2020]\n",
            "[51379  2020]\n",
            "[51387  2020]\n",
            "[51391  2020]\n",
            "[51419  2020]\n",
            "[51435  2020]\n",
            "[51456  2020]\n",
            "[51491  2020]\n",
            "[51496  2020]\n",
            "[51504  2020]\n",
            "[51513  2020]\n",
            "[51517  2020]\n",
            "[51535  2020]\n",
            "[51540  2020]\n",
            "[51549  2020]\n",
            "[51569  2020]\n",
            "[51576  2020]\n",
            "[51583  2020]\n",
            "[51587  2020]\n",
            "[51612  2020]\n",
            "[51617  2020]\n",
            "[51670  2020]\n",
            "[51692  2020]\n",
            "[51696  2020]\n",
            "[51714  2020]\n",
            "[51740  2020]\n",
            "[51756  2020]\n",
            "[51758  2020]\n",
            "[51762  2020]\n",
            "[51777  2020]\n",
            "[51782  2020]\n",
            "[51799  2020]\n",
            "[51802  2020]\n",
            "[51807  2020]\n",
            "[51812  2020]\n",
            "[51838  2020]\n",
            "[51874  2020]\n",
            "[51878  2020]\n",
            "[51914  2020]\n",
            "[51930  2020]\n",
            "[51937  2020]\n",
            "[51944  2020]\n",
            "[51977  2020]\n",
            "[51979  2020]\n",
            "[51997  2020]\n",
            "[52018  2020]\n",
            "[52043  2020]\n",
            "[52047  2020]\n",
            "[52071  2020]\n",
            "[52075  2020]\n",
            "[52086  2020]\n",
            "[52110  2020]\n",
            "[52121  2020]\n",
            "[52145  2020]\n",
            "[52157  2020]\n",
            "[52205  2020]\n",
            "[52229  2020]\n",
            "[52244  2020]\n",
            "[52245  2020]\n",
            "[52265  2020]\n",
            "[52270  2020]\n",
            "[52278  2020]\n",
            "[52300  2020]\n",
            "[52310  2020]\n",
            "[52315  2020]\n",
            "[52320  2020]\n",
            "[52342  2020]\n",
            "[52357  2020]\n",
            "[52361  2020]\n",
            "[52363  2020]\n",
            "[52397  2020]\n",
            "[52416  2020]\n",
            "[52444  2020]\n",
            "[52445  2020]\n",
            "[52464  2020]\n",
            "[52485  2020]\n",
            "[52487  2020]\n",
            "[52501  2020]\n",
            "[52506  2020]\n",
            "[52530  2020]\n",
            "[52531  2020]\n",
            "[52596  2020]\n",
            "[52597  2020]\n",
            "[52606  2020]\n",
            "[52639  2020]\n",
            "[52657  2020]\n",
            "[52672  2020]\n",
            "[52684  2020]\n",
            "[52725  2020]\n",
            "[52731  2020]\n",
            "[52751  2020]\n",
            "[52760  2020]\n",
            "[52783  2020]\n",
            "[52791  2020]\n",
            "[52799  2020]\n",
            "[52802  2020]\n",
            "[52803  2020]\n",
            "[52811  2020]\n",
            "[52818  2020]\n",
            "[52827  2020]\n",
            "[52838  2020]\n",
            "[52847  2020]\n",
            "[52856  2020]\n",
            "[52866  2020]\n",
            "[52869  2020]\n",
            "[52871  2020]\n",
            "[52875  2020]\n",
            "[52882  2020]\n",
            "[52895  2020]\n",
            "[52896  2020]\n",
            "[52897  2020]\n",
            "[52901  2020]\n",
            "[52904  2020]\n",
            "[52913  2020]\n",
            "[52944  2020]\n",
            "[52948  2020]\n",
            "[52960  2020]\n",
            "[52993  2020]\n",
            "[53006  2020]\n",
            "[53012  2020]\n",
            "[53030  2020]\n",
            "[53052  2020]\n",
            "[53054  2020]\n",
            "[53057  2020]\n",
            "[53078  2020]\n",
            "[53088  2020]\n",
            "[53090  2020]\n",
            "[53094  2020]\n",
            "[53105  2020]\n",
            "[53109  2020]\n",
            "[53113  2020]\n",
            "[53114  2020]\n",
            "[53119  2020]\n",
            "[53179  2020]\n",
            "[53180  2020]\n",
            "[53230  2020]\n",
            "[53232  2020]\n",
            "[53233  2020]\n",
            "[53240  2020]\n",
            "[53267  2020]\n",
            "[53271  2020]\n",
            "[53279  2020]\n",
            "[53286  2020]\n",
            "[53296  2020]\n",
            "[53351  2020]\n",
            "[53383  2020]\n",
            "[53394  2020]\n",
            "[53404  2020]\n",
            "[53421  2020]\n",
            "[53422  2020]\n",
            "[53430  2020]\n",
            "[53440  2020]\n",
            "[53485  2020]\n",
            "[53501  2020]\n",
            "[53525  2020]\n",
            "[53540  2020]\n",
            "[53577  2020]\n",
            "[53578  2020]\n",
            "[53589  2020]\n",
            "[53604  2020]\n",
            "[53607  2020]\n",
            "[53608  2020]\n",
            "[53614  2020]\n",
            "[53625  2020]\n",
            "[53633  2020]\n",
            "[53657  2020]\n",
            "[53677  2020]\n",
            "[53684  2020]\n",
            "[53695  2020]\n",
            "[53719  2020]\n",
            "[53726  2020]\n",
            "[53727  2020]\n",
            "[53733  2020]\n",
            "[53747  2020]\n",
            "[53748  2020]\n",
            "[53749  2020]\n",
            "[53753  2020]\n",
            "[53772  2020]\n",
            "[53787  2020]\n",
            "[53794  2020]\n",
            "[53797  2020]\n",
            "[53812  2020]\n",
            "[53826  2020]\n",
            "[53852  2020]\n",
            "[53856  2020]\n",
            "[53871  2020]\n",
            "[53880  2020]\n",
            "[53884  2020]\n",
            "[53895  2020]\n",
            "[53896  2020]\n",
            "[53898  2020]\n",
            "[53911  2020]\n",
            "[53940  2020]\n",
            "[53952  2020]\n",
            "[53960  2020]\n",
            "[54031  2020]\n",
            "[54034  2020]\n",
            "[54046  2020]\n",
            "[54069  2020]\n",
            "[54073  2020]\n",
            "[54086  2020]\n",
            "[54088  2020]\n",
            "[54093  2020]\n",
            "[54103  2020]\n",
            "[54129  2020]\n",
            "[54137  2020]\n",
            "[54232  2020]\n",
            "[54236  2020]\n",
            "[54237  2020]\n",
            "[54242  2020]\n",
            "[54255  2020]\n",
            "[54256  2020]\n",
            "[54265  2020]\n",
            "[54273  2020]\n",
            "[54277  2020]\n",
            "[54282  2020]\n",
            "[54287  2020]\n",
            "[54305  2020]\n",
            "[54308  2020]\n",
            "[54323  2020]\n",
            "[54334  2020]\n",
            "[54343  2020]\n",
            "[54357  2020]\n",
            "[54377  2020]\n",
            "[54380  2020]\n",
            "[54417  2020]\n",
            "[54430  2020]\n",
            "[54449  2020]\n",
            "[54452  2020]\n",
            "[54454  2020]\n",
            "[54475  2020]\n",
            "[54484  2020]\n",
            "[54516  2020]\n",
            "[54531  2020]\n",
            "[54573  2020]\n",
            "[54592  2020]\n",
            "[54593  2020]\n",
            "[54629  2020]\n",
            "[54632  2020]\n",
            "[54637  2020]\n",
            "[54663  2020]\n",
            "[54665  2020]\n",
            "[54713  2020]\n",
            "[54717  2020]\n",
            "[54723  2020]\n",
            "[54731  2020]\n",
            "[54734  2020]\n",
            "[54754  2020]\n",
            "[54766  2020]\n",
            "[54782  2020]\n",
            "[54804  2020]\n",
            "[54817  2020]\n",
            "[54818  2020]\n",
            "[54852  2020]\n",
            "[54864  2020]\n",
            "[54865  2020]\n",
            "[54874  2020]\n",
            "[4716 2020]\n",
            "[4735 2020]\n",
            "[4738 2020]\n",
            "[4739 2020]\n",
            "[4741 2020]\n",
            "[4747 2020]\n",
            "[4752 2020]\n",
            "[4753 2020]\n",
            "[4754 2020]\n",
            "[4762 2020]\n",
            "[4772 2020]\n",
            "[4783 2020]\n",
            "[4797 2020]\n",
            "[4800 2020]\n",
            "[4808 2020]\n",
            "[4810 2020]\n",
            "[4813 2020]\n",
            "[4817 2020]\n",
            "[4834 2020]\n",
            "[4877 2020]\n",
            "[4897 2020]\n",
            "[4898 2020]\n",
            "[4901 2020]\n",
            "[4923 2020]\n",
            "[4925 2020]\n",
            "[4938 2020]\n",
            "[4946 2020]\n",
            "[4960 2020]\n",
            "[4962 2020]\n",
            "[4967 2020]\n",
            "[4991 2020]\n",
            "[5017 2020]\n",
            "[5021 2020]\n",
            "[5029 2020]\n",
            "[5037 2020]\n",
            "[5051 2020]\n",
            "[5065 2020]\n",
            "[5076 2020]\n",
            "[5088 2020]\n",
            "[5107 2020]\n",
            "[5137 2020]\n",
            "[5192 2020]\n",
            "[5236 2020]\n",
            "[5288 2020]\n",
            "[5290 2020]\n",
            "[5305 2020]\n",
            "[5307 2020]\n",
            "[5329 2020]\n",
            "[5361 2020]\n",
            "[5366 2020]\n",
            "[5386 2020]\n",
            "[5420 2020]\n",
            "[5423 2020]\n",
            "[5433 2020]\n",
            "[5451 2020]\n",
            "[5454 2020]\n",
            "[5460 2020]\n",
            "[5469 2020]\n",
            "[5482 2020]\n",
            "[5522 2020]\n",
            "[5543 2020]\n",
            "[5570 2020]\n",
            "[5574 2020]\n",
            "[5581 2020]\n",
            "[5583 2020]\n",
            "[5584 2020]\n",
            "[5611 2020]\n",
            "[5632 2020]\n",
            "[5638 2020]\n",
            "[5643 2020]\n",
            "[5671 2020]\n",
            "[5676 2020]\n",
            "[5678 2020]\n",
            "[5691 2020]\n",
            "[5699 2020]\n",
            "[5708 2020]\n",
            "[5710 2020]\n",
            "[5711 2020]\n",
            "[5746 2020]\n",
            "[5747 2020]\n",
            "[5753 2020]\n",
            "[5771 2020]\n",
            "[5779 2020]\n",
            "[5781 2020]\n",
            "[5782 2020]\n",
            "[5789 2020]\n",
            "[5795 2020]\n",
            "[5829 2020]\n",
            "[5843 2020]\n",
            "[46234  2020]\n",
            "[46263  2020]\n",
            "[46269  2020]\n",
            "[46272  2020]\n",
            "[46289  2020]\n",
            "[46298  2020]\n",
            "[54947  2020]\n",
            "[54982  2020]\n",
            "[55013  2020]\n",
            "[55019  2020]\n",
            "[55045  2020]\n",
            "[55055  2020]\n",
            "[55066  2020]\n",
            "[55075  2020]\n",
            "[55080  2020]\n",
            "[55081  2020]\n",
            "[55131  2020]\n",
            "[55152  2020]\n",
            "[55172  2020]\n",
            "[55194  2020]\n",
            "[55215  2020]\n",
            "[55262  2020]\n",
            "[55269  2020]\n",
            "[55271  2020]\n",
            "[55273  2020]\n",
            "[55283  2020]\n",
            "[55292  2020]\n",
            "[55312  2020]\n",
            "[55336  2020]\n",
            "[55372  2020]\n",
            "[55385  2020]\n",
            "[55402  2020]\n",
            "[55455  2020]\n",
            "[55466  2020]\n",
            "[55468  2020]\n",
            "[55470  2020]\n",
            "[55479  2020]\n",
            "[55493  2020]\n",
            "[55497  2020]\n",
            "[55502  2020]\n",
            "[55506  2020]\n",
            "[55514  2020]\n",
            "[55524  2020]\n",
            "[55532  2020]\n",
            "[55536  2020]\n",
            "[55542  2020]\n",
            "[55544  2020]\n",
            "[55555  2020]\n",
            "[55565  2020]\n",
            "[55569  2020]\n",
            "[55580  2020]\n",
            "[55600  2020]\n",
            "[55607  2020]\n",
            "[55618  2020]\n",
            "[55627  2020]\n",
            "[55634  2020]\n",
            "[55640  2020]\n",
            "[55668  2020]\n",
            "[55684  2020]\n",
            "[55751  2020]\n",
            "[55767  2020]\n",
            "[55783  2020]\n",
            "[55784  2020]\n",
            "[55788  2020]\n",
            "[55801  2020]\n",
            "[55819  2020]\n",
            "[55844  2020]\n",
            "[55848  2020]\n",
            "[55881  2020]\n",
            "[55898  2020]\n",
            "[55927  2020]\n",
            "[55931  2020]\n",
            "[55947  2020]\n",
            "[55962  2020]\n",
            "[55970  2020]\n",
            "[55989  2020]\n",
            "[55991  2020]\n",
            "[55999  2020]\n",
            "[56000  2020]\n",
            "[56030  2020]\n",
            "[56038  2020]\n",
            "[56045  2020]\n",
            "[56058  2020]\n",
            "[56060  2020]\n",
            "[56103  2020]\n",
            "[56126  2020]\n",
            "[56159  2020]\n",
            "[56186  2020]\n",
            "[56242  2020]\n",
            "[56254  2020]\n",
            "[56256  2020]\n",
            "[56257  2020]\n",
            "[56273  2020]\n",
            "[56305  2020]\n",
            "[56307  2020]\n",
            "[56326  2020]\n",
            "[56378  2020]\n",
            "[56407  2020]\n",
            "[56418  2020]\n",
            "[56426  2020]\n",
            "[56438  2020]\n",
            "[56461  2020]\n",
            "[56515  2020]\n",
            "[56516  2020]\n",
            "[56518  2020]\n",
            "[56520  2020]\n",
            "[56523  2020]\n",
            "[56533  2020]\n",
            "[56558  2020]\n",
            "[56562  2020]\n",
            "[56569  2020]\n",
            "[56571  2020]\n",
            "[56576  2020]\n",
            "[56618  2020]\n",
            "[56621  2020]\n",
            "[56640  2020]\n",
            "[56657  2020]\n",
            "[56720  2020]\n",
            "[56741  2020]\n",
            "[56742  2020]\n",
            "[56755  2020]\n",
            "[56759  2020]\n",
            "[56764  2020]\n",
            "[56798  2020]\n",
            "[56807  2020]\n",
            "[56820  2020]\n",
            "[56829  2020]\n",
            "[56863  2020]\n",
            "[56866  2020]\n",
            "[56931  2020]\n",
            "[56933  2020]\n",
            "[56944  2020]\n",
            "[56946  2020]\n",
            "[56969  2020]\n",
            "[57001  2020]\n",
            "[57046  2020]\n",
            "[57059  2020]\n",
            "[57062  2020]\n",
            "[6376 2020]\n",
            "[26439  2020]\n",
            "[26442  2020]\n",
            "[26445  2020]\n",
            "[26448  2020]\n",
            "[26450  2020]\n",
            "[26460  2020]\n",
            "[26477  2020]\n",
            "[26480  2020]\n",
            "[26486  2020]\n",
            "[26487  2020]\n",
            "[26503  2020]\n",
            "[26512  2020]\n",
            "[26516  2020]\n",
            "[26517  2020]\n",
            "[26520  2020]\n",
            "[26522  2020]\n",
            "[26524  2020]\n",
            "[26526  2020]\n",
            "[26566  2020]\n",
            "[26593  2020]\n",
            "[26604  2020]\n",
            "[26607  2020]\n",
            "[26613  2020]\n",
            "[26615  2020]\n",
            "[26616  2020]\n",
            "[26626  2020]\n",
            "[26635  2020]\n",
            "[26637  2020]\n",
            "[26646  2020]\n",
            "[26647  2020]\n",
            "[26666  2020]\n",
            "[26671  2020]\n",
            "[26679  2020]\n",
            "[26688  2020]\n",
            "[26691  2020]\n",
            "[26692  2020]\n",
            "[26699  2020]\n",
            "[26706  2020]\n",
            "[26710  2020]\n",
            "[26720  2020]\n",
            "[26723  2020]\n",
            "[26724  2020]\n",
            "[26728  2020]\n",
            "[26730  2020]\n",
            "[26731  2020]\n",
            "[26737  2020]\n",
            "[26750  2020]\n",
            "[26759  2020]\n",
            "[26770  2020]\n",
            "[26771  2020]\n",
            "[26774  2020]\n",
            "[26777  2020]\n",
            "[26784  2020]\n",
            "[26786  2020]\n",
            "[26791  2020]\n",
            "[26799  2020]\n",
            "[26806  2020]\n",
            "[26812  2020]\n",
            "[26826  2020]\n",
            "[26828  2020]\n",
            "[26844  2020]\n",
            "[26850  2020]\n",
            "[26853  2020]\n",
            "[26855  2020]\n",
            "[26869  2020]\n",
            "[26888  2020]\n",
            "[26890  2020]\n",
            "[26891  2020]\n",
            "[26903  2020]\n",
            "[26906  2020]\n",
            "[26913  2020]\n",
            "[26927  2020]\n",
            "[26940  2020]\n",
            "[26964  2020]\n",
            "[26966  2020]\n",
            "[26987  2020]\n",
            "[26995  2020]\n",
            "[27003  2020]\n",
            "[27006  2020]\n",
            "[27016  2020]\n",
            "[27027  2020]\n",
            "[27041  2020]\n",
            "[27046  2020]\n",
            "[27050  2020]\n",
            "[27062  2020]\n",
            "[27067  2020]\n",
            "[27068  2020]\n",
            "[27070  2020]\n",
            "[27077  2020]\n",
            "[27083  2020]\n",
            "[27084  2020]\n",
            "[27092  2020]\n",
            "[27101  2020]\n",
            "[27107  2020]\n",
            "[27108  2020]\n",
            "[27122  2020]\n",
            "[27143  2020]\n",
            "[27144  2020]\n",
            "[27162  2020]\n",
            "[27165  2020]\n",
            "[27167  2020]\n",
            "[27170  2020]\n",
            "[27175  2020]\n",
            "[27193  2020]\n",
            "[27198  2020]\n",
            "[27207  2020]\n",
            "[27209  2020]\n",
            "[27212  2020]\n",
            "[27215  2020]\n",
            "[27220  2020]\n",
            "[27238  2020]\n",
            "[27255  2020]\n",
            "[27269  2020]\n",
            "[27270  2020]\n",
            "[27273  2020]\n",
            "[27277  2020]\n",
            "[27282  2020]\n",
            "[27285  2020]\n",
            "[27293  2020]\n",
            "[27299  2020]\n",
            "[27300  2020]\n",
            "[27302  2020]\n",
            "[27307  2020]\n",
            "[27332  2020]\n",
            "[27387  2020]\n",
            "[27390  2020]\n",
            "[27391  2020]\n",
            "[27396  2020]\n",
            "[27403  2020]\n",
            "[27410  2020]\n",
            "[27418  2020]\n",
            "[27422  2020]\n",
            "[27425  2020]\n",
            "[27437  2020]\n",
            "[27440  2020]\n",
            "[27461  2020]\n",
            "[27496  2020]\n",
            "[27497  2020]\n",
            "[27500  2020]\n",
            "[27518  2020]\n",
            "[27523  2020]\n",
            "[27524  2020]\n",
            "[27538  2020]\n",
            "[27540  2020]\n",
            "[27551  2020]\n",
            "[27553  2020]\n",
            "[27587  2020]\n",
            "[27591  2020]\n",
            "[27599  2020]\n",
            "[27609  2020]\n",
            "[27619  2020]\n",
            "[27621  2020]\n",
            "[27629  2020]\n",
            "[27632  2020]\n",
            "[27635  2020]\n",
            "[27638  2020]\n",
            "[27655  2020]\n",
            "[27658  2020]\n",
            "[27659  2020]\n",
            "[27673  2020]\n",
            "[27676  2020]\n",
            "[27679  2020]\n",
            "[27686  2020]\n",
            "[27688  2020]\n",
            "[27691  2020]\n",
            "[27710  2020]\n",
            "[27715  2020]\n",
            "[27716  2020]\n",
            "[27718  2020]\n",
            "[27720  2020]\n",
            "[27736  2020]\n",
            "[27746  2020]\n",
            "[27749  2020]\n",
            "[27757  2020]\n",
            "[27759  2020]\n",
            "[27760  2020]\n",
            "[27761  2020]\n",
            "[27774  2020]\n",
            "[27779  2020]\n",
            "[27780  2020]\n",
            "[27786  2020]\n",
            "[27805  2020]\n",
            "[27806  2020]\n",
            "[27812  2020]\n",
            "[27821  2020]\n",
            "[27830  2020]\n",
            "[27841  2020]\n",
            "[27852  2020]\n",
            "[27863  2020]\n",
            "[27865  2020]\n",
            "[27866  2020]\n",
            "[27867  2020]\n",
            "[27871  2020]\n",
            "[27878  2020]\n",
            "[27885  2020]\n",
            "[27890  2020]\n",
            "[27894  2020]\n",
            "[27903  2020]\n",
            "[27912  2020]\n",
            "[27925  2020]\n",
            "[27928  2020]\n",
            "[27939  2020]\n",
            "[27957  2020]\n",
            "[27983  2020]\n",
            "[27985  2020]\n",
            "[28006  2020]\n",
            "[28008  2020]\n",
            "[28010  2020]\n",
            "[28014  2020]\n",
            "[28016  2020]\n",
            "[28017  2020]\n",
            "[28023  2020]\n",
            "[28033  2020]\n",
            "[28037  2020]\n",
            "[28038  2020]\n",
            "[28058  2020]\n",
            "[28069  2020]\n",
            "[28071  2020]\n",
            "[28080  2020]\n",
            "[28088  2020]\n",
            "[28096  2020]\n",
            "[28101  2020]\n",
            "[28102  2020]\n",
            "[28111  2020]\n",
            "[28118  2020]\n",
            "[28124  2020]\n",
            "[28130  2020]\n",
            "[28133  2020]\n",
            "[28137  2020]\n",
            "[28146  2020]\n",
            "[28158  2020]\n",
            "[28160  2020]\n",
            "[28166  2020]\n",
            "[28169  2020]\n",
            "[28176  2020]\n",
            "[28178  2020]\n",
            "[28181  2020]\n",
            "[28182  2020]\n",
            "[28201  2020]\n",
            "[28205  2020]\n",
            "[28224  2020]\n",
            "[28228  2020]\n",
            "[28230  2020]\n",
            "[28236  2020]\n",
            "[28238  2020]\n",
            "[28250  2020]\n",
            "[28255  2020]\n",
            "[28259  2020]\n",
            "[28272  2020]\n",
            "[28273  2020]\n",
            "[28299  2020]\n",
            "[28307  2020]\n",
            "[28317  2020]\n",
            "[28319  2020]\n",
            "[28321  2020]\n",
            "[28323  2020]\n",
            "[28326  2020]\n",
            "[28334  2020]\n",
            "[28345  2020]\n",
            "[28346  2020]\n",
            "[28355  2020]\n",
            "[28360  2020]\n",
            "[28365  2020]\n",
            "[28367  2020]\n",
            "[28375  2020]\n",
            "[28377  2020]\n",
            "[28382  2020]\n",
            "[28391  2020]\n",
            "[28402  2020]\n",
            "[28405  2020]\n",
            "[28408  2020]\n",
            "[28416  2020]\n",
            "[28423  2020]\n",
            "[28425  2020]\n",
            "[28426  2020]\n",
            "[28428  2020]\n",
            "[28436  2020]\n",
            "[28446  2020]\n",
            "[28450  2020]\n",
            "[28452  2020]\n",
            "[28453  2020]\n",
            "[28457  2020]\n",
            "[28461  2020]\n",
            "[28462  2020]\n",
            "[28466  2020]\n",
            "[28471  2020]\n",
            "[28474  2020]\n",
            "[28484  2020]\n",
            "[28489  2020]\n",
            "[28492  2020]\n",
            "[28502  2020]\n",
            "[28526  2020]\n",
            "[28528  2020]\n",
            "[28529  2020]\n",
            "[28534  2020]\n",
            "[28538  2020]\n",
            "[28548  2020]\n",
            "[28570  2020]\n",
            "[28571  2020]\n",
            "[28601  2020]\n",
            "[28613  2020]\n",
            "[28624  2020]\n",
            "[28628  2020]\n",
            "[28633  2020]\n",
            "[28656  2020]\n",
            "[28661  2020]\n",
            "[28665  2020]\n",
            "[28668  2020]\n",
            "[28669  2020]\n",
            "[28675  2020]\n",
            "[28681  2020]\n",
            "[28684  2020]\n",
            "[28693  2020]\n",
            "[28706  2020]\n",
            "[28710  2020]\n",
            "[28711  2020]\n",
            "[28716  2020]\n",
            "[28717  2020]\n",
            "[28726  2020]\n",
            "[28745  2020]\n",
            "[28753  2020]\n",
            "[28755  2020]\n",
            "[28758  2020]\n",
            "[28791  2020]\n",
            "[28795  2020]\n",
            "[28797  2020]\n",
            "[28806  2020]\n",
            "[28821  2020]\n",
            "[28825  2020]\n",
            "[28829  2020]\n",
            "[28837  2020]\n",
            "[28854  2020]\n",
            "[28856  2020]\n",
            "[28859  2020]\n",
            "[28864  2020]\n",
            "[28871  2020]\n",
            "[28874  2020]\n",
            "[28881  2020]\n",
            "[28883  2020]\n",
            "[28899  2020]\n",
            "[28907  2020]\n",
            "[28917  2020]\n",
            "[28929  2020]\n",
            "[28932  2020]\n",
            "[28955  2020]\n",
            "[28960  2020]\n",
            "[28961  2020]\n",
            "[28963  2020]\n",
            "[28965  2020]\n",
            "[28966  2020]\n",
            "[28979  2020]\n",
            "[28986  2020]\n",
            "[28989  2020]\n",
            "[29014  2020]\n",
            "[29025  2020]\n",
            "[29027  2020]\n",
            "[29034  2020]\n",
            "[29039  2020]\n",
            "[29049  2020]\n",
            "[29050  2020]\n",
            "[29062  2020]\n",
            "[29065  2020]\n",
            "[29066  2020]\n",
            "[29094  2020]\n",
            "[29109  2020]\n",
            "[29119  2020]\n",
            "[29120  2020]\n",
            "[29121  2020]\n",
            "[29148  2020]\n",
            "[29157  2020]\n",
            "[29166  2020]\n",
            "[29169  2020]\n",
            "[29180  2020]\n",
            "[29183  2020]\n",
            "[29184  2020]\n",
            "[29191  2020]\n",
            "[29193  2020]\n",
            "[29195  2020]\n",
            "[29199  2020]\n",
            "[29207  2020]\n",
            "[29224  2020]\n",
            "[29230  2020]\n",
            "[29232  2020]\n",
            "[29241  2020]\n",
            "[29251  2020]\n",
            "[29254  2020]\n",
            "[29266  2020]\n",
            "[29268  2020]\n",
            "[29271  2020]\n",
            "[29280  2020]\n",
            "[29314  2020]\n",
            "[29331  2020]\n",
            "[29333  2020]\n",
            "[29342  2020]\n",
            "[29353  2020]\n",
            "[29363  2020]\n",
            "[29365  2020]\n",
            "[29372  2020]\n",
            "[29378  2020]\n",
            "[29404  2020]\n",
            "[29408  2020]\n",
            "[29411  2020]\n",
            "[29412  2020]\n",
            "[29413  2020]\n",
            "[29415  2020]\n",
            "[29425  2020]\n",
            "[29438  2020]\n",
            "[29446  2020]\n",
            "[29448  2020]\n",
            "[29449  2020]\n",
            "[29452  2020]\n",
            "[29460  2020]\n",
            "[29464  2020]\n",
            "[29473  2020]\n",
            "[29477  2020]\n",
            "[29490  2020]\n",
            "[29507  2020]\n",
            "[29518  2020]\n",
            "[29524  2020]\n",
            "[29532  2020]\n",
            "[29535  2020]\n",
            "[29539  2020]\n",
            "[29553  2020]\n",
            "[29562  2020]\n",
            "[29563  2020]\n",
            "[29565  2020]\n",
            "[29578  2020]\n",
            "[29593  2020]\n",
            "[29594  2020]\n",
            "[29598  2020]\n",
            "[29607  2020]\n",
            "[29608  2020]\n",
            "[29625  2020]\n",
            "[29627  2020]\n",
            "[29641  2020]\n",
            "[29649  2020]\n",
            "[29653  2020]\n",
            "[29656  2020]\n",
            "[29657  2020]\n",
            "[29661  2020]\n",
            "[29681  2020]\n",
            "[29689  2020]\n",
            "[29699  2020]\n",
            "[29704  2020]\n",
            "[29710  2020]\n",
            "[29735  2020]\n",
            "[29737  2020]\n",
            "[29750  2020]\n",
            "[29756  2020]\n",
            "[29759  2020]\n",
            "[29761  2020]\n",
            "[29764  2020]\n",
            "[29766  2020]\n",
            "[29772  2020]\n",
            "[29786  2020]\n",
            "[29790  2020]\n",
            "[29791  2020]\n",
            "[29819  2020]\n",
            "[29829  2020]\n",
            "[29850  2020]\n",
            "[29853  2020]\n",
            "[29864  2020]\n",
            "[29866  2020]\n",
            "[29886  2020]\n",
            "[29889  2020]\n",
            "[29909  2020]\n",
            "[29914  2020]\n",
            "[29918  2020]\n",
            "[29927  2020]\n",
            "[29936  2020]\n",
            "[29937  2020]\n",
            "[29943  2020]\n",
            "[29944  2020]\n",
            "[29946  2020]\n",
            "[29948  2020]\n",
            "[29950  2020]\n",
            "[29957  2020]\n",
            "[29968  2020]\n",
            "[29974  2020]\n",
            "[29975  2020]\n",
            "[29979  2020]\n",
            "[29987  2020]\n",
            "[29992  2020]\n",
            "[29998  2020]\n",
            "[30002  2020]\n",
            "[30016  2020]\n",
            "[30018  2020]\n",
            "[30030  2020]\n",
            "[30033  2020]\n",
            "[30047  2020]\n",
            "[30050  2020]\n",
            "[30055  2020]\n",
            "[30063  2020]\n",
            "[30069  2020]\n",
            "[30071  2020]\n",
            "[30099  2020]\n",
            "[30105  2020]\n",
            "[30107  2020]\n",
            "[30108  2020]\n",
            "[30125  2020]\n",
            "[30131  2020]\n",
            "[30133  2020]\n",
            "[30138  2020]\n",
            "[30142  2020]\n",
            "[30143  2020]\n",
            "[30147  2020]\n",
            "[30151  2020]\n",
            "[30153  2020]\n",
            "[30156  2020]\n",
            "[30157  2020]\n",
            "[30163  2020]\n",
            "[30164  2020]\n",
            "[30172  2020]\n",
            "[30173  2020]\n",
            "[30175  2020]\n",
            "[30180  2020]\n",
            "[30184  2020]\n",
            "[30186  2020]\n",
            "[30189  2020]\n",
            "[30191  2020]\n",
            "[30193  2020]\n",
            "[30202  2020]\n",
            "[30204  2020]\n",
            "[30207  2020]\n",
            "[30210  2020]\n",
            "[30211  2020]\n",
            "[30212  2020]\n",
            "[30213  2020]\n",
            "[30232  2020]\n",
            "[30237  2020]\n",
            "[30240  2020]\n",
            "[30253  2020]\n",
            "[30266  2020]\n",
            "[30273  2020]\n",
            "[30294  2020]\n",
            "[30298  2020]\n",
            "[30299  2020]\n",
            "[30302  2020]\n",
            "[30331  2020]\n",
            "[30335  2020]\n",
            "[30338  2020]\n",
            "[30345  2020]\n",
            "[30350  2020]\n",
            "[30377  2020]\n",
            "[30379  2020]\n",
            "[30397  2020]\n",
            "[30405  2020]\n",
            "[30412  2020]\n",
            "[30413  2020]\n",
            "[30424  2020]\n",
            "[30425  2020]\n",
            "[30436  2020]\n",
            "[30439  2020]\n",
            "[30448  2020]\n",
            "[30449  2020]\n",
            "[30452  2020]\n",
            "[30455  2020]\n",
            "[30459  2020]\n",
            "[30461  2020]\n",
            "[30464  2020]\n",
            "[30466  2020]\n",
            "[30469  2020]\n",
            "[30471  2020]\n",
            "[30480  2020]\n",
            "[30483  2020]\n",
            "[30488  2020]\n",
            "[30490  2020]\n",
            "[30501  2020]\n",
            "[30512  2020]\n",
            "[30517  2020]\n",
            "[30519  2020]\n",
            "[30527  2020]\n",
            "[30538  2020]\n",
            "[30540  2020]\n",
            "[30544  2020]\n",
            "[30547  2020]\n",
            "[30548  2020]\n",
            "[30555  2020]\n",
            "[30557  2020]\n",
            "[30564  2020]\n",
            "[30578  2020]\n",
            "[30580  2020]\n",
            "[30621  2020]\n",
            "[30624  2020]\n",
            "[30625  2020]\n",
            "[30634  2020]\n",
            "[30639  2020]\n",
            "[30641  2020]\n",
            "[30645  2020]\n",
            "[30652  2020]\n",
            "[30654  2020]\n",
            "[30658  2020]\n",
            "[30661  2020]\n",
            "[30665  2020]\n",
            "[30673  2020]\n",
            "[30675  2020]\n",
            "[30677  2020]\n",
            "[30686  2020]\n",
            "[30702  2020]\n",
            "[30708  2020]\n",
            "[30711  2020]\n",
            "[30715  2020]\n",
            "[30716  2020]\n",
            "[30717  2020]\n",
            "[30719  2020]\n",
            "[30733  2020]\n",
            "[30738  2020]\n",
            "[30741  2020]\n",
            "[30743  2020]\n",
            "[30750  2020]\n",
            "[30757  2020]\n",
            "[30763  2020]\n",
            "[30771  2020]\n",
            "[30778  2020]\n",
            "[30780  2020]\n",
            "[30787  2020]\n",
            "[30796  2020]\n",
            "[30812  2020]\n",
            "[30824  2020]\n",
            "[30828  2020]\n",
            "[30829  2020]\n",
            "[30837  2020]\n",
            "[30847  2020]\n",
            "[30855  2020]\n",
            "[30860  2020]\n",
            "[30866  2020]\n",
            "[30867  2020]\n",
            "[30870  2020]\n",
            "[30881  2020]\n",
            "[30882  2020]\n",
            "[30891  2020]\n",
            "[30900  2020]\n",
            "[30906  2020]\n",
            "[30915  2020]\n",
            "[30920  2020]\n",
            "[30934  2020]\n",
            "[30937  2020]\n",
            "[30947  2020]\n",
            "[30970  2020]\n",
            "[30983  2020]\n",
            "[31003  2020]\n",
            "[31010  2020]\n",
            "[31013  2020]\n",
            "[31017  2020]\n",
            "[31030  2020]\n",
            "[31034  2020]\n",
            "[31046  2020]\n",
            "[31049  2020]\n",
            "[31050  2020]\n",
            "[31069  2020]\n",
            "[31077  2020]\n",
            "[31086  2020]\n",
            "[31088  2020]\n",
            "[31090  2020]\n",
            "[31091  2020]\n",
            "[31096  2020]\n",
            "[31100  2020]\n",
            "[31102  2020]\n",
            "[31106  2020]\n",
            "[31109  2020]\n",
            "[31111  2020]\n",
            "[31112  2020]\n",
            "[31117  2020]\n",
            "[31123  2020]\n",
            "[31124  2020]\n",
            "[31139  2020]\n",
            "[31144  2020]\n",
            "[31162  2020]\n",
            "[31166  2020]\n",
            "[31167  2020]\n",
            "[31180  2020]\n",
            "[31193  2020]\n",
            "[31196  2020]\n",
            "[31215  2020]\n",
            "[31219  2020]\n",
            "[31220  2020]\n",
            "[31221  2020]\n",
            "[31223  2020]\n",
            "[31228  2020]\n",
            "[31229  2020]\n",
            "[31239  2020]\n",
            "[31255  2020]\n",
            "[31258  2020]\n",
            "[31263  2020]\n",
            "[31287  2020]\n",
            "[31288  2020]\n",
            "[31294  2020]\n",
            "[31295  2020]\n",
            "[31309  2020]\n",
            "[31345  2020]\n",
            "[31353  2020]\n",
            "[31362  2020]\n",
            "[31378  2020]\n",
            "[31385  2020]\n",
            "[31394  2020]\n",
            "[31406  2020]\n",
            "[31412  2020]\n",
            "[31416  2020]\n",
            "[42907  2020]\n",
            "[42913  2020]\n",
            "[42915  2020]\n",
            "[42920  2020]\n",
            "[42923  2020]\n",
            "[42927  2020]\n",
            "[42949  2020]\n",
            "[42950  2020]\n",
            "[42951  2020]\n",
            "[42961  2020]\n",
            "[42962  2020]\n",
            "[42968  2020]\n",
            "[42971  2020]\n",
            "[42973  2020]\n",
            "[42982  2020]\n",
            "[42994  2020]\n",
            "[43005  2020]\n",
            "[43007  2020]\n",
            "[43011  2020]\n",
            "[43026  2020]\n",
            "[43033  2020]\n",
            "[43043  2020]\n",
            "[43049  2020]\n",
            "[43055  2020]\n",
            "[43077  2020]\n",
            "[43132  2020]\n",
            "[43134  2020]\n",
            "[43144  2020]\n",
            "[43147  2020]\n",
            "[43153  2020]\n",
            "[43157  2020]\n",
            "[43159  2020]\n",
            "[43166  2020]\n",
            "[43171  2020]\n",
            "[43176  2020]\n",
            "[43181  2020]\n",
            "[43184  2020]\n",
            "[43186  2020]\n",
            "[43197  2020]\n",
            "[43198  2020]\n",
            "[43201  2020]\n",
            "[43204  2020]\n",
            "[43213  2020]\n",
            "[43226  2020]\n",
            "[43231  2020]\n",
            "[43237  2020]\n",
            "[43249  2020]\n",
            "[43257  2020]\n",
            "[43264  2020]\n",
            "[43270  2020]\n",
            "[43287  2020]\n",
            "[43318  2020]\n",
            "[43327  2020]\n",
            "[43329  2020]\n",
            "[43337  2020]\n",
            "[43345  2020]\n",
            "[43346  2020]\n",
            "[43347  2020]\n",
            "[43353  2020]\n",
            "[43355  2020]\n",
            "[43364  2020]\n",
            "[43369  2020]\n",
            "[43372  2020]\n",
            "[43374  2020]\n",
            "[43381  2020]\n",
            "[43388  2020]\n",
            "[43396  2020]\n",
            "[43403  2020]\n",
            "[43408  2020]\n",
            "[43424  2020]\n",
            "[43438  2020]\n",
            "[43441  2020]\n",
            "[43487  2020]\n",
            "[43497  2020]\n",
            "[43509  2020]\n",
            "[43510  2020]\n",
            "[43515  2020]\n",
            "[43517  2020]\n",
            "[43520  2020]\n",
            "[43524  2020]\n",
            "[43533  2020]\n",
            "[43540  2020]\n",
            "[43551  2020]\n",
            "[43555  2020]\n",
            "[43557  2020]\n",
            "[43566  2020]\n",
            "[43568  2020]\n",
            "[43585  2020]\n",
            "[43598  2020]\n",
            "[43601  2020]\n",
            "[43604  2020]\n",
            "[43614  2020]\n",
            "[43619  2020]\n",
            "[43621  2020]\n",
            "[43632  2020]\n",
            "[43633  2020]\n",
            "[43636  2020]\n",
            "[43647  2020]\n",
            "[43655  2020]\n",
            "[43665  2020]\n",
            "[43668  2020]\n",
            "[43677  2020]\n",
            "[43685  2020]\n",
            "[43695  2020]\n",
            "[43700  2020]\n",
            "[43708  2020]\n",
            "[43726  2020]\n",
            "[43727  2020]\n",
            "[43738  2020]\n",
            "[43760  2020]\n",
            "[43785  2020]\n",
            "[43789  2020]\n",
            "[43790  2020]\n",
            "[43800  2020]\n",
            "[43801  2020]\n",
            "[43807  2020]\n",
            "[43822  2020]\n",
            "[43838  2020]\n",
            "[43867  2020]\n",
            "[43872  2020]\n",
            "[43878  2020]\n",
            "[43894  2020]\n",
            "[43902  2020]\n",
            "[43907  2020]\n",
            "[43908  2020]\n",
            "[43921  2020]\n",
            "[43928  2020]\n",
            "[43939  2020]\n",
            "[43946  2020]\n",
            "[43950  2020]\n",
            "[43956  2020]\n",
            "[43957  2020]\n",
            "[43971  2020]\n",
            "[43972  2020]\n",
            "[43982  2020]\n",
            "[43987  2020]\n",
            "[43991  2020]\n",
            "[43993  2020]\n",
            "[44001  2020]\n",
            "[44014  2020]\n",
            "[44023  2020]\n",
            "[44024  2020]\n",
            "[44030  2020]\n",
            "[44038  2020]\n",
            "[44041  2020]\n",
            "[44053  2020]\n",
            "[44062  2020]\n",
            "[44075  2020]\n",
            "[44095  2020]\n",
            "[44098  2020]\n",
            "[44102  2020]\n",
            "[44114  2020]\n",
            "[44121  2020]\n",
            "[44131  2020]\n",
            "[44146  2020]\n",
            "[44148  2020]\n",
            "[44157  2020]\n",
            "[44158  2020]\n",
            "[44164  2020]\n",
            "[44177  2020]\n",
            "[44181  2020]\n",
            "[44185  2020]\n",
            "[44194  2020]\n",
            "[44216  2020]\n",
            "[44222  2020]\n",
            "[44224  2020]\n",
            "[44225  2020]\n",
            "[44231  2020]\n",
            "[44236  2020]\n",
            "[44239  2020]\n",
            "[44243  2020]\n",
            "[44249  2020]\n",
            "[44254  2020]\n",
            "[44258  2020]\n",
            "[44269  2020]\n",
            "[44270  2020]\n",
            "[44273  2020]\n",
            "[44277  2020]\n",
            "[44292  2020]\n",
            "[44296  2020]\n",
            "[44301  2020]\n",
            "[44321  2020]\n",
            "[44339  2020]\n",
            "[44340  2020]\n",
            "[44345  2020]\n",
            "[44354  2020]\n",
            "[44365  2020]\n",
            "[44367  2020]\n",
            "[44380  2020]\n",
            "[44381  2020]\n",
            "[44382  2020]\n",
            "[44385  2020]\n",
            "[44390  2020]\n",
            "[44392  2020]\n",
            "[44395  2020]\n",
            "[44399  2020]\n",
            "[44402  2020]\n",
            "[44414  2020]\n",
            "[44434  2020]\n",
            "[44438  2020]\n",
            "[44445  2020]\n",
            "[44455  2020]\n",
            "[44457  2020]\n",
            "[44464  2020]\n",
            "[44465  2020]\n",
            "[44470  2020]\n",
            "[44484  2020]\n",
            "[44486  2020]\n",
            "[44507  2020]\n",
            "[44508  2020]\n",
            "[44513  2020]\n",
            "[44514  2020]\n",
            "[44530  2020]\n",
            "[44548  2020]\n",
            "[44551  2020]\n",
            "[44552  2020]\n",
            "[44554  2020]\n",
            "[44556  2020]\n",
            "[44558  2020]\n",
            "[44566  2020]\n",
            "[44568  2020]\n",
            "[44570  2020]\n",
            "[44573  2020]\n",
            "[44575  2020]\n",
            "[44584  2020]\n",
            "[44594  2020]\n",
            "[44614  2020]\n",
            "[44616  2020]\n",
            "[44624  2020]\n",
            "[44625  2020]\n",
            "[44626  2020]\n",
            "[44631  2020]\n",
            "[44632  2020]\n",
            "[44633  2020]\n",
            "[44643  2020]\n",
            "[44645  2020]\n",
            "[44648  2020]\n",
            "[44652  2020]\n",
            "[44656  2020]\n",
            "[44664  2020]\n",
            "[44671  2020]\n",
            "[44672  2020]\n",
            "[44676  2020]\n",
            "[44678  2020]\n",
            "[44683  2020]\n",
            "[44696  2020]\n",
            "[44703  2020]\n",
            "[44704  2020]\n",
            "[44705  2020]\n",
            "[44731  2020]\n",
            "[44736  2020]\n",
            "[44737  2020]\n",
            "[44741  2020]\n",
            "[44747  2020]\n",
            "[44748  2020]\n",
            "[44761  2020]\n",
            "[44773  2020]\n",
            "[44778  2020]\n",
            "[44789  2020]\n",
            "[44793  2020]\n",
            "[44797  2020]\n",
            "[44802  2020]\n",
            "[44812  2020]\n",
            "[44813  2020]\n",
            "[44815  2020]\n",
            "[44819  2020]\n",
            "[44820  2020]\n",
            "[44831  2020]\n",
            "[44839  2020]\n",
            "[44842  2020]\n",
            "[44845  2020]\n",
            "[44863  2020]\n",
            "[44881  2020]\n",
            "[44883  2020]\n",
            "[44888  2020]\n",
            "[44905  2020]\n",
            "[44911  2020]\n",
            "[44914  2020]\n",
            "[44927  2020]\n",
            "[44930  2020]\n",
            "[44939  2020]\n",
            "[44956  2020]\n",
            "[44957  2020]\n",
            "[44968  2020]\n",
            "[44971  2020]\n",
            "[44979  2020]\n",
            "[44981  2020]\n",
            "[44986  2020]\n",
            "[44988  2020]\n",
            "[44993  2020]\n",
            "[44994  2020]\n",
            "[44996  2020]\n",
            "[45001  2020]\n",
            "[45002  2020]\n",
            "[45012  2020]\n",
            "[45024  2020]\n",
            "[45030  2020]\n",
            "[45056  2020]\n",
            "[45062  2020]\n",
            "[45067  2020]\n",
            "[45081  2020]\n",
            "[45083  2020]\n",
            "[45087  2020]\n",
            "[45099  2020]\n",
            "[45105  2020]\n",
            "[45106  2020]\n",
            "[45119  2020]\n",
            "[45137  2020]\n",
            "[45153  2020]\n",
            "[45160  2020]\n",
            "[45181  2020]\n",
            "[45191  2020]\n",
            "[45202  2020]\n",
            "[45203  2020]\n",
            "[45205  2020]\n",
            "[45206  2020]\n",
            "[45207  2020]\n",
            "[45215  2020]\n",
            "[45254  2020]\n",
            "[45261  2020]\n",
            "[45270  2020]\n",
            "[45278  2020]\n",
            "[45285  2020]\n",
            "[45291  2020]\n",
            "[45295  2020]\n",
            "[45306  2020]\n",
            "[45309  2020]\n",
            "[45312  2020]\n",
            "[45324  2020]\n",
            "[45342  2020]\n",
            "[45343  2020]\n",
            "[45344  2020]\n",
            "[45349  2020]\n",
            "[45368  2020]\n",
            "[45371  2020]\n",
            "[45379  2020]\n",
            "[45380  2020]\n",
            "[45389  2020]\n",
            "[45401  2020]\n",
            "[45405  2020]\n",
            "[45410  2020]\n",
            "[45443  2020]\n",
            "[45468  2020]\n",
            "[45469  2020]\n",
            "[45475  2020]\n",
            "[45485  2020]\n",
            "[45488  2020]\n",
            "[45497  2020]\n",
            "[45499  2020]\n",
            "[45505  2020]\n",
            "[45508  2020]\n",
            "[45509  2020]\n",
            "[45522  2020]\n",
            "[45538  2020]\n",
            "[45556  2020]\n",
            "[45567  2020]\n",
            "[45592  2020]\n",
            "[45594  2020]\n",
            "[45617  2020]\n",
            "[45624  2020]\n",
            "[45636  2020]\n",
            "[45639  2020]\n",
            "[45658  2020]\n",
            "[45659  2020]\n",
            "[45663  2020]\n",
            "[45667  2020]\n",
            "[45668  2020]\n",
            "[45683  2020]\n",
            "[45685  2020]\n",
            "[45695  2020]\n",
            "[45703  2020]\n",
            "[45705  2020]\n",
            "[45707  2020]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaMJMkRbQdnA"
      },
      "source": [
        "np.save('/content/features-224-densenet-fined-autoencoded-training-2021-2020.npy', id_features_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXFpINDxFGXM",
        "outputId": "53955dd8-0dc6-45fb-9aed-a7ed59b5e391"
      },
      "source": [
        "# Validation set (2021)\n",
        "id_features_vector = extract_store_finetuned('/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images', get_layer_output)\n",
        "np.save('/content/features-224-densenet-fined-validation-2021.npy', id_features_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/500 [00:00<01:19,  6.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting features...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNLerWqG-Zw6"
      },
      "source": [
        "## Using 2021 + 2020 data (and using autoencoder trained using only diagnostic procedure concepts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmffos_9-lZG"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2bMEyBH-lZH"
      },
      "source": [
        "path_to_concepts = ['/content/training-images-concepts-by-semantic/concepts-file/training-concepts-dp-only.csv',\n",
        "                    '/content/val-concepts-dp-only.csv',\n",
        "                    '/content/images-2020-dp-only.csv']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPVVaWnM-lZR"
      },
      "source": [
        "# Function to extract concepts from the training and validation images from 2021, and also from selected images from 2020 ImageCLEF dataset\n",
        "# These selected images are images that strictly have the same concepts of this year dataset, therefore, 6,556 images from last year dataset are being used\n",
        "def extract_concepts_all(root_paths, image_id_concepts_dict = dict()):\n",
        "    \"\"\"\n",
        "      Function that extract concepts for a concept file (csv and json), and stores them in a dictionary, \n",
        "      where the key is the absolute path of the image and the values are the concepts.\n",
        "\n",
        "      root_paths: a 1-d list that contains the absolute paths of the concept files\n",
        "      image_id_concepts_dict: dictionary that will contain the data from the concepts file\n",
        "\n",
        "      Returns: a dictionary with the absolute images paths as keys and their corresponding concepts as values.\n",
        "\n",
        "    \"\"\"\n",
        "    for idx, name in enumerate(root_paths):\n",
        "        with open(name, \"r\", encoding= 'utf-8-sig') as f:\n",
        "          reader = csv.reader(f, delimiter = '\\t')\n",
        "          if name =='/content/training-images-concepts-by-semantic/concepts-file/training-concepts-dp-only.csv':\n",
        "            path_image = '/content/ImageCLEF2021_ConceptDetection_Training-Set/ImageCLEF2021_ConceptDetection_Training-Set/Training-Images/'\n",
        "\n",
        "          if name == '/content/val-concepts-dp-only.csv':\n",
        "            path_image = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images/'\n",
        "\n",
        "          for i, line in enumerate(reader):\n",
        "            if idx != 2:\n",
        "              # It is recommended to check where the image has assigned concepts. This is relevant when separating concepts by sematic type\n",
        "              # If the image does not have a concept, an empty list will be passed.\n",
        "              if len(line[1]) < 1:\n",
        "                image_id_concepts_dict[path_image+line[0]+'.jpg'] = []\n",
        "              else:\n",
        "                image_id_concepts_dict[path_image+line[0]+'.jpg'] = list(line[1].split(';'))\n",
        "            else:\n",
        "                if len(line[1]) < 1:\n",
        "                  image_id_concepts_dict[line[0]] = []\n",
        "\n",
        "                else:\n",
        "                  image_id_concepts_dict[line[0]] = list(line[1].split(';'))\n",
        "\n",
        "    return image_id_concepts_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IAb4TFb-lZR"
      },
      "source": [
        "#Extract concepts for the multiple concept files\n",
        "image_id_concepts_dict = extract_concepts_all(path_to_concepts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "819nW8tb-lZR",
        "outputId": "ab176dbf-9aab-4b79-ce71-f551e266d76e"
      },
      "source": [
        "# Since we are working with around 9K images. We will only load the images absolute path and the concepts to a dataframe and then use a generator to load them during training.\n",
        "# Here, we will create a dataframe with the images path\n",
        "X = []\n",
        "df_all_images_ids = pd.DataFrame(columns=['image_path'])\n",
        "# Training images\n",
        "for image in tqdm(image_id_concepts_dict.keys(), position = 0):\n",
        "  X.append(image)\n",
        "df_all_images_ids['image_path'] = X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9792/9792 [00:00<00:00, 1412964.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B87Au7Jw-lZS",
        "outputId": "7eebc4c1-0af8-49a7-8895-c4a8045d2efd"
      },
      "source": [
        "# Transforming and encoding process\n",
        "# Since we need the encoded labels, we will use the transformer used in the autoencoder process\n",
        "\n",
        "#Load transformer\n",
        "with open(\"/content/mlb_autoencoder_dp_labels.pkl\", 'rb') as f:\n",
        "    mlb = pickle.load(f)\n",
        "\n",
        "# Put all concepts in a list of lists to be passed to the transformer\n",
        "labels =[]\n",
        "for image in tqdm(image_id_concepts_dict.keys(), position=0):\n",
        "  labels.append(image_id_concepts_dict[image])\n",
        "\n",
        "labels_transformed = mlb.transform(labels) # This will be used to get the encoded labels\n",
        "\n",
        "# Load trained encoder\n",
        "encoder = tf.keras.models.load_model('/content/encoder-dp-combined-images.h5', compile=False)\n",
        "\n",
        "# Encode transformed labels\n",
        "Y = np.array(encoder.predict(labels_transformed))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9792/9792 [00:00<00:00, 1215071.29it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EVg2CDag_rZ",
        "outputId": "395f81f4-4170-49e6-dd23-ad3ae35b3c6f"
      },
      "source": [
        "labels[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['C0024485'],\n",
              " ['C0032743'],\n",
              " ['C0040398'],\n",
              " ['C0024485'],\n",
              " ['C2456881', 'C0041618'],\n",
              " ['C0040398'],\n",
              " ['C0040398'],\n",
              " [],\n",
              " ['C0412611', 'C0040398'],\n",
              " ['C0040398']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1DPtFvChDsF",
        "outputId": "e9d37b38-d435-4c57-c99e-67be6c86a9a9"
      },
      "source": [
        "labels_transformed[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlNqtOMehOhR",
        "outputId": "d0cc9762-a913-428d-b6c5-161d3ee47617"
      },
      "source": [
        "Y[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 2.2402322 , 0.6117097 , 0.        , 3.6497285 ,\n",
              "        0.63613445, 3.4092917 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 2.4441638 , 3.8091717 ,\n",
              "        5.4655886 , 0.        , 2.3914764 , 2.8667312 , 1.9693022 ],\n",
              "       [0.        , 2.4963117 , 3.5909462 , 0.        , 2.0191474 ,\n",
              "        1.0522851 , 3.1866229 , 0.20849384, 0.40269482, 2.0956373 ,\n",
              "        0.        , 0.        , 0.        , 1.9132146 , 0.96986383,\n",
              "        2.2350454 , 0.        , 0.10135684, 1.4293385 , 2.3868608 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0eo9da-lZS"
      },
      "source": [
        "# Since we will use flow_from_dataframe in the training, we put both the images absolute path and the encoded labels\n",
        "df_use_densenet = pd.concat([df_all_images_ids, pd.DataFrame(Y)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_yBBwqS-lZT"
      },
      "source": [
        "# Train split dataset, because a portion is needed to set the threshold (to see if to assign the concept or not) and another portion to see the overall f1-score\n",
        "df_train, df_test = train_test_split(df_use_densenet, test_size = 0.2, shuffle = True, random_state = 14) # test will be used to get a final f1-score\n",
        "y_train, y_test = train_test_split(Y,test_size = 0.2, shuffle = True, random_state = 14)\n",
        "labels_transformed_train, labels_transformed_test = train_test_split(labels_transformed,test_size = 0.2, shuffle = True, random_state = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXh0ZKep-lZT"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycPjMLjj-lZT"
      },
      "source": [
        "default_densenet = tf.keras.applications.densenet.DenseNet121(include_top=False, weights= 'imagenet') # Load model (only feature extraction part) with imagenet weights\n",
        "default_densenet.trainable = False # Freeze all layers of the model, so weights remain the same when training, and only weights from added layers update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUsq9NpQ-lZT"
      },
      "source": [
        "# Adding the classification part to the existing model\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(default_densenet.output)\n",
        "x = tf.keras.layers.Dense(20, activation='sigmoid', name = 'prediction_layer')(x)\n",
        "\n",
        "\n",
        "model = tf.keras.models.Model(inputs = default_densenet.input, outputs= x) # Final model to be trained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkn8jB76-lZU"
      },
      "source": [
        "# Define some required parameter for training\n",
        "init_lr = 1e-4\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "valid_batch_size = 32\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=init_lr)\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 10, restore_best_weights= True, mode = 'max')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbdmtwTl-lZU"
      },
      "source": [
        "# Compile model. Since the output is no longer an array of 1s and 0s, the loss function can change to a different one.\n",
        "model.compile(loss = 'mean_squared_error', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEYro5cl-lZU",
        "outputId": "a729b65d-5af5-440e-a3ac-dad771f45eda"
      },
      "source": [
        "# Data generator\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2, rescale=1./255) # This will split the training dataframe, and also rescale the values from loaded images\n",
        "\n",
        "# Train generator\n",
        "train_generator = data_generator.flow_from_dataframe(df_train,x_col='image_path', y_col=df_train.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw',batch_size=32, shuffle=True, seed=14, subset='training')\n",
        "\n",
        "# Validation generator\n",
        "val_generator = data_generator.flow_from_dataframe(df_train,x_col='image_path', y_col=df_train.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw',batch_size=32, shuffle=True, seed=14, subset='validation')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6267 validated image filenames.\n",
            "Found 1566 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5Vc698a-lZU",
        "outputId": "3d4bf8fc-90e1-4de8-911d-3807645ec7b3"
      },
      "source": [
        "# Model training (only the classification layers that have been added)\n",
        "history = model.fit(train_generator, epochs = epochs, validation_data= val_generator, validation_steps = 20, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "196/196 [==============================] - 57s 265ms/step - loss: 2.3288 - acc: 0.1240 - val_loss: 1.8826 - val_acc: 0.1656\n",
            "Epoch 2/100\n",
            "196/196 [==============================] - 44s 222ms/step - loss: 1.9117 - acc: 0.1789 - val_loss: 1.8798 - val_acc: 0.1922\n",
            "Epoch 3/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 1.8849 - acc: 0.1908 - val_loss: 1.8420 - val_acc: 0.1922\n",
            "Epoch 4/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 1.8676 - acc: 0.1895 - val_loss: 1.8477 - val_acc: 0.1781\n",
            "Epoch 5/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 1.8729 - acc: 0.1953 - val_loss: 1.8875 - val_acc: 0.1703\n",
            "Epoch 6/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 1.8557 - acc: 0.1914 - val_loss: 1.8562 - val_acc: 0.1844\n",
            "Epoch 7/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 1.8727 - acc: 0.1988 - val_loss: 1.8424 - val_acc: 0.1984\n",
            "Epoch 8/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8487 - acc: 0.1867 - val_loss: 1.8561 - val_acc: 0.2062\n",
            "Epoch 9/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 1.8618 - acc: 0.1951 - val_loss: 1.8527 - val_acc: 0.2141\n",
            "Epoch 10/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8628 - acc: 0.1990 - val_loss: 1.8315 - val_acc: 0.1984\n",
            "Epoch 11/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8586 - acc: 0.2064 - val_loss: 1.8297 - val_acc: 0.1891\n",
            "Epoch 12/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8584 - acc: 0.2100 - val_loss: 1.8246 - val_acc: 0.1891\n",
            "Epoch 13/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8589 - acc: 0.2092 - val_loss: 1.8479 - val_acc: 0.2219\n",
            "Epoch 14/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8507 - acc: 0.2081 - val_loss: 1.8125 - val_acc: 0.2047\n",
            "Epoch 15/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 1.8549 - acc: 0.2151 - val_loss: 1.8262 - val_acc: 0.2156\n",
            "Epoch 16/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8593 - acc: 0.2188 - val_loss: 1.7962 - val_acc: 0.1813\n",
            "Epoch 17/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8601 - acc: 0.2088 - val_loss: 1.8084 - val_acc: 0.2000\n",
            "Epoch 18/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8409 - acc: 0.2072 - val_loss: 1.8479 - val_acc: 0.2375\n",
            "Epoch 19/100\n",
            "196/196 [==============================] - 43s 217ms/step - loss: 1.8537 - acc: 0.2198 - val_loss: 1.8882 - val_acc: 0.2359\n",
            "Epoch 20/100\n",
            "196/196 [==============================] - 43s 217ms/step - loss: 1.8543 - acc: 0.2152 - val_loss: 1.8349 - val_acc: 0.2016\n",
            "Epoch 21/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8510 - acc: 0.2091 - val_loss: 1.8087 - val_acc: 0.2422\n",
            "Epoch 22/100\n",
            "196/196 [==============================] - 43s 217ms/step - loss: 1.8530 - acc: 0.2192 - val_loss: 1.8632 - val_acc: 0.2188\n",
            "Epoch 23/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8538 - acc: 0.2262 - val_loss: 1.8330 - val_acc: 0.2375\n",
            "Epoch 24/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8589 - acc: 0.2210 - val_loss: 1.8149 - val_acc: 0.1906\n",
            "Epoch 25/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8420 - acc: 0.2038 - val_loss: 1.8290 - val_acc: 0.2266\n",
            "Epoch 26/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8433 - acc: 0.2241 - val_loss: 1.8222 - val_acc: 0.2156\n",
            "Epoch 27/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8464 - acc: 0.2245 - val_loss: 1.8591 - val_acc: 0.2500\n",
            "Epoch 28/100\n",
            "196/196 [==============================] - 43s 220ms/step - loss: 1.8398 - acc: 0.2246 - val_loss: 1.8422 - val_acc: 0.2297\n",
            "Epoch 29/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8631 - acc: 0.2238 - val_loss: 1.8237 - val_acc: 0.2203\n",
            "Epoch 30/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8567 - acc: 0.2298 - val_loss: 1.8526 - val_acc: 0.2188\n",
            "Epoch 31/100\n",
            "196/196 [==============================] - 43s 217ms/step - loss: 1.8520 - acc: 0.2326 - val_loss: 1.8127 - val_acc: 0.2359\n",
            "Epoch 32/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 1.8442 - acc: 0.2163 - val_loss: 1.8119 - val_acc: 0.2016\n",
            "Epoch 33/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8464 - acc: 0.2285 - val_loss: 1.8274 - val_acc: 0.2109\n",
            "Epoch 34/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8504 - acc: 0.2312 - val_loss: 1.8136 - val_acc: 0.2156\n",
            "Epoch 35/100\n",
            "196/196 [==============================] - 43s 219ms/step - loss: 1.8378 - acc: 0.2253 - val_loss: 1.7985 - val_acc: 0.2000\n",
            "Epoch 36/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8307 - acc: 0.2198 - val_loss: 1.8453 - val_acc: 0.2172\n",
            "Epoch 37/100\n",
            "196/196 [==============================] - 43s 218ms/step - loss: 1.8381 - acc: 0.2291 - val_loss: 1.8408 - val_acc: 0.2141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oJkpFUA-lZU"
      },
      "source": [
        "# Now that our classification layer has been trained, we can unfreeze the rest of the model, which are the convolutional blocks\n",
        "default_densenet.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AvNYHT5-lZV"
      },
      "source": [
        "# A new learning rate is defined, since a keras guide (https://keras.io/guides/transfer_learning/) suggests to lower it. Search for \"It's also critical to use a very low learning\"\n",
        "new_lr = 1e-5\n",
        "\n",
        "# Objects to be used by the model\n",
        "opt = tf.keras.optimizers.Adam(lr=new_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NqcDofI-lZV"
      },
      "source": [
        "# Compile model\n",
        "model.compile(loss = 'mean_squared_error', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x6jcP6R-lZV",
        "outputId": "c548174c-5d70-465c-b425-9217cc26fadf"
      },
      "source": [
        "# Model training (of the entire model)\n",
        "history_fined = model.fit(train_generator, epochs = epochs, validation_data= val_generator, validation_steps = 20, verbose= 1,\n",
        "                               callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "196/196 [==============================] - 86s 382ms/step - loss: 1.8634 - acc: 0.2161 - val_loss: 1.8312 - val_acc: 0.1688\n",
            "Epoch 2/100\n",
            "196/196 [==============================] - 72s 368ms/step - loss: 1.8368 - acc: 0.2057 - val_loss: 1.8450 - val_acc: 0.1641\n",
            "Epoch 3/100\n",
            "196/196 [==============================] - 73s 371ms/step - loss: 1.8416 - acc: 0.2112 - val_loss: 1.8198 - val_acc: 0.2016\n",
            "Epoch 4/100\n",
            "196/196 [==============================] - 73s 374ms/step - loss: 1.8206 - acc: 0.2089 - val_loss: 1.8286 - val_acc: 0.1984\n",
            "Epoch 5/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.8256 - acc: 0.2020 - val_loss: 1.8240 - val_acc: 0.1922\n",
            "Epoch 6/100\n",
            "196/196 [==============================] - 74s 374ms/step - loss: 1.8170 - acc: 0.2111 - val_loss: 1.8052 - val_acc: 0.2047\n",
            "Epoch 7/100\n",
            "196/196 [==============================] - 73s 374ms/step - loss: 1.8220 - acc: 0.2213 - val_loss: 1.7879 - val_acc: 0.2484\n",
            "Epoch 8/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.7938 - acc: 0.2215 - val_loss: 1.8219 - val_acc: 0.2375\n",
            "Epoch 9/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.8070 - acc: 0.2358 - val_loss: 1.8168 - val_acc: 0.2203\n",
            "Epoch 10/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.8194 - acc: 0.2426 - val_loss: 1.7925 - val_acc: 0.1922\n",
            "Epoch 11/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.8049 - acc: 0.2646 - val_loss: 1.7883 - val_acc: 0.2688\n",
            "Epoch 12/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.7917 - acc: 0.2789 - val_loss: 1.7908 - val_acc: 0.2688\n",
            "Epoch 13/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.7929 - acc: 0.2930 - val_loss: 1.8139 - val_acc: 0.2672\n",
            "Epoch 14/100\n",
            "196/196 [==============================] - 74s 374ms/step - loss: 1.7864 - acc: 0.3052 - val_loss: 1.7614 - val_acc: 0.2641\n",
            "Epoch 15/100\n",
            "196/196 [==============================] - 74s 374ms/step - loss: 1.7955 - acc: 0.3059 - val_loss: 1.8288 - val_acc: 0.2875\n",
            "Epoch 16/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.7908 - acc: 0.2928 - val_loss: 1.7758 - val_acc: 0.2750\n",
            "Epoch 17/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.7982 - acc: 0.2886 - val_loss: 1.7902 - val_acc: 0.2688\n",
            "Epoch 18/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.7910 - acc: 0.2897 - val_loss: 1.8123 - val_acc: 0.2406\n",
            "Epoch 19/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.8001 - acc: 0.2773 - val_loss: 1.7796 - val_acc: 0.2594\n",
            "Epoch 20/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.7957 - acc: 0.2801 - val_loss: 1.7767 - val_acc: 0.2531\n",
            "Epoch 21/100\n",
            "196/196 [==============================] - 73s 374ms/step - loss: 1.7881 - acc: 0.2808 - val_loss: 1.7805 - val_acc: 0.2547\n",
            "Epoch 22/100\n",
            "196/196 [==============================] - 73s 374ms/step - loss: 1.7797 - acc: 0.2881 - val_loss: 1.7906 - val_acc: 0.2688\n",
            "Epoch 23/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.7909 - acc: 0.2775 - val_loss: 1.7753 - val_acc: 0.2484\n",
            "Epoch 24/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.7817 - acc: 0.2805 - val_loss: 1.7945 - val_acc: 0.2578\n",
            "Epoch 25/100\n",
            "196/196 [==============================] - 74s 375ms/step - loss: 1.7888 - acc: 0.2908 - val_loss: 1.7887 - val_acc: 0.2625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDYMwNNB-lZV"
      },
      "source": [
        "### Evaluate the model on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAzzx-An-lZW",
        "outputId": "c9c07e3e-3cfa-4157-d990-ba4d4a17eb67"
      },
      "source": [
        "# Test data generator (same process that it was used in the training generators)\n",
        "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Here, the test split is being used, even though a y_col is being defined, it wont be used when predicting\n",
        "test_generator = test_gen.flow_from_dataframe(df_test,x_col='image_path', y_col=df_test.columns[1:], target_size=(224,224),\n",
        "                                                     class_mode ='raw', shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1959 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcsySEyT-lZW"
      },
      "source": [
        "# Predictions\n",
        "predictions = model.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbuqBDPqvwDI",
        "outputId": "905e747e-7c6c-42be-b299-87b8f086eeb7"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9994357 , 0.01967256, 0.754381  , 0.0019035 , 0.9999232 ,\n",
              "       0.6805687 , 0.02403776, 0.0148264 , 0.37443423, 0.9999558 ,\n",
              "       0.9128858 , 0.00334915, 0.0033653 , 0.99997044, 0.99985945,\n",
              "       0.99984026, 0.00129978, 0.9999738 , 0.14336427, 0.9998945 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt5_QtH8-lZW"
      },
      "source": [
        "# Decoding predictions\n",
        "# In the preprocessing part, the encoder was used. Now, those encoded predictions need to be decoded into 1s and 0s learned by the autoencoder\n",
        "\n",
        "decoder = tf.keras.models.load_model('/content/decoder-dp-combined-images.h5', compile=False) # Load decoder\n",
        "decoded_predictions = decoder.predict(predictions) # Decode predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxzmfDYbv3dQ"
      },
      "source": [
        "# In the process of training the autoencoder, a threshold was tuned to decide what is the value to consider when setting the predictions of the decoder to 1s and 0s\n",
        "# When tunning this value, 0.35... was the one with highest f1 score\n",
        "\n",
        "decoded_predictions[decoded_predictions>=0.4] = 1\n",
        "decoded_predictions[decoded_predictions<0.4] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk7zgAnP-lZW",
        "outputId": "1ff6529f-c05d-4d37-c14f-1ec18befd59f"
      },
      "source": [
        "# Compute f1-score\n",
        "# A higher f1-score is expected for this, because of combining all the images (train and val 2021 images). However, this score is using unseen data\n",
        "test_f1_score = f1_score(labels_transformed_test, decoded_predictions, average=\"micro\")\n",
        "print('F1-score (on test set): ' + str(test_f1_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score (on test set): 0.6674692993017097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJq_fTIE-lZW"
      },
      "source": [
        "# Save model\n",
        "model.save('/content/multilabel-classifier-using-autoencoder-all-smt.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeOukZ8Z-lZX"
      },
      "source": [
        "### Create a submission file for evaluation (using evaluate-f1.py script)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7038AYOK-lZX"
      },
      "source": [
        "# Lets load all the validation images 2021\n",
        "\n",
        "val_images_path_ids = [] # This list will contain the absolute path of each image and their id\n",
        "validation_images_path = '/content/ImageCLEF2021_ConceptDetection_Validation-Set/Validation-Images'\n",
        "\n",
        "#Extract images path and images ids\n",
        "for image in tqdm(os.listdir(validation_images_path), position= 0):\n",
        "  path_to_image = os.path.join(validation_images_path, image)\n",
        "  val_images_path_ids.append([path_to_image,image.split('.')[0]])\n",
        "\n",
        "val_images_path_ids_df = pd.DataFrame(val_images_path_ids, columns=['image_path','image_id']) # Dataframe to use in the prediction process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdRMYX1I-lZX"
      },
      "source": [
        "# Load images using the same preprocessing method used in training\n",
        "val_images_x = []\n",
        "for idx, row in val_images_path_ids_df.iterrows():\n",
        "  path_image = row['image_path']\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_image, target_size = (224,224)) # Load actual image\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)/255 # Transform image to array of shape (input_shape), and normalize values by dividing them over 255\n",
        "  val_images_x.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbODPYi_-lZX"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "val_images_preds = model.predict(np.array(val_images_x)) # Predict\n",
        "decoded_val_predictions = decoder.predict(val_images_preds) # Decode\n",
        "decoded_val_predictions[decoded_val_predictions>=0.4] = 1\n",
        "decoded_val_predictions[decoded_val_predictions<0.4] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNJDK6Ak-lZX"
      },
      "source": [
        "# Transformation of transformed labels to actual concepts\n",
        "\n",
        "val_labels_predicted = mlb.inverse_transform(decoded_val_predictions) # Use the transformer that was used in the autoencoder model training\n",
        "\n",
        "# Join predicted concepts and separate them by ;\n",
        "val_labels_united = []\n",
        "for prediction in val_labels_predicted:\n",
        "  str_concepts = ''\n",
        "  for concept in prediction:\n",
        "    str_concepts += concept+';'\n",
        "  val_labels_united.append(str_concepts[0:-1])\n",
        "\n",
        "# The image id needs to be included in the submission\n",
        "val_images_ids = []\n",
        "for idx, row in val_images_path_ids_df.iterrows():\n",
        "  val_images_ids.append(row['image_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVT6gbQR-lZY"
      },
      "source": [
        "# Create submission csv file that will contain the image_id \\t concepts\n",
        "final_predictions_val = pd.DataFrame({'image_ids': val_images_ids})\n",
        "final_predictions_val['predictions'] = pd.Series(val_labels_united)\n",
        "final_predictions_val.to_csv('/content/predictions-multilabel-classifier-using-autoencoder-dp-only.csv', \n",
        "                             index= False, sep ='\\t', header= False) # Dont include headers, and image_id and concepts need to be separated by tab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR58ZpEe-lZY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}