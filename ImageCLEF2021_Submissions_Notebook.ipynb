{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageCLEF2021 Submissions Notebook.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjpa121197/ImageCLEF2021/blob/main/ImageCLEF2021_Submissions_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38-ToS8B09Dc",
        "outputId": "725002c8-94ba-4a1a-8996-693b6faf80eb"
      },
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "os.environ['KAGGLE_USERNAME'] = \"####\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"####\" # key from the json file\n",
        "\n",
        "\n",
        "# File containing features for training, validation and testing images.\n",
        "# Also a merged csv file containing the actual concepts for the training and validation images\n",
        "!kaggle datasets download -d fjpa121197/imageclef-2021-final-features-and-concepts\n",
        "!kaggle datasets download -d fjpa121197/imageclef-2021-test-images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imageclef-2021-final-features-and-concepts.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading imageclef-2021-test-images.zip to /content\n",
            " 44% 9.00M/20.5M [00:00<00:00, 33.8MB/s]\n",
            "100% 20.5M/20.5M [00:00<00:00, 51.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iB3fDn51XvO",
        "outputId": "41718087-8995-4bca-8155-0c159db844c2"
      },
      "source": [
        "clef2021_final_features = \"/content/imageclef-2021-final-features-and-concepts.zip\"\n",
        "with ZipFile(clef2021_final_features, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done with final features file')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done with final features file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fJnv3Zrs8SV",
        "outputId": "d97ac930-9f27-41e0-d7d4-88375e71c5fe"
      },
      "source": [
        "# Unzip 2021 data test images\n",
        "clef2021_test_images = \"/content/imageclef-2021-test-images.zip\"\n",
        "with ZipFile(clef2021_test_images, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done with 2021 image test dataset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done with 2021 image test dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW4Vvfu813WC"
      },
      "source": [
        "import scipy\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "import json\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxNSO-sC_6sH"
      },
      "source": [
        "# Submission 1 (Information Retrieval Approach):\n",
        "The features for the training, validation and testing images have been extracted using a fine-tuned densenet-121 model (using training and validation images). The layer used as feature extractor is the average pool layer (dim 1024). Then, a KNN (n=1 and metric = cosine) was used to get the closest image and assign those tags.\n",
        "\n",
        "**Aicrowd submission id: 132945**\n",
        "\n",
        "**F1 score: 0.469**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-FFZzt61hbq"
      },
      "source": [
        "# Path to where all the extracted features of the training images are located\n",
        "train_features_path = '/content/imageclef-2021-final-features-and-concepts/train-val-images-features.npy'\n",
        "train_data_1 = np.load(train_features_path)\n",
        "train_data_2 = train_data_1[:,1:] #This is done because the first index of the arrays have the image id\n",
        "\n",
        "# Path to where all the extracted features of the validation images are located, these images will be used as query images.\n",
        "test_features_path = '/content/imageclef-2021-final-features-and-concepts/test-images-features.npy'\n",
        "test_data_1 = np.load(test_features_path)\n",
        "test_data_2 = test_data_1[:,1:]#This is done because the first index of the arrays have the image id\n",
        "\n",
        "\n",
        "# Read the actual tags for the training images\n",
        "db_images_tags = pd.read_csv('/content/imageclef-2021-final-features-and-concepts/merged-train-val-concepts.csv',names=['ImageId', 'Tags'], sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXleVvHA2ESg"
      },
      "source": [
        "# Initialize and fit data using Nearest neighbours, with n_neighbours = 1\n",
        "neigh = NearestNeighbors(n_neighbors=1, metric=scipy.spatial.distance.cosine)\n",
        "neigh.fit(train_data_2)\n",
        "\n",
        "# Get the results for our query images, which will return a list of lists of lists. One containing the distances, other one returning the indices\n",
        "# of the closest images\n",
        "results = neigh.kneighbors(test_data_2, return_distance=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FYdKMzG2agb"
      },
      "source": [
        "final_list_predictions = []\n",
        "\n",
        "for idx,test_image in enumerate(test_data_1):\n",
        "\n",
        "  test_image_id = 'synpic'+str(int(test_image[0])) # Get the actual image_id for the query image\n",
        "\n",
        "  # This will iterate through the results array and retrieve the index of the top 10 closest images, which will allow to map to an image_id\n",
        "  # The actual distance between the query image and the indexed images is given, however, this is optional.\n",
        "  top_1_images_ids_scores = []\n",
        "  for idy,result in enumerate(results[1][idx]):\n",
        "    top_1_images_ids_scores.append(['synpic'+str(int(train_data_1[result][0])),results[0][idx][idy]])\n",
        "\n",
        "  # Pass results to a dataframe so an inner join can be performed with the indexed images tags dataframe.\n",
        "  can = pd.DataFrame(top_1_images_ids_scores, columns=['ImageId','Canberra'])\n",
        "  candidate_images_tags = pd.merge(can, db_images_tags, on= 'ImageId')\n",
        "  candidate_tags_str = ';'.join(set(candidate_images_tags['Tags'][0].split(\";\")))\n",
        "  # Run the tag selection function, which will return a string containing the tags selected separated by \";\"\n",
        "  final_list_predictions.append([test_image_id,candidate_tags_str])\n",
        "\n",
        "# Save list containing the query images ids and its predicted tags, separated (ImageId and tags) by tabular space.\n",
        "np.savetxt(\"submission-1.csv\",final_list_predictions, delimiter='|',fmt = '% s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy-qCV1aA25b"
      },
      "source": [
        "# Submission 2 (Multi-label classification approach):\n",
        "\n",
        "\n",
        "\n",
        "**Aicrowd submission id: 133912**\n",
        "\n",
        "**F1 score: 0.412**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmGh5xKfuJTm"
      },
      "source": [
        "def transform_images(path_to_image):\n",
        "  #path_to_image = os.path.join(training_images_dir, image)\n",
        "  img = tf.keras.preprocessing.image.load_img(path = path_to_image, target_size= (224,224))\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img = tf.keras.applications.densenet.preprocess_input(img)\n",
        "\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDTzFf3wspvA"
      },
      "source": [
        "# Load images for them to be passed to each model (diagnostic procedure and bpo)\n",
        "test_images_ids = []\n",
        "test_images = []\n",
        "test_images_directory = '/content/ImageCLEF2021_CaptionConceptsTasks_TestSet_444_Images'\n",
        "for image in os.listdir(test_images_directory):\n",
        "  test_images_ids.append(image.split(\".\")[0])\n",
        "  test_images.append(transform_images(os.path.join(test_images_directory, image)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr5dOI2msMXV"
      },
      "source": [
        "## Diagnostic Procedure Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS9X3pyA4Px"
      },
      "source": [
        "# Load model and pickle object\n",
        "dp_model = tf.keras.models.load_model('/content/dp-classifier-partial-unfreeze-threshold40-use-for-predictions.h5', compile= False)\n",
        "\n",
        "with open(\"/content/mlb_dp_classifier.pkl\", 'rb') as f:\n",
        "    mlb = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-8qKyb5u960"
      },
      "source": [
        "dp_predictions = dp_model.predict(np.array(test_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JO_GZiUvE6C"
      },
      "source": [
        "# Use previous threshold with better f1-score\n",
        "dp_predictions[dp_predictions>=0.4] = 1\n",
        "dp_predictions[dp_predictions<0.4] = 0\n",
        "test_images_labels_predicted_dp = mlb.inverse_transform(dp_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1fHH6zgvd8D"
      },
      "source": [
        "# The concept(s) are needed as strings separated by ; if applicable\n",
        "val_labels_united_dp = []\n",
        "for idx,prediction in enumerate(test_images_labels_predicted_dp):\n",
        "  str_concepts = ''\n",
        "  for concept in prediction:\n",
        "    str_concepts += concept+';'\n",
        "  val_labels_united_dp.append([test_images_ids[idx],str_concepts[0:-1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR4UjHElv76x"
      },
      "source": [
        "dp_predictions_df = pd.DataFrame(val_labels_united_dp, columns=['ImageId', 'dp_predictions'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbxeu3aVwPDJ"
      },
      "source": [
        "## BPO Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXqE0MuTwFuR"
      },
      "source": [
        "# Load model and pickle object\n",
        "bpo_model = tf.keras.models.load_model('/content/bpo-classifier-partial-unfreeze-threshold1-use-for-predictions.h5', compile= False)\n",
        "\n",
        "with open(\"/content/mlb_bpo_classifier.pkl\", 'rb') as f:\n",
        "    mlb_bpo = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiRMMO2cwaIu"
      },
      "source": [
        "bpo_predictions = bpo_model.predict(np.array(test_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHWoZLVCwgbf"
      },
      "source": [
        "# Use previous threshold with better f1-score\n",
        "bpo_predictions[bpo_predictions>=0.1] = 1\n",
        "bpo_predictions[bpo_predictions<0.1] = 0\n",
        "test_images_labels_predicted_bpo = mlb_bpo.inverse_transform(bpo_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9K2vi32wtHC"
      },
      "source": [
        "# The concept(s) are needed as strings separated by ; if applicable\n",
        "val_labels_united_bpo = []\n",
        "for idx,prediction in enumerate(test_images_labels_predicted_bpo):\n",
        "  str_concepts = ''\n",
        "  for concept in prediction:\n",
        "    str_concepts += concept+';'\n",
        "  \n",
        "  if len(str_concepts) > 1:\n",
        "    val_labels_united_bpo.append([test_images_ids[idx],str_concepts[0:-1]])\n",
        "  else:\n",
        "    val_labels_united_bpo.append([test_images_ids[idx],np.nan])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhqYgoG_w1V2"
      },
      "source": [
        "bpo_predictions_df = pd.DataFrame(val_labels_united_bpo, columns=['ImageId', 'bpo_predictions'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f-N-hxcxD6Q"
      },
      "source": [
        "## Merge predictions from both dfs and create submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRXX-c1Cw5Hs"
      },
      "source": [
        "final_prediction = pd.merge(dp_predictions_df,bpo_predictions_df, on='ImageId',how='outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rlN9RsRxCo8"
      },
      "source": [
        "final_prediction['dp_bpo_tags'] = final_prediction[final_prediction.columns[1:]].apply(lambda row: ';'.join(row.dropna()), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGA4MGb5xbsB"
      },
      "source": [
        "final_prediction.to_csv('/content/submission-2.csv', index= False, sep ='|', header= False, columns=['ImageId','dp_bpo_tags'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}